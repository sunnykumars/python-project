[
  {
    "open_issues": [], 
    "repo": "pox"
  }, 
  {
    "open_issues": [], 
    "repo": "sfio"
  }, 
  {
    "open_issues": [
      {
        "comments": [
          "The idea here was to pass an array in a place where you might pass an accessor-expression, for instance to use data which is not in the same dataframe, or even to calculate new columns on the fly on the R side using [bquote .(expr)](https://stat.ethz.ch/R-manual/R-devel/library/base/html/bquote.html).\n"
        ], 
        "number": "19", 
        "title": "support embedded arrays"
      }, 
      {
        "comments": [
          "Damn my reticence, what was I going to do with these? We already use column names for accessors, and create magic variables so they are interpreted specially. What did I want to use row names for?\n"
        ], 
        "number": "18", 
        "title": "support row/column names"
      }, 
      {
        "comments": [], 
        "number": "17", 
        "title": "..index.. not recognized as ordinal"
      }, 
      {
        "comments": [], 
        "number": "16", 
        "title": "array of strings interpreted as function call"
      }, 
      {
        "comments": [
          "Use this: https://github.com/dc-js/dc.js/blob/develop/web/docs/api-latest.md#dc.baseMixin+controlsUseVisibility\n"
        ], 
        "number": "15", 
        "title": "have a way to disable the current filter display (and reset)"
      }, 
      {
        "comments": [
          "I think the problem is right here:\n\n``` r\n            else if(sexp[0]==='c')\n                    return sexp.slice(1);\n            // else we'll process as expression below\n```\n\nhttps://github.com/att/rcloud.dcplot/blame/master/inst/www/wdcplot.js#L232\n\nNo, just always process as expression.\n\nAnd here's the possibly-errant commit (1/1/2014), which looks like it was going in the right direction but didn't go far enough: att/rcloud@0eec64fe8729977f9600f10710444f0bc06d062f\n\n> Extensive changes to expression processing on JS side - needs further testing, but far more robust in principle.\n\nHar, har.\n"
        ], 
        "number": "14", 
        "title": "arrays containing negative numbers not parsed properly"
      }, 
      {
        "comments": [
          "Please provide a help page for wdcplot in RCloud when 'wdcplot' is entered into the search box\n"
        ], 
        "number": "13", 
        "title": "Help"
      }, 
      {
        "comments": [], 
        "number": "11", 
        "title": "move wdcplot.js, dcplot.js, and dataframe.js out of rcloud"
      }, 
      {
        "comments": [
          "Right now the charts are just float left. \n\nIt's possible that the horizontal space is less in view.html?  Which would be wrong.\n\nI plan to do upgrades of rcloud.dcplot and rcloud.shiny after the 1.2 release - marking 1.2.1\n", 
          "_From @rhknag on October 11, 2014 21:38_\n\nCan one set the horizontal space in view.html as one can do in edit.html?  In any event with my current settings I see wdcplot two charts per line in my example in edit.html and only one in view.html  with the following settings:\n\n``` r  width=1200, height=800, echo=FALSE\n```\n", 
          "_From @rhknag on October 23, 2014 15:19_\n\nI just noticed that more than one chart is shown per line in Firefox.   So I think it may be an issue of render size in the \"shareable link\" mode on Chrome.  It appears that charts are larger in \"shareable link\" mode than in notebook mode on Chrome - because I see two charts per line in notebook mode but only one per line in \"shareable link\" mode.  See the wdcplot section of : https://rcloud.research.att.com/edit.html?notebook=478b1a9adeb47072d87f\n"
        ], 
        "number": "10", 
        "title": "rcloud.dcplot showing only one chart per row in view mode"
      }, 
      {
        "comments": [
          "There are two things you might want to retrieve:\n1. The filter ranges / values (to be able to return to a filter like in Carlos and Kenny's [MLB Hall of Fame Voting Trajectories](http://cscheid.net/static/mlb-hall-of-fame-voting/) visualization)\n2. The actual row values.\n\nWe should support both.\n"
        ], 
        "number": "9", 
        "title": "wdcplot save values"
      }, 
      {
        "comments": [
          "dc.js and crossfilter can do any kind of aggregation, but it does expect to have all the data - I think you'd have to use something external for sampling.\n\nI assume you mean returning a percentage of the total for each bin, instead of its straight sum. dcplot.js and wdcplot.js do not have percent calculation built in.  It's really external to what crossfilter does - you would still need to do a regular sum in the group reductions and then calculate the percentages afterward.  This is because crossfilter expects to be able to calculate reductions incrementally, and a percentage depends on the values of the other bins so it doesn't really fit that model.\n\n`any` just grabs any value - it's intended for reductions where you expect all the records to have the same value.  I don't think that helps here.\n\nPercentage could be supported using a group wrapper (a.k.a. [fake group](https://github.com/dc-js/dc.js/wiki/FAQ#filter-the-data-before-its-charted)).  Or we could offer a way to get at the vector of all bins, or the sum of the bins, from R.\n"
        ], 
        "number": "8", 
        "title": "wdcplot  reduce  - percentage?"
      }, 
      {
        "comments": [
          "would prefer to fix this at the rserve.js level... i know, another big refactoring, but we are special casing everything that can be an array of size one to work around the way rserve.js thinks it's a scalar.\n", 
          "_From @cscheid on May 6, 2014 18:8_\n\nI'd like to not change `json` if possible. maybe the solution is to allow a function to return the unconverted raw javascript object from rserve-js. Right now everything in ocap mode calls json.\n", 
          "Yeah, I'm thinking that ideally clients of rserve.js could register that they want particular parameters really to be arrays and not scalarized.  I don't know how this would happen though.\n", 
          "I wouldn't want to change it everywhere, agreed.  Usually what looks like a scalar, is.\n", 
          "To contradict myself: we are working around arrays of size one being interpreted as scalars, all over the place. Do that again here.\n"
        ], 
        "number": "7", 
        "title": "wdcplot plots of factors with a single level are broken"
      }, 
      {
        "comments": [], 
        "number": "6", 
        "title": "Create example of using an ocapped R function as a dcplot param"
      }, 
      {
        "comments": [], 
        "number": "5", 
        "title": "Create example of using an ocapped js function as a dcplot param"
      }, 
      {
        "comments": [], 
        "number": "4", 
        "title": "Finish creating examples for new dcplot features"
      }, 
      {
        "comments": [
          "This will be handled via an extension to dc.js here:\n\nhttps://github.com/yurukov/dc.leaflet.js\n\nThe extension is not completely up to dc.js standards yet; I intend to integrate it post-2.0 (which means post-RCloud 1.2).\n"
        ], 
        "number": "3", 
        "title": "leaflet module"
      }, 
      {
        "comments": [
          "Putting off for 1.0, as it seems dc.js 2.0 is not ready and this also requires some serious development in dcplot.js\n"
        ], 
        "number": "2", 
        "title": "series charts"
      }, 
      {
        "comments": [], 
        "number": "1", 
        "title": "Incremental display of results"
      }
    ], 
    "repo": "rcloud.dcplot"
  }, 
  {
    "open_issues": [], 
    "repo": "graphviz"
  }, 
  {
    "open_issues": [], 
    "repo": "inception-chef-repo"
  }, 
  {
    "open_issues": [], 
    "repo": "e4ss"
  }, 
  {
    "open_issues": [], 
    "repo": "pads"
  }, 
  {
    "open_issues": [], 
    "repo": "GGobi"
  }, 
  {
    "open_issues": [
      {
        "comments": [
          "Showcase mode highlights code as its run, serving as a primitive debugger. It would be very helpful to our users."
        ], 
        "number": "23", 
        "title": "showcase mode doesn't work"
      }, 
      {
        "comments": [], 
        "number": "20", 
        "title": "Shiny in the cell and implementation of print shiny.appobj"
      }, 
      {
        "comments": [], 
        "number": "18", 
        "title": "Shiny in a cell"
      }, 
      {
        "comments": [], 
        "number": "17", 
        "title": "override shiny.tag instead of immediately starting server in rcloud.shinyApp"
      }, 
      {
        "comments": [
          "I don't think this is an issue in rcloud.shiny, but somewhere in configuration and permission space. \n\nThe notebook worked when I imported it to my local, once I installed latex. Did not get it working on rcloud-5, although moving `report.Rmd` out of Ganz's home seemed to help somewhat (pandoc errors instead of cannot open errors).\n"
        ], 
        "number": "11", 
        "title": "Download knitR report example is not working in RCloud"
      }, 
      {
        "comments": [], 
        "number": "8", 
        "title": "shiny server fails when rcloud path is user+path"
      }
    ], 
    "repo": "rcloud.shiny"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "2538", 
        "title": "new notebooks are hidden?"
      }, 
      {
        "comments": [
          "@bashlee, I'll assign this to you since it's good to have someone else who understands rcloud.solr.\r\n\r\nThere are still some rough edges to the integration of rcloud.solr into RCloud. I think @dougmet tested the package thoroughly using mocking, however RCloud is difficult to mock and we didn't do enough end-to-end testing."
        ], 
        "number": "2533", 
        "title": "\"all components of body must be named\" when hiding notebook or making it private"
      }, 
      {
        "comments": [
          "Let's discuss tomorrow on the call. I wasn't aware that there would be so many considerations. But I guess I'm not surprised, since the notebook interface is already so complicated.\r\n\r\nIn particular, I thought that the case where the user has manually scrolled would already be handled by design, because the notebook pane should only autoscroll if the final lines are visible.", 
          "Also I'm not clear what it would have to do with the input of the cell - it's mostly about the end of the output being visible but in danger of disappearing.", 
          "No question, this is a tricky feature. \r\n\r\nOne use case for this (probably the main use case) is long-running cells that are doing a lot of work. For that reason, you'll need to hook in deeper than `end_output` - probably `add_result` would be more appropriate.\r\n\r\nConsider the following test case:\r\n\r\n```r\r\nfor(i in 1:10) {\r\n    print(1:100)\r\n    Sys.sleep(2);\r\n} \r\n```\r\n\r\nAfter each output, the notebook should scroll.\r\n\r\nI still have to chew on the rest of your comments.", 
          "Thank you for providing example use case, it clarified the requirements a lot.\r\n\r\nBTW, the example that you provided results in RCloud session crash in my env. I am guessing it works fine for you? \r\n\r\nI will workaround this for now by using this:\r\n```{r}\r\nres <- lapply(c(1:10), function(x) {\r\n    print(1:100)\r\n    Sys.sleep(2)\r\n} ) \r\n```\r\n which does pretty much the same thing.", 
          "Hmm, that is probably the odd rserve.conf settings that you figured out to get pandoc working? Wild! I have no idea why a for loop would be different than lapply.\r\n", 
          "Tried with both configurations - default and 'tweaked' - and it failed... odd...  \r\n\r\nNew commit holds improved autoscrolling implementation, which supports the example use case and the simple use cases. \r\n\r\nI guess the question is if we should add support for the use cases covering execution of multiple cells in this thread, or should we raise a separate ticket? This might simplify change management...", 
          "@useless5771, are you perchance trying to use RCloud with R3.4? \r\n\r\nSo far we are only compatible with 3.3; segfaults will occur with 3.4.", 
          "This works great now.\r\n\r\nI am beginning to understand the issues you raised above.\r\n\r\nHowever think there might be simpler solutions.\r\n\r\n 1. It's not exactly about whether Run All was selected, but about whether there are more cells enqueued to run. So perhaps what we could do is just scroll to each cell as it is started, as long as the end of results of the last cell are visible.\r\n\r\n 2. Or alternately, maybe we could just scroll to the **next** cell, so that if you run cells in sequence, the next one can always \"capture\" the scroll.\r\n\r\nHowever, I agree this is another level of complication and we should take small steps.\r\n\r\nCould you please put this under an option e.g. 'Autoscroll notebook', so that if it drives people crazy they can turn it off? This is the behavior that I usually want but there are ways of interacting with the notebook where it might be annoying, particularly if you want to enqueue multiple cells or otherwise interact with the notebook after it has started.", 
          "Ok, I will add the option to disable the autoscroll. \r\n\r\nRegarding R version, indeed I use  3.4.3 (I upgraded it when I was investigating the issues with python/rmarkdown cells). I will downgrade it. Thanks.", 
          "\"Autoscroll notebook\" option exposed.", 
          "Downgrading R also fixed the for loop issue, thanks."
        ], 
        "number": "2526", 
        "title": "Autoscroll output in notebook pane when cell is executed."
      }, 
      {
        "comments": [], 
        "number": "2523", 
        "title": "session disconnect can prevent you from navigating away"
      }, 
      {
        "comments": [
          "I guess it's a particular notebook? \r\n\r\nI did notice some issues with solr & comments, but I thought they were old issues that carried over into the new implementation since it was based on the old one."
        ], 
        "number": "2522", 
        "title": "Indexing a notebook fails"
      }, 
      {
        "comments": [], 
        "number": "2520", 
        "title": "updating a notebook that doesn't match date filter doesn't show the notebook"
      }, 
      {
        "comments": [
          "Similarly, if a notebook is renamed so that it enters an existing folder, the folder should be moved to the correct spot, not kept in the same spot as currently:\r\n\r\n![image](https://user-images.githubusercontent.com/1366709/33400645-c9e3538a-d524-11e7-8f25-1b5ef7d99d17.png)\r\n", 
          "Finally, if the most recent notebook in a folder is renamed so that it leaves the folder, the folder should be moved to the spot determined by the next most recent notebook."
        ], 
        "number": "2519", 
        "title": "updating a notebook doesn't change its position in the date-sorted tree"
      }, 
      {
        "comments": [
          "It should be relatively simple to change so that entered text of `RCloud 249` matches `RCloud` or `249`, but I'm assuming that you'd also like to match `RCloud2017` and `249000` with that too.\r\n\r\nIt makes most sense to me for the lucene syntax prep to be done in `rcloud.solr`, rather than in the JS, although a change or two may be required there too (particularly where a space is added at the end - doesn't make sense to do another search).\r\n\r\n**Edit**: Looks like we'd have to use `setAllowLeadingWildcard` for my approach, above.", 
          "I forgot this was going through Lucene. I don't know if Lucene supports this, but my preferred behavior would be term1 followed by term2 followed by term3. (in regexp, `/term1.*term2.*term3/`)\r\n\r\nBarring that, an implied `AND` would be fine. I don't think there's any point to considering `OR` for incremental search, and I'd rather people didn't have to use Lucene syntax here.\r\n\r\nExample usage: type a fragment of a folder name, space, fragment of notebook name.", 
          "Thanks @gordonwoodhull.", 
          "We'll sort this in att/rcloud.solr#81 . Should be straight forward, just need to get the right syntax and try some edge cases.", 
          "Syntax updated to use AND operator in att/rcloud.solr#81. A search for \"Notebook 1\" would return notebooks `Notebook 1` & `Notebook 17` but not `Notebook 31`"
        ], 
        "number": "2518", 
        "title": "typing multiple terms in incremental search, only the last one is regarded"
      }, 
      {
        "comments": [], 
        "number": "2516", 
        "title": "\"Transferred a partial file\" when updating a comment"
      }, 
      {
        "comments": [], 
        "number": "2511", 
        "title": "this one folder has escaped the empty folder filter"
      }, 
      {
        "comments": [
          "![image](https://user-images.githubusercontent.com/2493614/33596833-1ff8eafe-d995-11e7-99ef-48c643f84a93.png)\r\n\r\nI assume you're not referring to this method of importing, because I cannot reproduce on 1.9."
        ], 
        "number": "2508", 
        "title": "importing external notebooks should open folders"
      }, 
      {
        "comments": [
          "@useless5771, there is no urgency to this issue, since the side panels display okay with my custom algorithm.\r\n\r\nHowever, since you recently had an encounter with `RCloud.UI.collapsible_column.resize`, it might be a good moment to look at this."
        ], 
        "number": "2504", 
        "title": "the side panels should probably use flexbox to fit panes"
      }, 
      {
        "comments": [], 
        "number": "2500", 
        "title": "show dates on folders when ordering by date"
      }, 
      {
        "comments": [
          "I think the implementation would be\r\n\r\n1. When reading the tree initially, calculate and save the latest date of all folders from the bottom up. \r\n2. Whenever a change is made to a notebook date, traverse from the notebook up the tree and take the max date of the saved value vs the change date .\r\n\r\nUsually a change to a notebook is because the user changed it, so it will be the max date, but the metadata can get out of sync with the backend, so it is also possible for a notebook to be updated to some old date.", 
          "Also please consider the order of \"new old\" folders that pop up when a notebook is new to this instance but has a date which places its folder in the middle of the sort, e.g. https://github.com/att/rcloud/pull/2507#issuecomment-346152914"
        ], 
        "number": "2497", 
        "title": "define date of folder recursively"
      }, 
      {
        "comments": [
          "Not questioning the requirement for some UI feedback that something is happening, but has this process slowed since the tree refactoring?", 
          "Looks like the slowness here is GitHub-related. When I fork the same folder on old versus new RCloud on Research (with gist backend) it's only a couple of seconds, no difference that I can tell.\r\n\r\n(That's a folder with only one notebook. A folder with eight notebooks takes more like eight seconds, which is long enough to make one wonder what is happening.)"
        ], 
        "number": "2495", 
        "title": "forking folder should show progress"
      }, 
      {
        "comments": [
          "Yes, it's definitely something we want to do. Fairly difficult design problem with a lot of ramifications, especially when the notebook has installed and run JavaScript.\r\n\r\nPrevious discussion: #1803, #777."
        ], 
        "number": "2454", 
        "title": "Resumable session management"
      }, 
      {
        "comments": [], 
        "number": "2453", 
        "title": "Rcloud ubuntu14 Fatal error"
      }, 
      {
        "comments": [
          "Hi @dipenpatel235 . Could you give me some more info on the issue above. do the container logs say something with error ? Or does the UI exhibit some different behavior. \r\n\r\nPrateek"
        ], 
        "number": "2452", 
        "title": "rcloud R code not compile using docker image"
      }, 
      {
        "comments": [], 
        "number": "2449", 
        "title": "tree filtering based on notebook folder/name"
      }, 
      {
        "comments": [], 
        "number": "2443", 
        "title": "Project grouping semantics and support"
      }, 
      {
        "comments": [
          "This has to do with the way \"star\" has two meanings. For other people's notebooks, it means I like it, I'm interested. For my own notebooks, it just means I created it and haven't unstarred it.\r\n\r\nAnother, unfortunate, meaning is \"I care about this user's notebooks and I don't want to hunt through All Users, so I'll make sure to star one of their notebooks.\"\r\n\r\nI wonder if there is some way to resuscitate the original meaning of Star, so that we don't have to implement an overlapping feature."
        ], 
        "number": "2439", 
        "title": "bookmarks"
      }, 
      {
        "comments": [], 
        "number": "2436", 
        "title": "ability to serve temporary files from a session"
      }, 
      {
        "comments": [], 
        "number": "2434", 
        "title": "stopping shell cells takes a random amount of time"
      }, 
      {
        "comments": [], 
        "number": "2433", 
        "title": "imported notebook name can clash with existing notebooks"
      }, 
      {
        "comments": [], 
        "number": "2428", 
        "title": "notebook still scrolls on autosave"
      }, 
      {
        "comments": [
          "Note that running `rcloud.update.notebook` directly works - afaict it's the same call?\r\n\r\n```R\r\nid <- rcloud.session.notebook()$content$id\r\nrcloud.update.notebook(id, list(files=list('scratch.R'=NULL)))\r\n```", 
          "If anyone needs a workaround, a colleague implemented it this way:\r\n\r\n```r\r\n    delete.asset = function(name) {\r\n        l = list()\r\n        l[name]=list(NULL)\r\n        rcloud.update.notebook(\r\n            rcloud.session.notebook()$content$id,\r\n            list(files=l))\r\n    }\r\n```\r\n", 
          "@bashlee, could you have a look at this one? Part of the effort is to determine how the current solution was supposed to work and see if it can be fixed. \r\n\r\nIf not, the above workaround could be cleaned up and used."
        ], 
        "number": "2420", 
        "title": "rcloud.delete.asset doesn't work"
      }, 
      {
        "comments": [], 
        "number": "2402", 
        "title": "simple gist interface to replace Open in GitHub"
      }, 
      {
        "comments": [], 
        "number": "2399", 
        "title": "package help"
      }, 
      {
        "comments": [], 
        "number": "2398", 
        "title": "generate slideshow in discover page (and elsewhere)"
      }, 
      {
        "comments": [
          "the effect is similar to the copy-then-delete annoyance in the asset pane #735. not the same root cause in the code, but also caused by lazy implementation of the API."
        ], 
        "number": "2397", 
        "title": "fork-and-rename takes a long time to rename"
      }, 
      {
        "comments": [
          "Please feel free to rewrite. I had no idea what I was doing at the time, and I think it has missed some later upgrades.", 
          "It's not that bad - it only needs to change the context creation to `githubgist::create.gist.context`, but I don't know what it may break and/or whether we need to beef up `githubgist::create.gist.context` to support this usage which is why I'm moving this to 1.8 with the quick fix in 1.7.1."
        ], 
        "number": "2395", 
        "title": "Import External Notebooks bypasses the git API and only works for GitHub imports"
      }, 
      {
        "comments": [
          "As noted on internal SO, we have `?user=...&path=...` and I can see how we could make the query string even shorter (and only have one part). \r\n\r\nBut I have no idea how to change the path - for complete control we'd probably have to delve into nginx's business.\r\n\r\n@s-u might have some ideas here. This is related to #514 but more ambitious.", 
          "The `R` scripts (like `notebook.R`) support path parsing, so in principle you could write one that does something (similar to `proxy.R`). However, what Lance is proposing cannot work in generality, because a) it would change the root of the document and b) those pages actually rely on the query string so you can't strip it. The browser has to actually go to the full URL for it to function.\r\n\r\nWe can special-case things like `shiny.html` by having let's say `shiny.R` that generates modified code that embeds the query variables in the html output, but it's only viable for such special cases since the underlying system has to be aware of the change.\r\n", 
          "As for branded domain/URL, that's really up to the user - you can always create one using `iframe`, e.g., see https://rcloud.social/notebook.R/s-u/iframe-example so I don't think  this has really anything to do with RCloud"
        ], 
        "number": "2389", 
        "title": "RCloud router request"
      }, 
      {
        "comments": [], 
        "number": "2386", 
        "title": "shareable link button sometimes not showing"
      }, 
      {
        "comments": [
          "An oddity of GitHub is you can comment on lines of commits but not lines of source.", 
          "I guess it's because source changes but a commit does not."
        ], 
        "number": "2385", 
        "title": "Comments on cells"
      }, 
      {
        "comments": [
          "Related: #1219\r\n\r\nIt can be argued that no one cares about the actual cell numbers that are stored in the gist. We could just display 1,2,3,4.... no matter what the actual cell numbers are. It would be harder to read the gist in github but not much more so.\r\n\r\nAlternately we could adopt stable numbering with fractional cell numbers, as I first suggested in #36. This could be made backward-compatible and the stability would make diff/merge simpler."
        ], 
        "number": "2384", 
        "title": "Optional cell numbering cleanup function (sort of a rebase)"
      }, 
      {
        "comments": [
          "Thanks @samurainate.\r\n\r\nI agree, it should follow the behavior of the R command line. In fact, I thought it was using the same code to decide which expressions to print. But @s-u would know better about that. ", 
          "This seems like a `data.table` oddity -- in fact the correct behavior should be to print it twice, because:\r\n\r\n```r\r\n> withVisible(iris.dt[,new.col:=\"a value\"])$visible\r\n[1] TRUE\r\n```\r\n\r\nso RCloud does the correct thing since `data.table` asks for that result to be printed. I wonder what makes `data.table` change its behavior, though. You may want to ask Matt, perhaps he can shed some light on how `data.table` decides to set the visibility flag.\r\n\r\nFor the record, RCloud doesn't perform any detection, it simply honors the visibility flag set by the expression so it's really up to the expression to decide the behavior, not RCloud."
        ], 
        "number": "2382", 
        "title": "Suppress or prevent automatic print of data.table when dt[,field"
      }, 
      {
        "comments": [
          "ideally, stuff like this could even work:\r\n```r\r\n div(id=\"clickme\", onClick=function() { print(\"i'm in R!\") })\r\n```\r\n(i don't know htmltools syntax, only looked at it briefly.)", 
          "and even better with more rcloud.web integration (output contexts?) and mini.html"
        ], 
        "number": "2375", 
        "title": "support printing htmltools objects"
      }, 
      {
        "comments": [], 
        "number": "2373", 
        "title": "rcloud.md.out?"
      }, 
      {
        "comments": [
          "We agree but we're not sure where to put this in the UI. The session info pane is really just a log for stdout/stderr/etc.\r\n\r\nFor adding your own messages to the session pane, you can use `rcloud.session.log`"
        ], 
        "number": "2370", 
        "title": "session info"
      }, 
      {
        "comments": [], 
        "number": "2367", 
        "title": "make sure whole R error message is printed in shiny/mini"
      }, 
      {
        "comments": [
          "This would be really great. Thanks for the suggestion @VincentLous!\r\n\r\nMaybe we can create a table of contents dropdown in the selection bar, which contains markdown titles as well as cell numbers for code cells (with an excerpt of the code?)\r\n"
        ], 
        "number": "2362", 
        "title": "navigation within a notebook"
      }, 
      {
        "comments": [], 
        "number": "2355", 
        "title": "websocket timeouts"
      }, 
      {
        "comments": [], 
        "number": "2354", 
        "title": "confirm and decrypt protected notebooks on export"
      }, 
      {
        "comments": [
          "At least on macOS, this is only a Firefox issue - Chrome and Safari use an ellipsis to shorten the filename. Putting off.\n"
        ], 
        "number": "2351", 
        "title": "file chooser in Pull&Replace can spill out"
      }, 
      {
        "comments": [
          "Actually it looks like I did this intentionally, in order to be conservative. If the output format is `html_document`, it's overridden with `html_fragment`. Otherwise it's kept.\n\nhttps://github.com/att/rcloud/blob/develop/rcloud.packages/rcloud.rmarkdown/R/main.R#L11\n\nI don't think that's very friendly to users, as there aren't likely to be formats that blend well with the RCloud GUI.\n\nMaybe only keep the format if another option forces it.\n"
        ], 
        "number": "2338", 
        "title": "rmarkdown cells with other layout can break RCloud layout"
      }, 
      {
        "comments": [
          "I'm seeing some sort of memory corruption during garbage collection in Chrome, too:\n\nupdate_notebook: Error in base64encode(what) : GC encountered a node (0x7f84a82f1600) with an unknown SEXP type: FREESXP at memory.c:995 R trace: .Call(B64_encode, as.raw(what), linewidth, newline) base64encode(what) encode.b64(bin.f[[i]]$content) .gist.binary.process.outgoing(id, content) fun(...)\nCancel\n"
        ], 
        "number": "2336", 
        "title": "Firefox"
      }, 
      {
        "comments": [], 
        "number": "2330", 
        "title": "Support pull from notebook w/ version "
      }, 
      {
        "comments": [], 
        "number": "2324", 
        "title": "Cookie Domain do not infer until explicitly set"
      }, 
      {
        "comments": [], 
        "number": "2323", 
        "title": "Infinite login loop when no real authentication backend exists"
      }, 
      {
        "comments": [
          "Hopefully this will be improved by the rcloud.solr rewrite."
        ], 
        "number": "2318", 
        "title": "Handle SOLR connection issues gracefully"
      }, 
      {
        "comments": [
          "I created a Markdown cell with a link, like so:\n\n```\nThis cell contains a <a href=\"http://rcloud.social/index.html\">link in markdown</a>. \n```\n\nRan it:\n![image](https://cloud.githubusercontent.com/assets/1366709/19794489/84766322-9ca0-11e6-8913-8ff847f6f5b1.png)\n\nI clicked on the link and Firefox browsed to the other page and did not show a reconnect message.\n\nIs there another step or circumstance where this occurs?\n", 
          "I just executed the markdown cell and clicked on the link \n\n![session](https://cloud.githubusercontent.com/assets/10941328/19799656/6c92aad4-9d15-11e6-84a8-19ced187635b.gif)\n"
        ], 
        "number": "2316", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "Hi @LanceJensen-General, thanks for the report.\n\nI'm not sure I understand, do you mean this button? &emsp;![image](https://cloud.githubusercontent.com/assets/1366709/19654550/c218f8e6-99e6-11e6-831f-80575afadeb5.png)\n\nThat just activates the cell editor (enters edit mode as opposed to view mode), it doesn't make the notebook read-only. Currently the only notebooks that are read-only are other people's notebooks and old versions of one's own notebooks.\n", 
          "Yes.  That is the button.  I can be in the mode where the editor is \"off\"\nand still delete content from the cell.\n", 
          "I'm not able to repro that. I can delete the whole cells but I can't modify their content unless the edit mode is enabled. Are there specific steps to reproduce this bug?\n", 
          "I was simply trying to get into edit mode.  The ui seemed to respond.  I\ndeleted some text.  Then I typed.  No characters appeared.  I hovered over\nthe edit mode icon for the cell and it gave me the enter edit mode option.\nI was able to then type in the field.\n\nEnvironmentally I would say that +/-2 hours I had connection issues.\n (Reconnect message in red in the session pane) I also had the source code\nstaleness.  I think these events happen when the server gets loaded.\n"
        ], 
        "number": "2314", 
        "title": "Cell Edit toggle button"
      }, 
      {
        "comments": [
          "PS: another interesting thought would be to have the automatic star go away with time - the thought being that whatever I start working on is relevant in the short term, but only things I tagged should stay relevant in the long term... (though, not without its problems, either).\n"
        ], 
        "number": "2302", 
        "title": "\"real star\" or bookmark feature for own notebooks"
      }, 
      {
        "comments": [
          "@shaneporter, could you take a look at this? I vaguely remember you fighting to keep these images in bounds."
        ], 
        "number": "2296", 
        "title": "Asset image overlaps on other divs "
      }, 
      {
        "comments": [], 
        "number": "2295", 
        "title": "Application hangs, even though cell execution is completed"
      }, 
      {
        "comments": [
          "It's a little weird, but you can do this in the history in the notebook tree - just start to rename the version as if you are creating a tag, but press <kbd>ctrl/cmd enter</kbd> instead. I don't know if this is more or less confusing than if we enabled it in the navbar, which would also mean being able to change the title of all versions while viewing an old version."
        ], 
        "number": "2293", 
        "title": "allow forking a renamed version of a notebook"
      }, 
      {
        "comments": [
          "An intermittent bug it seems - I see the correct order.\n", 
          "Now I'm seeing stuff like this - kind of jumbled order:\n\n![image](https://cloud.githubusercontent.com/assets/1366709/19106637/6e586abe-8ab6-11e6-8413-07feb86fee9b.png)\n\nMaybe the dates we are displaying are not the same dates we're sorting by.\n", 
          "I'm not seeing this on three sites right now. But we haven't fixed anything. \ud83d\ude20 \n"
        ], 
        "number": "2292", 
        "title": "recent discover pages out of order?"
      }, 
      {
        "comments": [
          "How would the client make the discovery? Is there an existing RCloud endpoint that can be used?\n", 
          "I think we could just add a restful script, something like `info.R`, so for example `http://rcloud.social/info.R?gist-backend` would return gist.github.com, or something like that.\n"
        ], 
        "number": "2291", 
        "title": "Import by RCloud URL, not repo URL "
      }, 
      {
        "comments": [
          "Strange. I refreshed the page a few times so I could see the abnormal behaviour. Didn't actually see the lack of update time _but_ I did see the absolute time (Mon Oct 3 2016 by shaneporter) and even no items (blank page with menu bar) on a couple of occasions.\n\nI am now seeing _nothing_ on Firefox. No data is coming back. Chrome is OK.\n", 
          "It's harmless, but the API is not yet supported by Firefox. It displays the warning\n\n```\nTypeError: document.registerElement is not a function\n```\n\nin the browser console. And MDN says [This is an experimental technology. The browser you use it in must support Web Components.](https://developer.mozilla.org/en-US/docs/Web/API/Document/registerElement) and links to info for how to enable the feature in Firefox.\n"
        ], 
        "number": "2290", 
        "title": "Discover page fails to show time"
      }, 
      {
        "comments": [
          "I agree that in the long run we want to migrate from knitr to RMarkdown. I'm not sure if there is anything our Markdown cells do that our RMarkdown cells don't. Markdown is probably a little faster because there is less disk access and no external processes. \n\nIt looks like htmlwidgets currently work in RMarkdown cells (only with the `suppress_viewer` hack!?) but this is probably by accident and looks like it's out of order - like maybe we're still intercepting print and diverting the output. \n\nThe RMarkdown support is currently \"experimental\" in the sense that I wrote it for a particular purpose (Mani's rcloud.iip slideshow package), never really tested it to find out what works and what doesn't, but it seemed to work, so we shipped it and and never looked back.\n\nAs we discussed on the call, the real prize here would be to process the intermediate htmltools structures similar to what we're doing for htmlwidgets. If that makes sense, it could be a lot more efficient and we should be able to fix RMarkdown features that aren't working.\n", 
          "First of all, I realized, that we do not need html widget support in markdown/rmarkdown cells for flexdashboard. It is enough to have html widgets support in regular R cells, and we already have that. So I think we can close this issue.\n\n> It looks like htmlwidgets currently work in RMarkdown cells (only with the suppress_viewer hack!?) but this is probably by accident and looks like it's out of order - like maybe we're still intercepting print and diverting the output.\n\nThat is indeed surprising. They did not work for me, I only got a static image (with the wrong size), but maybe I did not have pandoc on the rcloud machine.\n\nMaking rmarkdown cells work with the optimized html widgets code seems really hard to me, so how about I close this issue now and we focus on flexdashboard? \n", 
          "I'd rather keep it open for the future, but sure, it's not something you have to worry about.\n", 
          "OK, sorry. :)\n", 
          "NP. It does seem like the right way to go, for a variety of reasons.\n\nI guess different projects have different ways of managing issues. Because RCloud has such a ridiculous scope we're used to having issues open for years into the future. (One of our milestones used to be called \"when hell freezes over\" but now it's called \"when things get slow\", which is equivalent. ;-)\n\nI'll put this in \"2.0\".\n"
        ], 
        "number": "2284", 
        "title": "Format markdown cells with rmarkdown v2"
      }, 
      {
        "comments": [
          "As in treating it like a **Python** cell?\n\nTo be honest, the use of `source(...)` what more of a hack than intention, unfortunately people started using it as a way to execute R assets in cells -- which on it's own is a good idea.\n\nWe have a dichotomy here - if you run anything but R (Perl, Python, shell, ...) it is a separate process, but R is executed in the cell. Unless we implement every foreseeable cell type, we can't really support in-cell execution.\n\nOne way out would be to add a parameter to `rcloud.execute.asset`, e.g, `in.cell=FALSE` which could default to `NA` meaning \"`TRUE` is the cell type exists, `FALSE` otherwise\".\n\nI'd like to point out that we didn't quite decide what we consider in-cell, either -- in principle we should support `a<-1` in R cell followed by `print a` in a Python cell. It is technically possible and I think in-cell execution would only make sense in that case. Until then I'd argue for keeping things in a separate process.\n"
        ], 
        "number": "2272", 
        "title": "shouldn't rcloud.execute.asset for Python execute within the Python process?"
      }, 
      {
        "comments": [
          "I think we discussed this. Some editors implement Replace All as \"replace to end\" and some implement it as \"replace every single occurrence\". I chose the former (probably because it's what emacs does) but I'm open to arguments for the latter.\n", 
          "But i checked in every editors (eg: Sublime, Notepadd ++, gedit) it replaces all the contents.\n", 
          "Yep, I'm not surprised if Emacs has uncommon behavior here. I'm open to changing it.\n"
        ], 
        "number": "2270", 
        "title": "Replace All, not Replace to End"
      }, 
      {
        "comments": [], 
        "number": "2264", 
        "title": "find/replace matches remain highlighted/replaceable after they no longer match"
      }, 
      {
        "comments": [], 
        "number": "2257", 
        "title": "firefox"
      }, 
      {
        "comments": [], 
        "number": "2244", 
        "title": "Allow rcloud.call.notebook to evaluate notebook in .GlobalEnv"
      }, 
      {
        "comments": [
          "This will probably be fixed by #2504 flexbox layout of panels."
        ], 
        "number": "2241", 
        "title": "Comments div is not getting resized to original state"
      }, 
      {
        "comments": [
          "again, probably #2504 flexbox panels will fix this easily"
        ], 
        "number": "2240", 
        "title": "For comments div, vertical scroll bar doesn't get disable"
      }, 
      {
        "comments": [
          "I'm surprised this isn't simpler. Apparently we've been hard-coding the behavior into our other dialogs; here we don't seem to have anything capturing the keyboard, and wrapping everything in a form and listening for the submit event also doesn't seem to work.\n\nWould probably be better to determine the right way to do this and apply it evenly to all our dialogs.\n"
        ], 
        "number": "2233", 
        "title": "enter key on thumb dialog"
      }, 
      {
        "comments": [
          "This has to do with wrong package versions, but I don't have time to look into it right now. I'll assign to @s-u to determine which packages are out of date on naraj.\n"
        ], 
        "number": "2224", 
        "title": "Error is displayed in session div after executing a cell which consists plot content in it"
      }, 
      {
        "comments": [
          "Ref: #1996 which changed from always-scroll to scroll-when-close to end. It's enough more complicated here that I'm putting it off, though.\n", 
          "Maybe it should depend on what has the focus?", 
          "Now I forget why I thought this was more complicated than the error pane, or why it should depend on the focus. I think we should try it the same way as #1996."
        ], 
        "number": "2222", 
        "title": "autoscroll output in the notebook pane"
      }, 
      {
        "comments": [
          "What I'm seeing is that the keyboard focus can be on a lot of elements that don't invoke help but which don't seem to need the keyboard themselves.\n\nSo I have to click on the notebook background or on a panel header in order for Help to work.\n\nIs this what you mean?\n", 
          "@gordonwoodhull, Yes we need to click on background to invoke it\n", 
          "Well, there still may be cases, but if I disable the textarea associated with the asset editor, it seems to fix this case, so.\n", 
          "still it is reproducible on the latest commit e0db7a2\n", 
          "Okay, that's not surprising, there will always be things grabbing the focus.\n\nThanks @Prateek032!\n"
        ], 
        "number": "2218", 
        "title": "Global shortcuts not available because something has grabbed focus"
      }, 
      {
        "comments": [
          "As noted in #2213, I think this is related to the recently-used menu that is left behind when the dialog closes.\n", 
          "Seems this didn't have to do with the recents menu, as #2251 didn't fix it.\n", 
          "As some point in the past, I _could_ reproduce this issue, but am no longer able to do so using the 'steps to reproduce' at the top.\n", 
          "@shaneporter , even am not able to reproduce this issue, working fine for above mentioned steps.\n"
        ], 
        "number": "2214", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "My system resolution is 1366 x 672\n", 
          "Thanks @amithrb!  I think it only looks trimmed but it's the usual problem of a div (in this case an iframe) spilling out because the height is not getting reflected correctly by the panel.\n"
        ], 
        "number": "2212", 
        "title": "Firefox"
      }, 
      {
        "comments": [], 
        "number": "2203", 
        "title": "get notebook ID without opening the notebook"
      }, 
      {
        "comments": [
          "Thanks @Prateek032. Once again, I can't repro - I bet you won't see this on rcloud-5 or rcloud.social either, and it's another International GitHub Latency problem.\n"
        ], 
        "number": "2196", 
        "title": "Epoch time is showing in Discover page"
      }, 
      {
        "comments": [], 
        "number": "2193", 
        "title": "wrong error when session expired on discover page"
      }, 
      {
        "comments": [
          "Good to hear that it's addictive.\n\nIf you could 'see' the data behind the popularity (forks and stars), would you see it updating quite frequently?\n\nWe wouldn't want to reorder automatically, but we could look at doing something else. :pensive:\n", 
          "I'm not sure if the popularity changes fast enough to see many changes - we'd have to scale up a bit to see those kind of trends. But the Recent Notebooks tab on our internal instance is showing a full page of notebooks that have been edited in the past hour, and a couple more pages for the past day. \n\nIt's really neat to see at a glance who the active users are, and what they're working on.\n\nSo you think that reordering would be too disruptive? Maybe if it were opt-in, under a Follow checkbox/querystring? More like something you'd want to see on a display wall than to actually navigate.\n", 
          "Ah OK, sorry, missed that somehow the first time around, but actually, I think it would be good if, as you suggest:\n- the user can toggle the auto-reorder feature.\n- if the reordering is disruptive, there is a notification that it is about to update.\n\nBut that might work quite nicely, don't you think?\n", 
          "In fact, I'm sure there's a lot more we can do with the design on the discover page, that extends beyond a grid of notebooks.\n"
        ], 
        "number": "2187", 
        "title": "discover page could refresh itself periodically?"
      }, 
      {
        "comments": [
          "+1 happens on clean docker build too. Exception seems to be arising on the python side :(\n"
        ], 
        "number": "2177", 
        "title": "Error after executing Python cell"
      }, 
      {
        "comments": [
          "I can see how this would be helpful. \n\nPlease note that in the current implementation, these notebooks will not be available to view anonymously - the encryption depends on logging in. \n\nIOW, currently if you can run the notebook you can view the code.\n", 
          "I apologize, @mstair, we did not get to this in release 1.7.\n\nIt should be pretty easy to set a default encryption group. What's trickier is adding users automatically to that group. Currently we don't do user management ourselves - if a user has a Unix login and a GitHub login which correspond to the RCloud instance, they can log in.  So we don't even detect when a new user shows up.\n\nSomething that's even trickier is that an encryption group is currently owned by a particular user, and that user needs to be logged in in order for the credentials to be present to change the encryption group. This other kind of group would have to be owned by the RCloud instance in a secure way, and I'm not sure how to do that.\n", 
          "@gordonwoodhull completely understood and now that I have a better understanding of RCloud internals and account management, this request may be out of scope.\n"
        ], 
        "number": "2146", 
        "title": "Support notebook protection enabled globally for an instance as default"
      }, 
      {
        "comments": [
          "My concern is that this screws up the set of installed packages and makes it impossible to upgrade them automatically at the system level - one has to go in and clean out nobody's library every once in a while.\n"
        ], 
        "number": "2142", 
        "title": "ban installing packages anonymously"
      }, 
      {
        "comments": [
          "It doesn't have to be fancy or have history. It just has to be a blue comment balloon in the same color as the dialog.\n", 
          "The design problem here is that the MOTD feature is implemented as a script which is not part of RCloud - it's quoted in #91. So if I added this I'd want to bring that script in and canonicalize it. Hmm.\n"
        ], 
        "number": "2135", 
        "title": "See old MOTDs"
      }, 
      {
        "comments": [
          "maybe a menu choice on the upper right \"About\" that could pop open some messages about github, rcloud.social, benevolent dictator(s) and then whatever attributions as a clickable link \n"
        ], 
        "number": "2134", 
        "title": "ace BSD attribution"
      }, 
      {
        "comments": [], 
        "number": "2114", 
        "title": "why does protection controller timeout instead of continuing?"
      }, 
      {
        "comments": [
          "Specifically, they cycle once and once focus leaves the dialog for the location bar, it never comes back. @shaneporter, please see if there is a bootstrap feature for this. If not, we can delay fixing this.\n", 
          "Had a quick look and there doesn't seem to be a built-in feature to resolve this issue.\n\nIn fact, [the issue is known](https://github.com/angular-ui/bootstrap/issues/738). \n\n[Some solutions have been proposed](http://stackoverflow.com/questions/14572084/keep-tabbing-within-modal-pane-only), but given the time until the next release, and some nervousness to make changes to key-bindings, perhaps we should delay.\n", 
          "Meh. Okay. The dialogs will be mouse-driven for the near future. Thanks!\n"
        ], 
        "number": "2093", 
        "title": "Import/Ok/ cancel options are not getting focused using <Tab> key"
      }, 
      {
        "comments": [
          "Thanks @amithrb!\n\nThe second scenario is #2089. I'm going to put the external notebooks one off since importing no notebooks does nothing, so it's harmless.\n"
        ], 
        "number": "2091", 
        "title": "Import button should be disabled"
      }, 
      {
        "comments": [], 
        "number": "2076", 
        "title": "edit all user options"
      }, 
      {
        "comments": [
          "There is a larger concurrency problem and it might be better to set a lock on all commands that replace the session. But that's work.\n", 
          "I'm currently seeing some other bug where undo fails the first time and then is disabled forever. Investigating.\n", 
          "The case was where there is no previous version. The command gets disabled and never reenabled.\n\nSo I'm moving the disable into the has-previous check, and while I'm at it, I'm also trying using [`Promise.finally`](http://bluebirdjs.com/docs/api/finally.html) instead of `Promise.then` to see if it fixes this issue.\n\nEDIT: Could not repro this issue, keeping `.finally` because it is more correct. Fixed the no previous/next version problem.\n"
        ], 
        "number": "2068", 
        "title": "undo/redo get permanently disabled after please wait of heck"
      }, 
      {
        "comments": [
          "Confirmed. This is a weird one since why would the server crash on Firefox only. \n\nWhen I tried reloading and forking again, I got an error about \"bytecode version is too old\" a few times. Inside of `logical(1)` (sorry, can't repro to get the full error trace). \n\nAlso I do not see it on rcloud-5.\n\nSo I wonder if there might be an R version problem here.\n", 
          "\"bytecode version is too old\" means indeed that you have stale packages. You must re-install all packages when you change the R version.\n", 
          "I didn't upgrade my R. Can this result from packages warning that they were compiled for the wrong version of R?\n", 
          "Nope, I don't think this has to do with package versions. I am able to repro on two OSX instances, and I am not seeing the bytecode error - that was a red herring.\n\nHowever, I still not have repro'd on any of our Linux servers.\n"
        ], 
        "number": "2062", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "Sorry for the very slow response, @pavopax!\n\nI don't see the disconnection error, but I am getting a similar result.\n\nThis notebook, with the content above, simply won't load:\n\nhttps://rcloud.social/edit.html?notebook=e67b897acc7b0daa52a65177c2d74f86\n\nthe load_notebook call [here](https://github.com/att/rcloud/blob/37389c03e60a046e04254d686e02880bd1542b0e/htdocs/js/notebook/notebook_controller.js#L43) simply does not return.\n\nIf I delete the cell, it's okay. The notebook also loads on a few other instances of RCloud running the newer version, so maybe this somehow got fixed. But I find this very hard to explain - that's some clever syntax, but not _that_ clever. And this is without even running the notebook.\n"
        ], 
        "number": "2050", 
        "title": "`x %>% summary` breaks"
      }, 
      {
        "comments": [
          "We don't support running the server on Windows. (R in windows does not have a proper fork function IIRC.)\n\nWe will endeavor to add OSX install instructions, although they are only slightly different.\n", 
          "For this release, we hope to provide a DMG installer and Docker image. \n\nUnfortunately, due to the huge number of dependencies, installing RCloud is never a simple task, especially if anything has been installed previously. We do hope to improve the install docs in the future, but for the purpose of trying RCloud out locally, DMG or Docker is probably the best way to go.\n"
        ], 
        "number": "2049", 
        "title": "Mac OSX installation instructions?"
      }, 
      {
        "comments": [
          "This is a question for our roving R expert @s-u.\n"
        ], 
        "number": "2017", 
        "title": "rcs.list(list=TRUE) ?"
      }, 
      {
        "comments": [], 
        "number": "2012", 
        "title": "dialogs are slow to open when the notebook has a lot of output"
      }, 
      {
        "comments": [
          "I tested this. It was slow but not as slow as we saw on the call.\n\nThis is definitely not the only automated test that is failing; it's just the first one. \n\nMy feeling is that we have to revisit the use of timeouts in the automated tests. It seems essentially unstable, especially when we don't control the (virtual) hardware our tests run on.\n"
        ], 
        "number": "2009", 
        "title": "It takes longer for a cell to get in editable mode"
      }, 
      {
        "comments": [
          "Hi @tonijung! Thanks for the suggestion.\n\nI doubt that we are going to support .Rnw, since our primary output is HTML and AFAICT PDF is the only output for .Rnw. It's hard for me to imagine what a cell would do if its output is PDF - would it produce little PDF fragments for each cell? \n\nWe do, however, support RMarkdown (.Rmd), and outputting from there to PDF is pretty simple (although we don't yet have a built-in command to build the whole document #1320). I realize that the formatting in Markdown is not nearly as sophisticated as in LaTeX.\n"
        ], 
        "number": "1981", 
        "title": "R, Knitr, and LaTeX to generate PDFs"
      }, 
      {
        "comments": [
          "I'm not able to reproduce in Chrome/OSX, Firefox/OSX, or Firefox/Linux. This seems strange to me because the code special-cases for many inputs but not `select`s:\n\n``` js\n            if((d.tagName.toUpperCase() === 'INPUT' &&\n                (d.type.toUpperCase() === 'TEXT' || d.type.toUpperCase() === 'PASSWORD' ||\n                 d.type.toUpperCase() === 'FILE' || d.type.toUpperCase() === 'EMAIL' )) ||\n               d.tagName.toUpperCase() === 'TEXTAREA' ||\n               d.isContentEditable) {\n                doPrevent = d.readOnly || d.disabled;\n            }\n            else {\n                doPrevent = true;\n            }\n```\n"
        ], 
        "number": "1959", 
        "title": "Backspace key loads previous page "
      }, 
      {
        "comments": [
          "It's ok on Firefox 45.0.1, Ubuntu:\n\n![image](https://cloud.githubusercontent.com/assets/2493614/15039432/0861791e-12a5-11e6-8da5-51c237cd55c9.png)\n\nI'll upgrade and take a look.\n\n**Update:**  Yep, Firefox 46 checkboxes are massive.\n", 
          "I have looked at Firefox 46 checkboxes on Windows, and they are 'normal'. Unable to check on Mac, but regardless of that platform's rendering, we have an issue.\n\nI can't think of an alternative to styling checkboxes across platforms/browsers.\n\nIt seems all styling/JavaScript solutions require a particular structure of label and input (there are 2 alternatives as I recall.) I'd have to go through and verify that all are using a particular structure, because if not, they will not be visible.\n", 
          "Weird, why would they make them so large on one platform only? Of course it is okay in Firefox 46 on OSX.\n\nWe always do `<label><input ...></input> Label text</label>`, or I think we always do. That allows you to click on the text to invoke the checkbox. \n\nThere's probably a trivial CSS trick we can do - but if not, I think we can safely chalk this up as a browser bug.\n", 
          "Yes, as far as I can see, it's a browser issue, since it's not reproducible on other OSs or previous versions of Firefox on Ubuntu.\n", 
          "This happens also on Chrome and Safari on iOS. \n![image](https://cloud.githubusercontent.com/assets/1366709/15365372/fecf6052-1ced-11e6-9baf-ebfec8be43a8.jpeg)\n", 
          "Oh dear.\n"
        ], 
        "number": "1957", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "Thanks @Prateek032! This seems like more of a browser bug (we don't create or request the suggestions drop-down) but it's still good to know about. Maybe we should be hiding our controls a different way.\n", 
          "I'm unable to repro on OSX simply because there is no suggestions dropdown.\n"
        ], 
        "number": "1954", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "Weird, no idea why this would go into a loop. Pretty rare case, though, delaying.\n"
        ], 
        "number": "1953", 
        "title": "Previous notebook fails to load in first try"
      }, 
      {
        "comments": [
          "@s-u, this doesn't cover the full functionality of a command prompt. \n\nI've been doing a lot of testing of server-side code recently, and I often find myself wanting to go back to an old command, edit it, and execute it as a new cell, preserving the old cell and output.\n\nWith a command prompt with history, this is easy. But if you're going up to an old cell in order to edit it, you have to go through contortions to preserve that old cell while you execute a new version of that code. \n\nI even found myself doing edit, cmd-enter to execute, and then ctrl-Z in the cell to restore it. Which is crazy.\n\nI think a duplicate cell command could help, but I wonder if there is something even \"faster\" we could do.\n\nThoughts?\n", 
          "IMO the thing that would feel most like a command prompt is a \"revert cell and execute as new cell\" command but that is just bizarre.\n", 
          "I thought that's exactly what <Alt><Enter> does (on macOS) or am I missing something?\n", 
          "`<Alt><Enter>`\n", 
          "(Oh, GH on mobile is utterly broken - I'll fix it when I get in)\n", 
          "(It's just hard to type backticks on a mobile device - fixed.)\n\n<kbd>alt enter</kbd> saves and executes the current cell. I want to preserve the old content and output and create a new cell with an altered version of the content. If I go back and edit the old cell and press <kbd>cmd enter</kbd> I get two of the new content. Either way the old content is lost.\n"
        ], 
        "number": "1950", 
        "title": "\"extra cell\" when no command prompt"
      }, 
      {
        "comments": [], 
        "number": "1948", 
        "title": "shortcuts dialog is under a scrollbar, chrome/osx"
      }, 
      {
        "comments": [
          "@s-u has requested the function parameters before, that should be easy. We couldn't decide where to put this; the R GUI put it in the status bar, which we don't have. \n\nUsing the completion select as shown above is a possibility, but perhaps some effort. (Up till now we've been leaning on Ace's implementation.)\n"
        ], 
        "number": "1943", 
        "title": "show function parameters and maybe documentation while typing"
      }, 
      {
        "comments": [
          "I really have no idea. Perhaps it should be an error, but a more helpful error like \"execution of language X not supported\". Hesitating to assign you @s-u, but you wrote the list of case here.\n"
        ], 
        "number": "1939", 
        "title": "What is the expected behavior for execution of markdown asset?"
      }, 
      {
        "comments": [
          "I have found out how to reproduce the non-working code completion in cells too. I'll wait until I have a solution before I explain further. :)\n", 
          "(Not a solution, but hopefully a step in the right direction.)\n\nThe starting content for `scratch.R` is:\n\n``` R\n# keep snippets here while working with your notebook's cells\n```\n\nit's the **'** that messes up the autocomplete. Remove that, and you're fine. As I mentioned, this is also reproducible in any of the cells. It can also be messed up with a **\"** character.  \n\nDigging deeper, it seems to be ok if that character is _after_ the code, or if there is 'stuff' between the offending character and the code.\n\nI'm looking at you `rcloud.get.completions` in `rcloud.support.R`.\n\nOver to you @gordonwoodhull?\n", 
          "Mrrrr. Good detective work @shaneporter. For expediency, we're sending the entire code over to R for completion, but it is probably expecting a single line of code. Weird that it would parse a quote character inside a comment, but hey chances are it's not even using the standard R parser.\n\nWe could always manually strip comments from the code, but that's annoying.\n\nI'm going to [pass the buck](https://en.wikipedia.org/wiki/Buck_passing) to @s-u since he knows R internals best.\n"
        ], 
        "number": "1938", 
        "title": "Code Completion doesn't work for the first time in Asset div"
      }, 
      {
        "comments": [
          "I have not been able to repro this, and @sanketd11 said this was only on one particular machine.\n\nLet's keep an eye out for this.\n", 
          "FWIW, neither was I, but yeah, I'll keep an eye out.\n"
        ], 
        "number": "1927", 
        "title": "Cell Crop/Delete options get misaligned when Find/Replace is invoked"
      }, 
      {
        "comments": [], 
        "number": "1915", 
        "title": "display shortcut keys in tooltips"
      }, 
      {
        "comments": [
          "Yuck, I guess this means we start another z-index war - recent menu 1000?\n"
        ], 
        "number": "1907", 
        "title": "Zoom in/out button overlaps with 'Recent' notebook panel"
      }, 
      {
        "comments": [], 
        "number": "1902", 
        "title": "URL to notebook folder "
      }, 
      {
        "comments": [
          "Thanks @Prateek032, are you still able to reproduce this? Looks like it is trying to send the binary asset to SOLR, is that the case? Or does it happen in other cases also?\n", 
          "yes its reproducible only if we stop the SOLR \n"
        ], 
        "number": "1892", 
        "title": "Error"
      }, 
      {
        "comments": [], 
        "number": "1884", 
        "title": "RCloud walkthrough"
      }, 
      {
        "comments": [
          "'ctrl a' seems like a nice shortcut to select all the cells (and by select, I mean as if the user checked each 'select' checkbox'), but any copying of those cells' text with a subsequent 'copy' action isn't at all obvious to me. If anything, the existing action makes sense.\n", 
          "Would it make sense if you could also paste cells? \ud83d\ude1c \n\nGiven that Copy currently does nothing if nothing is selected, I think copying the code of the cells only if there is no text selection would be safe. Say you wanted to copy and paste a few cells into RStudio. But I'm not clear if it should copy both the code and results in that case.\n\nSo yeah, let's leave the cell copying part to simmer, and just do select-all for now.\n"
        ], 
        "number": "1879", 
        "title": "cell-based select-all and copy"
      }, 
      {
        "comments": [
          "Thanks for reporting this @sanketd11!\n\nI don't regard this as all that important, but yes it is a bug.\n"
        ], 
        "number": "1877", 
        "title": "both parts of split selected cell should be selected"
      }, 
      {
        "comments": [], 
        "number": "1872", 
        "title": "coalesce selected? on selection bar?"
      }, 
      {
        "comments": [], 
        "number": "1869", 
        "title": "Session div error for cell language change"
      }, 
      {
        "comments": [], 
        "number": "1858", 
        "title": "return files from RCloud.UI.upload_with_alerts"
      }, 
      {
        "comments": [
          "I commented in e22ff3d3456:\n\n> trailing whitespace\n> (if i care so much about this, i probably need a linting commit hook)\n> (do i care so much about this? apparently.)\n\n@shaneporter replied\n\n> Or grunt-contrib-jshint?\n\nExactly. For dc.js we have a `grunt lint` command which runs jscs and jshint, and we install a pre-commit hook which lints and also forbids checking in merge conflicts.\n\nhttps://github.com/dc-js/dc.js/tree/develop/scripts\n\nWe can copy this config out of dc.js but I want to make the rules less strict.\n\nAlso the script can't deal with `git mv` (tries to check the deleted file for merge conflicts) and that has to be fixed.\n", 
          "I'm _fairly_ sure (:wink:) that introducing any (useful) level of linting will initially cause a lot of failures.\n\nAs well as the things you mention, I particularly like being told about undeclared or unused variables.\n", 
          "Actually the code is fairly sane, but yeah it's still some work. I have jshint highlighting in my emacs and I've occasionally run it over most of the source. \n\nWith default options (no whitespace stuff) jshint detects 69 errors in our base javascript, try\n\n``` bash\njshint `ls htdocs/*.js htdocs/js/*.js htdocs/js/notebook/*.js htdocs/js/ui/*.js | grep -v \"bundle\\|worker\"`\n```\n"
        ], 
        "number": "1855", 
        "title": "lint our JS sources and impose (lax) style guidelines"
      }, 
      {
        "comments": [], 
        "number": "1851", 
        "title": "'Index' link is broken in the help feature"
      }, 
      {
        "comments": [], 
        "number": "1836", 
        "title": "search paging stops working when the search term is removed"
      }, 
      {
        "comments": [], 
        "number": "1816", 
        "title": "Python waiting for CR"
      }, 
      {
        "comments": [
          "There are some technical problems with renaming a notebook while forking it. We seem to run into GitHub concurrency issues and it doesn't know about a gist it just told us about.\n\nIf we are willing to lose the history, then we can do the prefix and fix #703/#1643 duplicated fork names, and #1715 unable to fork another user's notebook twice, at the same time. \n", 
          "But that's not the real question, I guess. \n\nA more fundamental question is, does the forked notebook still belong to the original author in some way? I had always thought that once it is forked it is no different from any of your own notebooks, but apparently this is not so.\n", 
          "I see, I didn't know about the technical issue.\n\nAs for becoming your own - yes, that's true, but it still has the information that it's a fork so it is distinguishable.\n\nAs far as interaction goes, it is your own. But the problem I'm running into is that I have no  control over the name at fork time, so it gets filed somewhere in the tree that may not be anywhere close to the nomenclature I use for my own notebooks - you just inherit the path that the author gave it. You may say that I should simply rename it, but too often one just forks a notebook to change a line to see the result, so renaming it is the last thing on one's mind ... until you try to find it again and can't since it's not filed anywhere that you would expect it.\n", 
          "Yes, that is very messy, I agree. I also end up with some very long \"limbs\" in my notebook tree from forking deeply nested notebooks. I guess I would expect them to land in my root folder, but that's a special case of specifying the prefix.\n\nWell, it kind of looks like we are moving toward ditching GitHub forks entirely, because of all the other problems, so maybe we can address all of these at once.\n"
        ], 
        "number": "1815", 
        "title": "way to organize forked notebooks"
      }, 
      {
        "comments": [
          "This can be reproduced simply by double-clicking play. It will not happen every time, but I can repro more than 50% of the time with a double click (but not a double tap?).\n\nNo errors; this is not #1441 although the user behavior that triggers it is pretty much the same.\n", 
          "I'm also seeing this on running a longish numbers notebook in view.html, which is scary wrong. \n\nJust the autorun that starts on page load, no interaction.\n"
        ], 
        "number": "1813", 
        "title": "no proxy"
      }, 
      {
        "comments": [
          "I guess that this would be fairly straightforward. Are there any general plans to make the comments area better? I'm thinking something that approaches the comments system in github, with avatars, comment time, and markdown write/preview.\n", 
          "It's a good idea. I wonder if it would help adoption of this feature, which is pretty much unused.\n"
        ], 
        "number": "1811", 
        "title": "Enhancement"
      }, 
      {
        "comments": [
          "@shaneporter, I think this may actually be an RCAP bug, leaving the DOM in a weird state when it's done. Please take a look when you return to that work.\n"
        ], 
        "number": "1807", 
        "title": "Div contents overlap with div panels"
      }, 
      {
        "comments": [
          "Actually this is also pretty much the same functionality as \"pull latest version from other user\", which I don't seem to find an issue for right now. \n\nIt's not a #127 full notebook merge, so there is no UI problem to solve.\n"
        ], 
        "number": "1806", 
        "title": "Import File to Version"
      }, 
      {
        "comments": [
          "Check permissions for the tmp folder in /data/rcloud. assuming ur ROOT is /data/rcloud. \n", 
          "Hi @mvklingeren . Did the above give you any insight to the resolution?\n"
        ], 
        "number": "1805", 
        "title": "Running fresh_start.sh as non root?"
      }, 
      {
        "comments": [], 
        "number": "1804", 
        "title": "drag gists to notebook tree"
      }, 
      {
        "comments": [
          "+1\n\nShouldn't the client also attempt to reconnect automatically? Assuming we can detect this situation.\n\nI guess we can start by making it manual and then see if the automatic makes sense.\n", 
          "Sure, automatic would be best, because it would limit the time that something goes wrong (e.g., what if the user tries to send anything while the connection is down?).\n"
        ], 
        "number": "1803", 
        "title": "allow re-connect when connection was lost due to network issues"
      }, 
      {
        "comments": [], 
        "number": "1800", 
        "title": "something between mini.html and view.html"
      }, 
      {
        "comments": [
          "This issue is also replicable on RCloud-2 instance with (hotfix-1.5.2/da25214) \n", 
          "Aah thanks for reminding me. This is a pretty severe bug and we should try to fix it for the point release.\n", 
          "On the call today, I think we narrowed it down to the case where you upload **one binary file and one text file** (!) I don't think that's something we've explicitly tested before.\n\nE.g. uploading one jpeg plus one svg also exhibits the bug.\n", 
          "As reported by QA, I am also unable to reproduce this locally, only on our internal instances. As such, it could have something to do with enterprise github.\n\nAdding another text or binary file before attempting to encrypt, makes encryption succeed. Same with deleting either asset. (Although, see next issue.) Something about the notebook is in a bad state for just the moment after a text file and a binary file are added at the same time.\n\nThis is not a new bug. I guess it is obscure enough for me to say let's put it off.\n"
        ], 
        "number": "1798", 
        "title": "Error, while making Notebook as Private"
      }, 
      {
        "comments": [
          "This can also be reproduced by editing a cell and then navigating to another version and back using the mouse.\n\nThere is a race condition where the notebook is saved when loading the new notebook, but the connection is dropped before the dirty bit can be cleared. So the notebook controller still thinks the notebook needs saving.\n\nIn fact, `shell_tab.js` does not properly wait for any save to complete. Connecting the promises causes #572 WebSocket is already in CLOSING or CLOSED state.\n", 
          "this attempt on `connect-save-promises` branch\n"
        ], 
        "number": "1795", 
        "title": "Error, while Notebook \"Redo (ctrl + y)\""
      }, 
      {
        "comments": [], 
        "number": "1793", 
        "title": "unsaved changes on fork should go to the new notebook"
      }, 
      {
        "comments": [
          "Thanks @Prateek032. This is due to my fix for #1607, a way to get back to the source for markdown cells on readonly notebooks. It should not allow this for unrun cells or for non-markdown cells.\n\nMaybe it should be an entirely different button and not edit at all.\n", 
          "This was bothering me while I was testing out 1.6. The button is strangely illuminated and inviting on a readonly notebook, and does nothing good. \n\nIdea here is to add a flag for markdown-ness using `set_flags`:\nhttps://github.com/att/rcloud/blob/develop/htdocs/js/ui/cell_commands.js#L13\n\nPossibly also a flag for \"has been run\" or \"has results\".\n\nUse `RCloud.language.is_a_markdown` in cell_view.js somewhere to set this flag.\n", 
          "I think the issue is not with hiding the code, but with the tooltip on the button.\n\nIf I'm opening a large notebook, why wouldn't I want to hide some of the cells' code? \n\nIf the tooltip was changed, in readonly mode to 'hide code' or 'show code' (dependent on visibility of the code block), wouldn't that resolve the issue in a better way?\n", 
          "@gordonwoodhull - do you think that my suggestion, above, is practical?\n", 
          "Sigh, maybe that is something people would want to do, but I don't think that's consistent with what we allow anywhere else. Only for Markdown do we ever hide the code, and that is because the code is present in the Markdown output.\n\nThink I'll just put this issue in limbo.\n"
        ], 
        "number": "1790", 
        "title": "Cell edit button is enabled for read only notebook"
      }, 
      {
        "comments": [
          "The problem with that is that markdown cells can have side-effects so you cannot run them out of order without breaking the notebook. However, Marty mentioned that the underlying idea here was to have some kind of README cell at the top.\n\nSo I can think of a couple options:\n- have a special README.md asset which would be shown at the top of the notebook - sort of like README on GH. It would re-render on commit.\n- we already have a \"text\" cell type, so we could add some kind of markdown \"lite\" (I shudder to think - we already have a proliferation of markdown-type cells) which would not allow side-effects. I'm not sure I like it - I guess a `html` cell would be somewhat less controversial as you know there will be no side-effect, but that may be less convenient for the author.\n\nComments welcome ...\n", 
          "I like the idea of a README, that's really what I'm trying to accomplish. \n", 
          "Okay, does this make sense: if there is an asset named README.md, it will get inserted as a special cell after the welcome message. I bet there is some way to ensure that knitr or rmarkdown does not interpret any R code, so we can basically use the existing interpreter with a special flag.\n", 
          "Yes, that makes sense, so you would use knitr with eval=FALSE to render it?\n", 
          "I like, but... I go back and forth about whether I like the asset idea, as that's really a divergence from the norm.\n\nIf sourced from an asset, it needs to be really clear that the contents of the special cell after the welcome message came from the README.md asset.  Maybe it's title could be \"Asset README.md\" or something like that?  \n\nAlso, that special cell shouldn't have any of the cell buttons (split, combine, edit, etc), and shouldn't be grabable/moveable by clicking in the left gutter.  Probably not hard, as all that is similar to when viewing a notebook owned by someone else.\n\nHow can it be made clear to the notebook author that R code won't be run, and why?  Maybe using .html instead of .md (as Simon suggested) would handle the first part.\n\nOn second thought, if the README.md is always executed as the first cell, are side effects still a concern?\n\nI definitely like this idea, but still chewing on it...\n", 
          "Yeah, all that stuff is complicated. Probably worth it, but complicated. \n\nPlus: while you are editing the markdown in the asset, when it autosaves it will update the notebook area. It has to.\n\nIt has to be markdown, because html is not really meant for humans.\n\nI'm thinking, with all the complications Gus mentioned, that autorun cells might actually be easier to understand and to implement. But I don't have a strong opinion, just saying.\n", 
          "This is just my 2 cents, but inserting a special cell after the welcome message if there's a `README.md` asset seems a bit opaque to me. How would a user know this is how it worked? It also makes it difficult to provide any explanation or context.\n\nI like the idea of a README below the welcome message. For new notebooks, a message could be shown below the welcome message:\n\nThis notebook doesn't have a README. [Create one](#).\n\nWhen the link is created, a new 'readme' cell is inserted, with some guidance and explanation to the user. \n\nOptions to edit and remove the readme will also be provided. (Removing will revert to the 'new notebook' state.)\n", 
          "I agree with @shaneporter. Guess I was confusing the mechanism with the UI - I think it should definitely be an asset named README.md but it does make more sense to edit it in place.\n\nReal estate is tight, so we might want to omit the cell header on this special cell, and have just a separator line between the welcome message and the README. But there are still a couple commands, delete and toggle edit, so maybe this isn't possible. It should definitely not be selectable in #658, doesn't need a run indicator or language selector, so most of the purpose of the cell header is not applicable.\n"
        ], 
        "number": "1787", 
        "title": "Execute markdown cells when Notebook is opened"
      }, 
      {
        "comments": [], 
        "number": "1784", 
        "title": "title abbreviation gets messed up by read-only notebooks"
      }, 
      {
        "comments": [
          "I started experimenting with this and some of the cases are not too hard, although it tangles up the initialization promises further.\n\nSpecifically, there are three cases: load a particular notebook, load last accessible notebook, and create new notebook. The first two cases should be okay, although it does mean delaying the update to the tree until there is a tree to update. \n\nInterestingly, the third case does require the notebook tree to be loaded first, because a new notebook has to look at the tree to determine the name of the new notebook. If we had a server-side model of the tree as suggested in #1781, but for now we'd have to handle this case differently, and create new notebooks only after the tree is loaded. \n\nSince loading existing notebooks is the more common case (new notebooks are usually created from an open RCloud page), it's probably okay to only handle those cases.\n", 
          "This is a pretty big refactor, because most of the editor_tab assumes that the notebook tree and the \"notebook registry\" will be loaded before any notebooks are loaded. It's worth doing, but it's not a simple tweak, because there are many cases involved in notebook loading.\n\nIt might make sense to tackle this at the same time as #1781, and really seriously untangle this code all at once.\n", 
          "Interestingly, while the notebook tree still starts loading before the notebook, lazy loading of the tree #1781 now means that the notebook shows up first. This can still be improved, and lazy loading has set the stage to allow loading the notebook even earlier.\n"
        ], 
        "number": "1780", 
        "title": "load notebook before tree?"
      }, 
      {
        "comments": [
          "Currently this is an RStudio-only package.\n\nhttps://cran.r-project.org/web/packages/manipulate/manipulate.pdf\n\n`isAvailable` Check whether manipulate is available\n\n**Description**\nCheck whether manipulate is available in the current front-end environment.\n\n**Usage**\n`isAvailable()`\n\n**Details**\nThe manipulate package works only within the RStudio front-end.\n\n**Value**\n`TRUE` if manipulate is available, otherwise `FALSE`\n"
        ], 
        "number": "1779", 
        "title": "Enable manipulate in RCloud"
      }, 
      {
        "comments": [
          "Hi RCloud team,\n\nI'm the maintainer of swirl and I would like to help get swirl working on RCloud. I did a little experiment and it looks like there might be an issue with how RCloud handles task callbacks. Run the following code in RCloud and on your own R console and observe the difference:\n\n``` r\ntimes <- function(total = 3, str = \"Task a\") {\n  ctr <- 0\n\n  function(expr, value, ok, visible) {\n    ctr <<- ctr + 1\n    cat(str, ctr, \"\\n\")\n    if(ctr == total) {\n      cat(\"handler removing itself\\n\")\n    }\n    return(ctr < total)\n  }\n}\n\n# add the callback that will work for\n# 4 top-level tasks and then remove itself.\nn <- addTaskCallback(times(4))\n\nprint(\"Hello\")\nprint(\"Hello\")\nprint(\"Hello\")\nprint(\"Hello\")\n```\n\nI copied this code straight form the help page of `addTaskCallback()`.\n", 
          "Thanks @seankross, I verified that the task callback is not added (or doesn't function) in RCloud. \n\nOn a quick search I find suggestions that Rserve doesn't implement/handle `addTaskCallback`:\n\nhttp://r.789695.n4.nabble.com/automatically-calling-dev-off-td4711715.html\n", 
          "There are no top-level tasks in RCloud, so for the same reason this has no effect. Top level tasks only work when REPL is used, since it is an internal mechanism in R - so you would not expect (nor want) to call those in RCloud. Could you provide any context here? Task callbacks are often used as a horrible hack when the code doesn't actually use proper input handlers in R, but since I have no idea what it's used for in this context I can't say if you can simply register a cell callback (is that what you would want?)  or whatever other purpose it serves.\n", 
          "Just as a context for those not familiar with the details: When R is used in REPL mode (Run/Evaluate/Print/Loop) it allows user code to inject arbitrary functions into the loop. Those callbacks are called in between the iterations of the loop. However, RCloud doesn't use REPL since that would require R to control the entire process and also would restrict it to purely serial \"console\" mode. Instead, RCloud uses a mode where R is always available for evaluations since you may want to run other things that are not part of the \"console\" (out-of-band cell executions, re-drawing plots, etc.) which mean that inherently the REPL mode makes no sense (we are also not sending raw \"input\" but evaluate cells instead). \n\nAlso cells are executed directly, so there is no separation of individual evaluations. Thus RCloud provides much more flexibility - the application is informed by OOB message on any asynchronous action and can act on many different callbacks. That said, we cannot easily create a compatibility mode to run R top level callbacks in addition to the native methods even if we wanted to have `Rserve_eval` to fire task callback, because R doesn't currently expose `Rf_callToplevelHandlers` as part of the API.\n", 
          "I have added a very, very hacky work-around to `rcloud.social` (see also [Rserve/top-level-handlers](https://github.com/s-u/Rserve/tree/top-level-handlers). It's not perfect, because of several issues - many of them deep inside R (it turns out the R internal code that runs handlers uses the similar facility that we use for running RCloud cells which means we get into recursions which mess up things ...). I'd still prefer if we found an \"official\" way to get swirl to work directly...\n", 
          "thanks Simon.  I was able to work through a few prompts until I got to one that I believe calls omnitest.  Here's the session log from rcloud.social, invoked with \nlibrary(swirl)\nswirl()\n\n| Welcome to swirl!\n\n| Please sign in. If you've been here before, use the same name as you did\n| then. If you are new, call yourself something unique.\n\nWhat shall I call you? mm6769\n\n| Thanks, mm6769. Let's cover a few quick housekeeping items before we begin\n| our first lesson. First of all, you should know that when you see '...', that\n| means you should press Enter when you are done reading and ready to continue.\n...  <-- That's your cue to press Enter to continue\n\n| Also, when you see 'ANSWER:', the R prompt (>), or when you are asked to\n| select from a list, that means it's your turn to enter a response, then press\n| Enter to continue.\n\nSelect 1, 2, or 3 and press Enter \n\n1: Continue.\n2: Proceed.\n3: Let's get going!\n\nSelection: 1\n\n| You can exit swirl and return to the R prompt (>) at any time by pressing the\n| Esc key. If you are already at the prompt, type bye() to exit and save your\n| progress. When you exit properly, you'll see a short message letting you know\n| you've done so.\n\n| When you are at the R prompt (>):\n| -- Typing skip() allows you to skip the current question.\n| -- Typing play() lets you experiment with R on your own; swirl will ignore\n| what you do...\n| -- UNTIL you type nxt() which will regain swirl's attention.\n| -- Typing bye() causes swirl to exit. Your progress will be saved.\n| -- Typing main() returns you to swirl's main menu.\n| -- Typing info() displays these options again.\n\n| Let's get started!\n...\n\n| Please choose a course, or type 0 to exit swirl.\n\n1: R Programming\n2: Take me to the swirl course repository!\n\nSelection: 1\n\n| Please choose a lesson, or type 0 to return to course menu.\n\n 1: Basic Building Blocks      2: Workspace and Files  \n 3: Sequences of Numbers       4: Vectors  \n 5: Missing Values             6: Subsetting Vectors  \n 7: Matrices and Data Frames   8: Logic  \n 9: Functions                 10: lapply and sapply  \n11: vapply and tapply         12: Looking at Data  \n13: Simulation                14: Dates and Times  \n15: Base Graphics             \n\nSelection: 1\n\n  |  \n  |                                                                      |   0%\n\n| In this lesson, we will explore some basic building blocks of the R\n| programming language.\n\n...\n\n  |  \n  |==                                                                    |   3%\n\n| If at any point you'd like more information on a particular topic related to\n| R, you can type help.start() at the prompt, which will open a menu of\n| resources (either within RStudio or your default web browser, depending on\n| your setup). Alternatively, a simple web search often yields the answer\n| you're looking for.\n\n...\n\n  |  \n  |====                                                                  |   5%\n\n| In its simplest form, R can be used as an interactive calculator. Type 5 + 7\n| and press Enter.\n\nWarning: stack imbalance in '.Call', 72 then 73\nWarning: stack imbalance in '<-', 66 then 67\nWarning: stack imbalance in '{', 63 then 64\nWarning: stack imbalance in 'if', 57 then 58\nWarning: stack imbalance in '<-', 55 then 56\nWarning: stack imbalance in '{', 52 then 53\nWarning: stack imbalance in 'if', 46 then 47\nWarning: stack imbalance in '<-', 44 then 45\nWarning: stack imbalance in '{', 41 then 42\nWarning: stack imbalance in '.Call', 38 then 39\nWarning: stack imbalance in '<-', 32 then 33\nWarning: stack imbalance in '{', 29 then 30\n", 
          "Yes, I saw that, too, but I have no idea what swirl is doing at that point so it's over to their side.\n", 
          "I'll take a look. All of these comments are very useful, thanks so much. Just a warning: don't expect an answer or a guess from me today.\n", 
          "Now _that's_ an error!\n", 
          "Note that the imbalance warnings come probably because there is an error raised in the callback itself which blows up things (since we're relying on our error handling which gets scrupulously replaced when R runs the handlers so the whole protection stack gets messed up - R will clean up the mess it caused itself, but grudgingly as you can see ;)). But that's just my theory - the whole top level callback handling is so ugly (it was designed to be run only at C level but then R level was added on top of it which is very fragile). Again, I'd prefer explicit handlers instead of the top level callbacks if at all possible...\n"
        ], 
        "number": "1778", 
        "title": "use of package swirl"
      }, 
      {
        "comments": [], 
        "number": "1775", 
        "title": "Enhancement"
      }, 
      {
        "comments": [], 
        "number": "1774", 
        "title": "Page links overlap with settings div"
      }, 
      {
        "comments": [
          "Ha, I just ran into this and I am somewhat experienced with the interface. \n\nI'm not sure what the solution is, either. I'm not against enabling it for an empty notebook, but that might mislead people who wonder why it doesn't work thereafter.\n"
        ], 
        "number": "1773", 
        "title": "\"Run\" and unsubmitted code"
      }, 
      {
        "comments": [], 
        "number": "1771", 
        "title": "Notebook Permissions/ Group management "
      }, 
      {
        "comments": [
          "My guess is that `q()` will actually delete the R temporary directory so it won't exist afterwards. This will only affect installations without user switching. Note that shell cells are just one of many cases that will break when the temporary directory is gone - a lot of R code and packages rely on the temporary directory.\n", 
          "When setting up a session we should check that the directory exists. R does that check on startup but we should do it again.\n\nNote that this is only borderline a bug - the behavior after running `q()` is undefined. In a single-user setup you can equally simply blow away things from your session and kill anyone's session if you so desire so it's really not advisable to run things that way.\n", 
          "Some more features affected by this issue are -\n- shiny.html\n\n![shiny](https://cloud.githubusercontent.com/assets/9251570/12136593/6e0e43b2-b46f-11e5-93ac-dd7592742c11.PNG)\n\n-help\n\n![help](https://cloud.githubusercontent.com/assets/9251570/12136592/6e0df4e8-b46f-11e5-90b7-c8fa98e15187.PNG)\n", 
          "Yes, like said, this breaks a lot of things in R (nothing to do with RCloud) since a lot of R code relies on the existence of the temporary directory.\n", 
          "Is there some extra initialization we can do for each session? Wouldn't folks usually want a fresh temp directory with each session?\n", 
          "Yes we can and we do when user switching is enabled so that each user has its own temp dir (for permission reasons, really). We don't do that in non-switched setup. Partially, because R doesn't actually support that (there is no official way to set the tempdir in an existing session, because R assumes it has it under control directly). Note that this is R-internal directory and R manages the files there - it's different from the session temporary directory (which is truly session-specific). \n", 
          "Just to clarify this is nothing to do with the system `TEMPDIR` - that's a whole different issue, will fix the title. (BTW I don't expect any comments there - it's one line of code and we have discussed it more than it's worth it ;))\n", 
          "Actually, there is really no good way to fix this. The problem is that even if we guarantee the existence of `tempdir()` at session init, it doesn't help as another session can blow it away at any other point. So I'm inclined to simply override `q()` and document \"don't do it\" since there is no way for us to prevent the user from doing stupid things like that.\n", 
          "My point was why should the sessions share the tempdir when they are separate processes. Seems like it's bound to run into other kinds of collisions. So why not always create a tempdir on session start? Or am I missing something?\n", 
          "Because R is managing that at R start but the server is forking so at the time we get into session code it's already established by R that was started as the server. If we do something ourselves then we have to maintain it (cleanup etc.). If we think this is a problem we'll probably have to do something along the lines of creating a new tree, overriding the R internals to replace the R managed one and then add cleanup. And that won't help if someone just deletes it anyway... so I'm not sure I really want to go deep down that road.\n", 
          "@s-u, didn't you address part of this?\n"
        ], 
        "number": "1770", 
        "title": "q() deletes R tempdir() causing chaos for non-switched RCloud setup"
      }, 
      {
        "comments": [
          "This issue is no longer reproducible.\n", 
          "This is now reproducible only on RCloud-Local instance\n", 
          "I can see how this would happen if compute separation is disabled:\n- `rcloud.update.notebook` has a parameter `is.current` which defaults true. In a brief scan, I couldn't find any call which passes false for this parameter.\n- if this flag is set, it updates the current notebook cache `.session$current.notebook`\n- the current notebook is used basically only for running cells and asset stuff (all compute side)\n- `rcloud.set.notebook.cryptgroup` cleverly uses `rcloud.update.notebook` with an empty changeset to encrypt/decrypt the notebook.\n- none of this matters if the compute and control processes are separate, because the notebook cache won't be affected by the update. (In fact, the notebook cache only helps up until any change to the notebook when compute separation is enabled.)\n\nHowever, I wasn't able to test this because the server hung when I tried to start it with `compute.separation.modes` removed from rcloud.conf.\n\n@Prateek032, please verify that this line is not present in your rcloud.conf.\n", 
          "Although it's still a bug, my proposed solution is:\n1. add `compute.separation.modes` to rcloud.conf.samp - it's a useful feature, well tested, and we want to move away from having an exponential number of configurations in the wild.\n2. sometime deal better with notebook caching. `.session$current.notebook` seems inherently messy to me. I bet we have similar problems with the asset functions, but we just don't notice.\n"
        ], 
        "number": "1769", 
        "title": "Cell output is not visible after making notebook private "
      }, 
      {
        "comments": [], 
        "number": "1768", 
        "title": "Firefox"
      }, 
      {
        "comments": [
          "Do you know of an Ubuntu app that exhibits the issue? \n", 
          "Hmm, I'm not able to repro on Ubuntu and LibreOffice - it looks like they somewhere drop all formatting from text copied from the browser (?)\n\nMy description above was imprecise. The problem is that a lot of formatting does get copied. In the case of the welcome message, the pasted text is invisible. In the case of cells, I get blue and grey bars through the text (here pasted into Mail):\n\n![image](https://cloud.githubusercontent.com/assets/1366709/14614540/a4f0b8a0-056f-11e6-8613-9bea51d99cbb.png)\n\nI expect to see similar results on Windows, which definitely supports rich text copy and paste, but I don't have access today, so I'm labeling this an OSX bug for now.\n", 
          "I am pretty sure the blue bars were not happening before, and the grey bars were omitted because they were entirely `.nonselectable` - but this is very tricky stuff and maybe there is a better way (for example, it might be easier to get it right if we didn't use the selection but only the selected cells, see #1879).\n\nhttps://github.com/att/rcloud/blob/develop/htdocs/js/ui/init.js#L70-L87\n", 
          "So, even worse, I pasted some stuff into a message. It was invisible. Then I pressed backspace and _everything else in the message_ became invisible!\n\n![image](https://cloud.githubusercontent.com/assets/1366709/14862656/64d82f38-0c80-11e6-984c-9554ea196b24.png)\n", 
          "I tried this in 'Outlook Mail' (I still call it Hotmail) and replicated the 'where's my text?' issue. Pasting as plain text into Hotmail works. \n\nTried in various editors and things seem to work ok.\n", 
          "Glad you were able to replicate somewhere. Yes, it's exactly the paste as html or paste as rich text that fails. \n\nSince we are synthesizing the data that gets copied in an off-screen div, we're either adding formatting that makes it invisible, or we're copying it out of the notebook wrong. \n\nProbably some kind of clipboard inspector tool would point out the problem immediately. Last time I looked into it, all the possible formats got copied to the clipboard independently.\n", 
          "Good idea about the clipboard inspector. Here's 'CopyQ' for Ubuntu showing two copied items\n\n![image](https://cloud.githubusercontent.com/assets/2493614/19592959/2407a57a-9776-11e6-9bcf-700f103a5df8.png)\n\nThe top item is a copied selection from RCloud.\n", 
          "ah, that's a beaut \ud83d\ude0f  - does it show the source as well?\n", 
          "Yeah, it's got the HTML (in this case for the two cells it has selected), and when I paste it into jsfiddle, I see the expected output.\n", 
          "Tried reproducing this with no luck, tried various selections, including cells with plots; pasting into Outlook, Outlook webmail and gmail, none exposed issues mentioned in here. However I haven't tried OS X which is the environment in which this happens.\r\n\r\nI noticed however that for some selections (when the last element in the selection is a new-line) chrome adds a 'BR' element with class: 'Apple-interchange-newline', e.g.:\r\n\r\n```\r\n<meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"><pre class=\"response\" style=\"box-sizing: border-box; font-family: Monaco, &quot;DejaVu Sans Mono&quot;, &quot;Droid Sans Mono&quot;, &quot;Lucida Console&quot;, Consolas, monospace; font-size: 13px; white-space: pre-wrap; display: block; padding: 16px; margin: 0px; line-height: 1.42857; color: rgb(51, 51, 51); word-break: break-all; word-wrap: break-word; background-color: rgb(245, 245, 245); border: 0px; border-radius: 0px; max-width: 100%;\">RCloud 1.8-devel (features-issue-2401/d9b30c6), R version 3.2.3 (2015-12-10) <br style=\"box-sizing: border-box;\">Welcome, useless5771</pre><div class=\"notebook-cell\" id=\"part1.R\" style=\"box-sizing: border-box; border-width: 0px; padding: 0px; margin-top: 0em; background-color: white; position: relative; width: 1127px; min-height: 25px;\"><div style=\"box-sizing: border-box;\"><div class=\"source-div\" style=\"box-sizing: border-box; color: rgb(51, 51, 51); font-family: &quot;Helvetica Neue&quot;, Verdana, Helvetica, Arial, sans-serif; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;\"><div class=\"code-div\" style=\"box-sizing: border-box; position: relative; tab-size: 4; display: block;\"><div class=\"rcloud-gutter\" style=\"box-sizing: border-box; background-color: rgb(245, 245, 245); position: absolute; width: 48px; height: 27px; cursor: pointer;\"></div><pre class=\"edit-code inactive\" style=\"box-sizing: border-box; font-family: Monaco, &quot;DejaVu Sans Mono&quot;, &quot;Droid Sans Mono&quot;, &quot;Lucida Console&quot;, Consolas, monospace; font-size: 13px; white-space: pre-wrap; display: block; padding: 0px 0px 2px; margin: 0px; line-height: 1.42857; color: rgb(51, 51, 51); word-break: break-all; word-wrap: break-word; background-color: rgb(238, 243, 247); border: 0px; border-radius: 0px; max-width: 100%; cursor: text;\"><code class=\"r hljs \" style=\"box-sizing: border-box; font-family: Monaco, &quot;DejaVu Sans Mono&quot;, &quot;Droid Sans Mono&quot;, &quot;Lucida Console&quot;, Consolas, monospace; font-size: 11px; padding: 1px 6px 0px 54px; color: inherit; white-space: pre-wrap; background-color: transparent; border-radius: 0px; border: 0px; display: block; max-width: inherit; margin-right: auto; margin-left: 0px; word-break: normal; line-height: 1.1;\"><span class=\"hljs-number\" style=\"box-sizing: border-box; color: mediumblue;\">1</span>+<span class=\"hljs-number\" style=\"box-sizing: border-box; color: mediumblue;\">1</span> \r\n\r\n</code></pre></div></div><div class=\"r-result-div\" style=\"box-sizing: border-box; padding: 16px; color: rgb(51, 51, 51); font-family: &quot;Helvetica Neue&quot;, Verdana, Helvetica, Arial, sans-serif; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;\"><pre style=\"box-sizing: border-box; font-family: Monaco, &quot;DejaVu Sans Mono&quot;, &quot;Droid Sans Mono&quot;, &quot;Lucida Console&quot;, Consolas, monospace; font-size: 12px; white-space: pre-wrap; display: block; padding: 0px; margin: 0px; line-height: 1.42857; color: rgb(51, 51, 51); word-break: break-all; word-wrap: break-word; background-color: white; border: 0px; border-radius: 0px; max-width: 100%; cursor: text;\"><br class=\"Apple-interchange-newline\"> \r\n```\r\n\r\nThis <br> element is added automatically by Chrome, Firefox doesn't do this.\r\n\r\nDifficult to say without actually being able to reproduce that this might be the cause of the formatting issues.\r\n\r\nAnother thing that I noticed is that the 'offscreen' element created by the select_allowed_elements function in Firefox gets included in the copied HTML snippet but in Chrome it isn't.\r\n\r\nI can have a look at select_allowed_elements and possibly delete the trailing br, but would be good to have a confirmation that this 'Apple-interchange-newlline' is what is causing the issue.\r\n\r\n\r\n\r\n\r\n", 
          "Yeah, this is difficult to repro and I guess we need someone with a Mac to look at it. I thought maybe since Shane was able to repro in Outlook that maybe it was a cross-platform issue but I guess that was just a fluke."
        ], 
        "number": "1764", 
        "title": "unwanted formatting in copied text on OSX"
      }, 
      {
        "comments": [], 
        "number": "1763", 
        "title": "cell commands are clipped - firefox/windows"
      }, 
      {
        "comments": [], 
        "number": "1758", 
        "title": "Most stars feature is not working in Discover page"
      }, 
      {
        "comments": [], 
        "number": "1757", 
        "title": "Context output is not visible when executed from asset div"
      }, 
      {
        "comments": [], 
        "number": "1756", 
        "title": "Enhancement"
      }, 
      {
        "comments": [], 
        "number": "1753", 
        "title": "Externally Deleted Notebooks"
      }, 
      {
        "comments": [
          "I vote 'yes', as I feel RCloud should try to support the same functionality regardless of notebook storage backend.\n"
        ], 
        "number": "1752", 
        "title": "gitgist"
      }, 
      {
        "comments": [
          "Thanks @Prateek032 \n\nI bet we're not doing language detection properly in the truncation fix-up.\n"
        ], 
        "number": "1751", 
        "title": "Notebook with Markdown cell contents are being truncated"
      }, 
      {
        "comments": [], 
        "number": "1750", 
        "title": "deferred results in custom output contexts"
      }, 
      {
        "comments": [
          "Duplicate of Issue #1336 ?\n"
        ], 
        "number": "1731", 
        "title": "Output text doesn't get wrapped for Python cell"
      }, 
      {
        "comments": [
          "My gut response is that history should be local to the cell, regardless if prompt cell or code cell.\n\nI'll chew on it some more.\n", 
          "Thanks @holyguster, that was my first thought too. The fact that command-line R gets \"universal\" history is just an artifact of the way it uses Gnu readline. \n\nOne reason it might be helpful to get more history is if you debug two cells in succession. Then you might arrow up to your debug commands on the last cell. But that's probably rare. Getting back your command prompt stuff is probably not useful (and I find it annoying when using command-line R).\n"
        ], 
        "number": "1729", 
        "title": "do pseudo-readline history in input field of context"
      }, 
      {
        "comments": [
          "(motivation is that merging or overwriting artifacts is extremely annoying to developers)\n", 
          "+1\n", 
          "Proposed solution. @s-u, @prateek05, is this acceptable?\n1. make `npm` another prerequisite (currently we only require it if you're [\"hacking on the code\"](https://github.com/att/rcloud/blob/develop/doc/INSTALL.md#will-you-be-hacking-on-the-code-read-on) but since we require `R` and a few other things, seems reasonable enough to require node.\n2. [de](https://github.com/att/rcloud/blob/develop/htdocs/js/package.json)-[duplicate](https://github.com/att/rcloud/blob/develop/htdocs/lib/package.json) `package.json`, move it to root, and make it somewhat descriptive of RCloud (even though we still won't actually publish RCloud to npm, of course)\n3. do `npm install` in root directory when `bootstrapR.sh` is run\n4. add a dependency to a plain javascript parser like acorn or esprima, for validation with decent error messages\n5. validate before uglifying, pointing to root directory's `node_modules`\n6. consider disabling uglify.\n", 
          "I'm somewhat hesitant making `nodejs` + `npm` a requirement for everyone since it's not directly available, e.g. on OS X. I think we should really keep the distinction of hacking on it - where it's ok to require a lot more and work off the bare git checkout - and installing it which doesn't need either. So if we just provide automated tar balls (like we do for packages on RForge.net) which contain the artifacts then I think it would be ok.\n", 
          "Ah - so you're suggesting distributing through RForge rather than GitHub?\n", 
          "I don't think GH has a way to build distribution tar balls (since you don't have a VM to install things on). I didn't check, though, if there is a way to \"push\" distribution tar balls that have been built elsewhere - if it does, then we could do that, otherwise either our RCloud website or RForge.net would be ok ...\n", 
          "Okay, now I've lost interest because this is stuff I don't now how to do.\n", 
          "I think we already have what need - just pack up the result after `build.sh` ...\n", 
          "GitHub **does** have a way to push distribution tar balls - it's called GitHub Releases. \n\nhttps://help.github.com/articles/creating-releases/\n\nBasically each tag is automatically a Release and then you have the option to annotate it further with release notes and binaries.\n\nSo I think all we would need is a script that runs build.sh and then includes what we want to include in a tarball.\n", 
          "I guess what I was looking for was\n\nhttps://developer.github.com/v3/repos/releases/#upload-a-release-asset\n\nso we need script that packs up the release and then pushes the asset for it. That makes sense - I may tackle this anyway for RForge.net to push package tar balls as the GH automated way is only wreaking havoc.\n", 
          "Ah yes, even better if it's automated!\n", 
          "Assigning to @s-u for creating a script to pack up the right resources, delaying to next release so that we have a release cycle to deal with consequences if any.\n", 
          "@s-u, Is this the same thing we need in order to host rcloud.support on RForge so that packages that depend on it like rcleaflet can be built?\n", 
          "Maybe in 2.0 :laughing: "
        ], 
        "number": "1728", 
        "title": "delete artifacts?"
      }, 
      {
        "comments": [
          "This is as expected, but it does need to be documented.\n", 
          "This is actually interesting. Certainly the original design was to not have any side-effects. However, it would be debatable if we would want to enable console-like behavior when a context is created - it is technically doable and may actually make sense ....\n"
        ], 
        "number": "1721", 
        "title": "Print() needs to be used explicitly to print output of any R code in Mini.html (output context feature)"
      }, 
      {
        "comments": [
          "`rcloud.get.notebook` currently has parameters `id, version, source, raw`, and `raw` doesn't distinguish between binary asset decoding and notebook decryption.\n\nFor this to work right we need decryption but not binary asset decoding, and this is actually not trivial: when we encrypt notebooks we do not separately encode the binary files! So we would actually have to decrypt and then _en_code any binary files...\n\nhttps://github.com/att/rcloud/blob/develop/rcloud.support/R/binary.R#L73\n\nAlso, we should probably warn the user that they are losing encryption by exporting to file.\n\nThe workaround, not a happy one, is to set the notebook public before exporting. Let's try to fix this for 1.6.\n"
        ], 
        "number": "1718", 
        "title": "encrypted notebook should be decrypted"
      }, 
      {
        "comments": [
          "Thanks for reporting this, @Prateek032. \n\nThis is a known issue, again due to Github's policy of only forking once. You in fact receive the same deleted notebook, which has not actually been deleted from Github, but only removed from the RCloud catalog.\n\nThe workaround when this happens is to Open in Github the notebook, delete it there, and then fork the other user's notebook again.\n\nWe are open to suggestions how to make this easier. It is our own policy not to truly delete notebooks, because there may still exist links to them and we generally don't want to lose code.\n", 
          "This is worse that I expected - it essentially makes collaboration hard since you can't follow changes someone else is making. The only way to work around it would be to use our own metadata just as we do for `gitgist` an create a new notebook with overriding `forkof` information.\n\nGiven how much we're working around limitations in GH, I'm really inclined to ditch it and invest in the server on top of `gitgist` instead.\n", 
          "Yes. It means ditching the notebook history, but I guess we're forced to do it.\n", 
          "Yes, in the case of forking the history is less of an issue, since it still exists in the notebook that was forked and you have a direct link to it.\n", 
          "BTW: we should also consider having a true \"delete\" such that deleting a notebook actually deletes it - including on GH. We could make it an option for now and change the default later.\n", 
          "If you combine shallow forking with true deletion, history really will be lost.\n", 
          "We could limit the deletion to non-forked notebooks. Essentially the context in which the deletion came up was that our GH is filling up with a lot of garbage (one-line test notebooks and such) that will show its ugly face if we ever have to restore notebook metadata from GH. That's low priority but something to keep in mind.\n", 
          "Maybe for 1.6 it would be a good idea to warn the user that this is what is happening and provide instructions to delete from GitHub if they want a fresh fork?\n", 
          "Added a warning/explanation for 1.6.\n", 
          "Another workaround is to import the notebook instead of forking it. Use Advanced / Import External Notebooks. Specify the same Github server that your instance is using, and the notebook id. It will be copied instead of forked.\n"
        ], 
        "number": "1715", 
        "title": "Forking doesn't create a new copy of the notebook"
      }, 
      {
        "comments": [], 
        "number": "1714", 
        "title": "reentrant calls to R from JS"
      }, 
      {
        "comments": [
          "A couple of libraries in this space:\n\nhttps://github.com/Mikhus/jsurl (just the parsing part, no history manipulation)\n\nhttps://github.com/ryanburnette/Qurl (with history support)\n\n(we might need tighter control over history than qurl offers; see https://github.com/att/rcloud.params/issues/1)\n", 
          "Related: when a notebook is opened via `?user=...&path=...`, we shouldn't rewrite that with the hash, if possible."
        ], 
        "number": "1713", 
        "title": "don't rewrite parts of url that don't concern rcloud"
      }, 
      {
        "comments": [
          "this would help #1710 fail faster\n", 
          "maybe make configurable?"
        ], 
        "number": "1712", 
        "title": "consider shortening requirejs timeout"
      }, 
      {
        "comments": [
          "We could add some kind of `rcloud.install.package` where you could specify in more detail if you want to install it privately (the default now), for all users or for a notebook. The latter is a bit tricky, because it would break when you fork a notebook. Analogously, we could introduce `rcloud.require` which is a bit smarter about looking up packages in the context of notebooks (including fork-of), users etc..\n\nNote, however, that in general users may not be able install packages, since DLs may not include dev tools etc.\n"
        ], 
        "number": "1708", 
        "title": "Install package for notebook?"
      }, 
      {
        "comments": [
          "The \"forked only once\" behavior is not desired behavior: it's just a limitation forced on us by GitHub.\n\nCurrently the notebook numbering behavior is implemented client-side, and only for cases where we are copying instead of truly forking. If we want to support numbering for these cases, we'll have to reimplement it server-side (which is kind of a PITA because the server doesn't know anything about the notebook tree).\n"
        ], 
        "number": "1700", 
        "title": "Forking a folder of foreign data lake creates multiple copies of notebooks "
      }, 
      {
        "comments": [
          "Drat, this is one of those continuation/promise conversion thingies, `fatal_dialog` takes a continuation and needs to return a promise, and I can't wrap my head around it atm.\n"
        ], 
        "number": "1694", 
        "title": "notebooks continue to load in background when history notebooks bad"
      }, 
      {
        "comments": [
          "I'm unable to repro, I get the expected markdown output the first time.\n\n![image](https://cloud.githubusercontent.com/assets/1366709/10264316/bf2c8a40-69d5-11e5-917a-b9a181117de3.png)\n", 
          "Please clarify.\n", 
          "not able to repro, once again. we have got to be missing some step.\n", 
          "You know, I bet this is a concurrency issue because: \n1. it happens intermittently\n2. it is the same symptom as when running a cell that doesn't exist: no content, thus no output. like when the compute process cache of the notebook wasn't getting updated.\n", 
          "@Prateek032, @sanketd11, I still have never reproduced this. \n\nI know you showed me on the call, but could you please add some more detail, e.g. have you ever seen this on a Research instance? are there surrounding cells that affect this? Thanks.\n", 
          "This is on local instance. I was able to reproduce this even with the single cell while switching between other cell languages to markdown cell . \n", 
          "I wonder if there is greater latency committing changes from India. There are some cases where GitHub does not completely commit a change: even though we wait for a result and observe the correct change, the next request does not observe that change. (This would also be helped by compute reading the notebook from control.)\n\nCan you reproduce it if you wait a couple seconds between changing the type and clicking Run All?\n", 
          "I was able to reproduce this consistently only when i change the cell language and executed in quick succession. When i waited for couple of seconds before executing, it worked as expected \n", 
          "Thanks @Prateek032, I'm going to blame GitHub then. This should be fixed by reading the canonical version of the notebook from the control process - which holds onto the correct result of the commit rather than rereading the notebook.\n"
        ], 
        "number": "1686", 
        "title": "Cell output is not visible after changing the cell language"
      }, 
      {
        "comments": [
          "R doesn't allow cancellation of locator by interrupt - that is true for other R GUIs as well. The only way to cancel a locator is to press `<ESC>`. Since the UI knows about the modal state of a locator, it could (and probably should) map \"Stop\" to the locator cancellation.\n", 
          "Yes - eventually. We should deal with this at the same time we deal with input cancellation #1196.\n"
        ], 
        "number": "1685", 
        "title": "Compute separation"
      }, 
      {
        "comments": [
          "I cannot replicate that. I get `## Error in locator(1): plot.new has not been called yet` in Markdown cell on an existing plot or simply `NULL` from `locator()` if run in the same cell.\n", 
          "Same, I get the error, not stuck.\n", 
          "saw this on the call\n", 
          "Not seeing any error on local or rcloud.social, it just runs through. I think this is the best we can do.\n"
        ], 
        "number": "1684", 
        "title": "locator() gets invoked for R plots in markdown cell"
      }, 
      {
        "comments": [
          "The issue is that the plot loses focus when the result is hidden, so it no longer accepts `<ESC>` to cancel the locator. I'd suggest disallowing result hiding for the duration of locator callback (if technically feasible).\n", 
          "If the result is re-shown and then clicked on, focus returns and ESC works. If one simply clicks away on something else that can take the focus, like the asset editor, then the plot loses focus and ESC doesn't work until it's clicked again.\n", 
          "Now that we have more sensible key bindings, we could temporarily bind the ESC key globally when the locator or readline is running. Ref #1196\n"
        ], 
        "number": "1683", 
        "title": "locator() is not getting terminated by <ESC>"
      }, 
      {
        "comments": [
          "As we discussed, the issue here is the slowness and the lack of feedback for long running operations.\n"
        ], 
        "number": "1682", 
        "title": " Since folder forking is slow, double clicking can create multiple copies of notebooks in the same folder"
      }, 
      {
        "comments": [
          "Confirmed on local and rcloud-2 (but not rcloud.research). The asset apparently uploads successfully before killing the connection, as the confirmation appears in the file upload panel, and the content is there on reload.\n", 
          "This is bad, but it's also really hard to track down. Putting off. At least the notebook is okay when reloaded.\n", 
          "The same message appears after uploading `200kb docx` file to the asset\n"
        ], 
        "number": "1680", 
        "title": "Upload large csv file session Reconnect message appears"
      }, 
      {
        "comments": [
          "I see no reason to support Mr. Number Name. But we should eventually have an error for him.\n"
        ], 
        "number": "1679", 
        "title": "User with number-name gets read-only notebooks"
      }, 
      {
        "comments": [
          "@s-u, the link I mentioned is above. Maybe redis.keys is not a slow operation even though it is O(N). And I agree that the bottleneck right now is surely the amount of data being sent down from the server to the client, and the parsing of that data. \n\nBut it's probably not good that we have so many wildcard searches over the keys, at least these 9:\n\n``` bash\n$ grr rcs.list\nrcloud.support/R/notebook.protection.R:  keys <- rcs.list(rcs.key('.cryptgroup', groupid, 'users', '*'))\nrcloud.support/R/notebook.protection.R:  keys <- rcs.list(rcs.key(user, 'system', 'cryptgroups', '*'))\nrcloud.support/R/notebook.protection.R:  keys <- rcs.list(rcs.key('.cryptgroup', '*', 'name'))\nrcloud.support/R/rcloud.support.R:  gsub(\"/.*\",\"\",rcs.list(usr.key(user=\"*\", notebook=\"system\", \"config\", \"current\", \"notebook\")))\nrcloud.support/R/rcloud.support.R:    rcs.list(rcs.key(\".notebook\", notebook, \"stars\", \"*\")))\nrcloud.support/R/rcloud.support.R:  gsub(\".notebook/([^/]*).*\", \"\\\\1\", rcs.list(star.key(\"*\")))\nrcloud.support/R/rcloud.support.R:  notebooks <- gsub(\".*/\", \"\", rcs.list(usr.key(user=user, notebook=\"system\", \"config\", \"notebooks\", \"*\")))\nrcloud.support/R/rcloud.support.R:  keys <- rcs.list(usr.key(user=.session$username, notebook=\"system\", \"config\", \"recent\", \"*\"))\n...\nrcloud.support/R/stash.R:  k <- rcs.list(stash.key(stash, \"*\", \"*\", type=\"*\"))\n```\n"
        ], 
        "number": "1674", 
        "title": "eliminate redis O(N) operations?"
      }, 
      {
        "comments": [], 
        "number": "1667", 
        "title": "author keys"
      }, 
      {
        "comments": [], 
        "number": "1661", 
        "title": "proper access separation between compute and control"
      }, 
      {
        "comments": [
          "This has nothing to do with latin characters, but rather strings with undeclared encoding. If you use latin1 is works just fine:\n\n``` r\n> a=\"P\\xe1ssword\"\n> Encoding(a)\n[1] \"unknown\"\n> Encoding(a)=\"latin1\"\n> a\n[1] \"P\u00e1ssword\"   \n```\n\nThe real problem is that whatever code reads TIGER/Line doesn't declare the encoding properly.\n\nThat said, we need to do something to not bomb on those. Since they are useless anyway (the content is really undefined) we may as well simply take them as bytes and encode them by casting each byte to Uint16 and treat them as unicode subsequently encoding to UTF-8. The issue with that is that the JS side has no way to distinguish such undefined strings from valid UTF-8. The other alternative is to pass them as byte arrays.\n", 
          "I checked R behavior and it's a bit more complicated than that. Normally, undeclared encoding is taken to be the current locale. Since we're running in a UTF8 locale `a=\"\\xe1\"` is entirely illegal, since that is not a valid UTF8 string. Unfortunately, R will let it pass so a string in the native locale may not be actually valid. Strictly speaking, this is a user error, so bailing out at some point is the right answer. The problem is that the only way to detect such strings is to do a full UTF8-validity check on every string we pass which seems like a fairly heavy penalty for detecting edge cases.\n"
        ], 
        "number": "1653", 
        "title": "strings with undeclared encoding that are not UTF8 bomb rserve.js"
      }, 
      {
        "comments": [
          "Yeah, I suppose the tool tip should be platform specific\n"
        ], 
        "number": "1652", 
        "title": "if a KB shortcut exists for a UI button, include on tooltip popup"
      }, 
      {
        "comments": [], 
        "number": "1649", 
        "title": "keep same asset open"
      }, 
      {
        "comments": [], 
        "number": "1646", 
        "title": "somehow label a notebook currently broken"
      }, 
      {
        "comments": [
          "odd, must be a css issue\n", 
          "This issue is still reproducible \n", 
          "Thanks @Prateek032, we'll have to fix it next time.\n"
        ], 
        "number": "1642", 
        "title": "Dataframe dimensions are not  displayed in single line"
      }, 
      {
        "comments": [
          "looks like more search/solr bugs.\n"
        ], 
        "number": "1640", 
        "title": "Error while deleting comments"
      }, 
      {
        "comments": [
          "Thanks @sanketd11!\n", 
          "We observed that the forked notebook itself is not getting searched when tried to search with id. The forked notebook and its contents (comments, assets, etc) are reflected in the search result only if we edit that notebook after forking.\n"
        ], 
        "number": "1639", 
        "title": "Unable to search comments from forked notebooks"
      }, 
      {
        "comments": [
          "to make it more complicated, this is likely to be an issue only without compute separation, because it changes the current notebook for the control process only.\n"
        ], 
        "number": "1636", 
        "title": "current notebook potentially lost when forking folder of foreign notebooks"
      }, 
      {
        "comments": [
          "#1602 #1632\n", 
          "I'm actually not sure what to do about this, since we don't pass the expected notebook id when we run a cell.\n"
        ], 
        "number": "1633", 
        "title": "no error when fetching a cell fails for snapshotted execution"
      }, 
      {
        "comments": [
          "We are not able to reproduce this on RCloud-5 with either chrome or firefox browser\n"
        ], 
        "number": "1629", 
        "title": "reload message is overlapping"
      }, 
      {
        "comments": [
          "There is nothing we can do about it since the context needs it. This can only be fixed once compute can ask control to execute gist commands on its behalf.\n", 
          "Ah. Right.\n", 
          "Possibly a stretch here...\n\nCould this be co-opted to also allow us to protect some gist content, allowing only the owner (and maybe group) to read?\n", 
          "@holyguster, I don't think that's relevant to the issue described here - do you have a feature request in mind? \n\nThis is really just about how the configuration is stored in memory and whether configuration secrets are safe.\n", 
          "This is blocked by #1661\n"
        ], 
        "number": "1613", 
        "title": "the truth will out"
      }, 
      {
        "comments": [
          "Correction, looks like I was wrong about the RCloud version on rcloud.research.att.com; that appears to be RCloud 1.4.2 (master/1e0df18), R version 3.2.1 (2015-06-18).\n\nSo maybe that is why A is different from B and C above.\n", 
          "The effect may vary depending on whether the setup is proxified (tupile) or not (external site).\n\nThe messages in B and C depend on your cookies, so you likely had stale token on Windows so the authentication fails, while on Mac you didn't have any so it used anonymous mode which went past the authentication setup but then failed on unpublished notebook.\n\nIn the case C RCloud knows that you have authenticated before so it assumes that you simply have stale token. In case B it seems like you never authenticated so RCloud assumes you wanted to access the notebook anonymously which is prohibited there. We could improve the message in that case.\n"
        ], 
        "number": "1612", 
        "title": "notebook.R error for unpublished notebook when not logged in could use a link to Login"
      }, 
      {
        "comments": [
          "What @s-u and I discussed... a long time ago... was to use the existing `mode`, which is currently a 'scalar' string\n- change it into a vector of flag-strings\n- combine that functionality with the extra flags that are being sent along with the very breakful `session_type` in this PR\n  Then the same flags will be used to determine whether to do compute separation and to decide which packages to load.\n\nThis means e.g. changing \n\n``` r\n    if (mode %in% cs.modes) { ## use fork only in modes that require it\n```\n\nhttps://github.com/att/rcloud/blob/develop/rcloud.support/R/ocaps.R#L88\n\nto a union operation, etc etc. And removing most of the virulent interface changes in the current PR (yay).\n", 
          "I'll clean this up soon and pass back to @s-u for review.\n", 
          "This seemed potentially too disruptive for the point release - could have strange effects for third-party extension developers, and we also need to make sure they know about the tags they need for the DESCRIPTION file. For now, we've disabled extensions also for mini.html (see commit above).\n\nHope to fix this up and merge to develop soon for 1.5.\n"
        ], 
        "number": "1609", 
        "title": "Filter rcloud extensions, take 2"
      }, 
      {
        "comments": [], 
        "number": "1608", 
        "title": "Error while opening notebooks after executing the notebook with iip slides"
      }, 
      {
        "comments": [], 
        "number": "1596", 
        "title": "leading spaces accepted in notebook name"
      }, 
      {
        "comments": [
          "Thanks @Prateek032, RCloud currently does not have very many features preventing you from shooting yourself in the foot. As long as this doesn't break the session or corrupt the notebook, it is probably okay, but I'll keep this open for if/when we think about concurrency issues.\n"
        ], 
        "number": "1592", 
        "title": "Unexpected message is displayed after deleting asset "
      }, 
      {
        "comments": [
          "The notebook successfully loads, and clicking away from the Please Wait doesn't harm anything. \n\nBut the spinny cursor doesn't go away #758 \n", 
          "Fixing #758 causes this to happen every time. Consistency and progress.\n"
        ], 
        "number": "1587", 
        "title": "clicking on notebook twice fast causes please wait from heck"
      }, 
      {
        "comments": [
          "rebuilt and now they work, on chrome/osx only. this is annoying!\n", 
          "updating jquery ui to 1.11.4 doesn't help \n"
        ], 
        "number": "1556", 
        "title": "jquery-ui tooltips don't work on webkit browsers"
      }, 
      {
        "comments": [
          "As of RCloud 1.4, the notebook protection and visibility options are completely orthogonal. So the notebook will still appear in the tree. If someone without access clicks on it, they will get an error (which could be improved, #1552).\n\nI'm open to the idea of combining these features in the future, so I'll mark this for the next release. It's just some work to filter the tree by groups.\n\nRenaming the \"eye\" from private/public to maybe \"hidden/shown\" is #1539 - I agree this is confusing.\n", 
          "One way forward, preserving backward compatibility:\n1. Add \"hidden\" radio button to notebook protection dialog, selecting current `visibility` flag\n2. Hide all notebooks in tree if they are marked invisible or `group!=='public'`\n3. Make eye command another shortcut to protection dialog\n"
        ], 
        "number": "1549", 
        "title": "private notebooks should not be visible in tree"
      }, 
      {
        "comments": [
          "Thanks for the report @dougmet. Let's try to narrow in on this a bit more, since obviously this is not happening in all cases.\n\nIs this a particularly large notebook? Or is it possible there is invalid text in the notebook? Or do you mean you encounter this with all notebooks?\n\nI take it you are not seeing any feedback as all in the session pane. To diagnose it better in JavaScript, see if the browser's debugger console shows any errors.\n", 
          "Hi @gordonwoodhull , thanks for looking at this.\n\nActually yes, for one of the instances (which is on the same network as its Enterprise GitHub) I do find that the problem is much worse for larger notebooks. I often have one or two assets as well. For smaller notebooks it seems more robust. That's a good lead.\n\nFor my local version at home (which connects to public GitHub) I find this problem with all notebooks. So perhaps the slower response?\n\nI don't get any special errors in the console. Sometimes a warning about keyboard events and the ace editor but I don't feel like that's going to be the issue.\n", 
          "It doesn't even tell you it has disconnected? I am not sure if we are talking about the same bug.\n\n@s-u, is it now reasonably easy to install the \"proxified\" server, to see if it's more stable and/or aide in troubleshooting?\n", 
          " No disconnection message. In the case of running an R cell you still get the spinning running indicator but it doesn't appear to send anything out (or perhaps RServe doesn't take it).\n", 
          "Do any changes to the notebook get lost? \n\nI'm trying to ascertain if something is failing or if the connection is just hanging somehow.\n\nWe have a proxy server in 1.5 which may help with connection stability.\n", 
          "Yes and no. The first change you make gets saved. After that nothing is saved. I wish I could give you better information. As I say, there are no obvious errors on either the R or JS side, so in that sense it looks like it's hanging. But I don't really know.\n", 
          "I've confirmed with @dougmet and team that they are still having these issues. Hopefully we will be able to put some effort into stability and connectivity for 1.5\n", 
          "Disconnection issues are greatly improved with the [proxified server](https://github.com/att/rcloud/wiki/ProxifiedSetup). Unfortunately websocket still seems to be a brittle protocol over some networks.\n"
        ], 
        "number": "1526", 
        "title": "Failure after one call to rcloud.update_notebook()"
      }, 
      {
        "comments": [
          "good idea, like the way input throbs, only different colors.\n"
        ], 
        "number": "1518", 
        "title": "\"running\" cell indicator for long cells"
      }, 
      {
        "comments": [
          "the request for viewing a dataframe goes to the same process as the cell executions. so this makes sense. but it would be good to have some indication that the request to view the dataframe is being held up.\n", 
          "related: #1463\n"
        ], 
        "number": "1515", 
        "title": "some indication that access to dataframe is delayed while current cell is executing"
      }, 
      {
        "comments": [], 
        "number": "1503", 
        "title": "highlight markdown code on hover"
      }, 
      {
        "comments": [], 
        "number": "1498", 
        "title": "override q() to avoid user errors"
      }, 
      {
        "comments": [], 
        "number": "1494", 
        "title": "Upload overwrite"
      }, 
      {
        "comments": [], 
        "number": "1481", 
        "title": "support \"show all\" in history"
      }, 
      {
        "comments": [], 
        "number": "1480", 
        "title": "should svg assets be displayed as graphic?"
      }, 
      {
        "comments": [], 
        "number": "1478", 
        "title": "png assets not getting displayed in firefox"
      }, 
      {
        "comments": [
          "I'm not able to reproduce this, must be platform-specific. Given that PDF support is broken anyway #1477, I don't consider this an important issue, but we should check this again when that issue is resolved.\n", 
          "reopening. this issue is on ubuntu. also it's not specific to pdfs, it's clicking on the non-content area of the asset.\n", 
          "Was able to repro this on OSX with PDFs and clicking within the range of X coordinates of the tab. Odd.\n", 
          "This is very weird, but definitely not important. Spent a little too much time trying to figure out what's going on here - I see a focus event but not a click event? Delaying indefinitely.\n"
        ], 
        "number": "1476", 
        "title": "clicking on asset area causes name to start editing"
      }, 
      {
        "comments": [], 
        "number": "1473", 
        "title": "message when cell interrupted"
      }, 
      {
        "comments": [], 
        "number": "1472", 
        "title": "notebook mutability should be defined by gist backend"
      }, 
      {
        "comments": [
          "moving this from #620, where @s-u commented:\n\n> Idea: add a parse-only ocap (and callback in lang) such that the UI can determine independently the validity of the code.\n", 
          "I'll take over the parse piece\n"
        ], 
        "number": "1466", 
        "title": "automatically determine when command prompt input finished"
      }, 
      {
        "comments": [], 
        "number": "1463", 
        "title": "Some indicator/throbber for \"updating environment viewer\""
      }, 
      {
        "comments": [
          "The easier part are notifications form the session - it's trivial to send a OOB when the notebook is modified by the session, but probably less trivial to act on it on the UI side.\n\nHowever, there is generally no way to track changed from the back-end - mostly because such layer doesn't exist (i.e., the gist backends have no defined way to signal anything).\n\nThe middle ground are notebooks modified by RCloud since we could conceivably signal that across sessions (e.g., on the proxy plane if we have it support messaging in general).\n"
        ], 
        "number": "1458", 
        "title": "reflect modifications to notebook from R in UI"
      }, 
      {
        "comments": [
          "Verified it's not that the value gets recalculated, it's just the value/structure printing. \n\n@s-u knows how to observe changes to the environment instead of blindly refreshing the whole workspace view every time a cell is run. \n\n`rcloud.enviewer.build` already takes a list of variables, so we just need to keep the current state around, update the variables that changed, and delete any removed.\n", 
          "There are two separate issues:\n- `str()` can take forever on large recursive objects. We only use the first 3 lines so it's a complete waste. This is the real problem observed in this issue.\n- enviewer re-builds all objects on each call. We have ways to guess which objects changed in the workspace so we could make this a bit more smart.\n", 
          "BTW there was one more rather reasonable suggestion: When the enviewer is collapsed it should not update anything. Only when opened it should update the objects. Personally, I'd very much prefer that because in 95% of the cases I don't want to use it so it should not be slowing down my session when not used.\n", 
          "Yes, that's a good idea too...\n", 
          "Update now only happens when the Workspace is open - 17673507df6092618a3f6cb1bd57e4bcf09330f9\n", 
          " add cell eval hook\n", 
          "Since we already addressed the main issue this may get pushed past 1.4 depending on the available cycles.\n"
        ], 
        "number": "1452", 
        "title": "after creating big recursive objects, Workspace viewer refresh causes long run cell run times"
      }, 
      {
        "comments": [], 
        "number": "1448", 
        "title": "Tooltip for unstar in navbar shows star text"
      }, 
      {
        "comments": [], 
        "number": "1447", 
        "title": "searching for edited comments yields odd results"
      }, 
      {
        "comments": [
          "should log a polite message to session pane instead.\n", 
          "@s-u, this is waiting on the context going first in OOB sends/messages, to handle contexts in a consistent way #1471\n", 
          "@s-u, actually I'm not sure what to do here. Surely we don't want yet another try-catch? Many different places can fail here.\n\nI know the expected behavior is just to return a regular `cell-eval-error` as if evaluat**_ion**_ (not evaluat**_ing**_) failed\n", 
          "passing this back, R guru!\n", 
          "unless there's really no good way to deal with this, since there are legitimate failures like unable to fetch the cell content.\n", 
          "But those are already covered by the context, so I'm not sure what exactly is the issue. You will always be able to interrupt before we can even setup a context - that is absolutely expected by definition - it's an asynchronous even after all. So is this really about #1473? Interrupts shouldn't really go to the session pane regardless of where they happen...\n", 
          "Maybe we don't have to deal with it for 1.4, but it seems pretty weird that pressing the stop button will generate a big scary error message depending on the moment you press it.\n", 
          "Well, it is #1473 and I'm sorry to say that we probably won't be able to solve it without hacking R. The `tryCatch(..., interrupt=..)` approach doesn't seem to work with those nested evals we're dealing with. That said, we should be (hopefully) able to avoid it for the most common case which seems to be interrupting the retrieval of a long notebook.\n"
        ], 
        "number": "1441", 
        "title": "error when stopping execution before execution has started"
      }, 
      {
        "comments": [
          "Right, we would have to reimplement knitr or learn more about its internals in order to make this happen. As of 1.3 it is an entirely different mode of processing for R cells vs Markdown cells.\n\nPerhaps if knitr is using the htmltools framework there is a customization point, but this is pure speculation.\n"
        ], 
        "number": "1437", 
        "title": "No Save option for plots (for R code in markdown cell) "
      }, 
      {
        "comments": [
          "Hmm, this scrolling behavior doesn't seem to be built into the jQuery UI resizable \"widget\". Kind of surprising, since it does work for drag and drop.\n"
        ], 
        "number": "1434", 
        "title": "grow page down dynamically when resizing R image at bottom of rcloud page"
      }, 
      {
        "comments": [
          "Looks like it loses keyboard focus but the blinking cursor doesn't go away. This happens as soon as the dragging starts; i.e. dropping the cell in the same place also causes the \"phantom blink\".\n\nI think jQuery UI may be copying the elements when it starts the drag. We may be able to force a keyboard blur when dragging starts.\n"
        ], 
        "number": "1432", 
        "title": "Firefox "
      }, 
      {
        "comments": [
          "The shortcut 'ctrl+K' is already in use for cell cropping feature.\n"
        ], 
        "number": "1426", 
        "title": "ctrl-K should kill to end of real line"
      }, 
      {
        "comments": [], 
        "number": "1425", 
        "title": "arrow key history for debugger"
      }, 
      {
        "comments": [
          "Session div throws above mentioned error message, when we create a new notebook and try to comment on it (without adding any code to it). When we add some code to the notebook and save/execute, then session div doesn't throw the above error. \n", 
          "Someday we will basically rewrite the solr code. Until then, I think this is on hold.\n"
        ], 
        "number": "1418", 
        "title": "Comments in forked notebook are not found in the search results"
      }, 
      {
        "comments": [
          "@s-u, I guess you mean not eval errors (which are always parse errors and go to the session pane per #674, albeit [without line numbers](https://code.google.com/p/v8/issues/detail?id=2589)), but errors from the code when it's later invoked. \n\nI'm not sure we can do anything about this in general, at least without major hackery - say the code was attached to a button, so it's just the browser invoking JS and that will go to the error console like all JS errors do. You **can** click on the line number in the console and go to the code - in the browser's debugger. And then you can even set breakpoints, there. Maybe not as nice as in the asset, but then again, we probably don't have the resources to implement a visual debugger, so maybe that's just as well.\n\nSo, I guess I'm confused what this is about. Chrome's debugger (as well as Firefox's and IE's) is pretty awesome. I don't think we can top that.\n", 
          "I _do_ mean the eval errors since there is no way to figure out what they are referring to. I'd be very happy if they triggered the JS debugger, obviously.\n", 
          "You mean syntax errors? We don't have any control over it. As the link above confirms, Chrome does not give a line number when eval fails due to a syntax error.\n", 
          "They do get printed to the session pane and AFAICS that's all we can do.\n", 
          "Ok, got it - it's simply impossible since Chrome doesn't expose that information specifically for syntax errors. Firefox allegedly does (but I can't currently test it since it seems to have a bug in SSL verification).\n", 
          "Just tested in Firefox; the exception does have a line number in it which we might be able to use. \n\nIf the code is an asset, the asset viewer will also mark syntax errors automatically.\n"
        ], 
        "number": "1414", 
        "title": "better error JS handling in install.js.module()"
      }, 
      {
        "comments": [], 
        "number": "1408", 
        "title": "replace notebook ids in notebook when forking it"
      }, 
      {
        "comments": [
          "oh weird, it displays disabled, but it's not actually. it displays an error in the browser debug console.\n"
        ], 
        "number": "1406", 
        "title": "Select checkbox for 'publish notebook' is not disabled "
      }, 
      {
        "comments": [
          "I don't think github gists store this information. We'd have to store it separately and augment the notebook.\n"
        ], 
        "number": "1405", 
        "title": "'forked from' link loads the current version of notebook instead of the history version"
      }, 
      {
        "comments": [
          "Thought we had an earlier request for this, can't find it. It's a good idea but it's a mountain of work.\n"
        ], 
        "number": "1402", 
        "title": "reflect changes to notebook tree in other sessions"
      }, 
      {
        "comments": [
          "Those are not handled by RCloud since the Python interface doesn't provide the corresponding features. This is a feature request for the `rcloud.python` package.\n"
        ], 
        "number": "1399", 
        "title": "There is no 'save' option for the images, which are generated from 'Python' language"
      }, 
      {
        "comments": [], 
        "number": "1397", 
        "title": "Gitgist"
      }, 
      {
        "comments": [], 
        "number": "1396", 
        "title": "Gitgist"
      }, 
      {
        "comments": [], 
        "number": "1395", 
        "title": "Gitgist"
      }, 
      {
        "comments": [], 
        "number": "1394", 
        "title": "change internal links when forking a folder"
      }, 
      {
        "comments": [
          "This is working for me. Nothing has changed in search, so this is weird. @Prateek032 are you still seeing this?\n", 
          "This issue is still reproducible on RCloud-local instance. This issue also occurs for articles e.g. 'a','an','the', etc also for prepositions like 'on','in','at', 'as',etc. apart from this, keywords 'is','are', 'will' are not getting searched.\n", 
          "In RCloud-2, For keywords 'an','e','o','l', etc following error message is thrown in session div\n![rcloud-2_search](https://cloud.githubusercontent.com/assets/9251570/8103619/dfe165ea-0ff7-11e5-8c1c-7c61cb9fd8cf.PNG)\n", 
          "okay, thanks for confirming. i will try to take a quick look but probably will not fix SOLR issues for this release.\n"
        ], 
        "number": "1390", 
        "title": "Unable to search for alphabet 'a'"
      }, 
      {
        "comments": [
          "Oddly, it doesn't happen with a simple\n\n``` r\nlapply(1:100, function(x) readline(x))\n```\n\nSo it is probably something else.\n"
        ], 
        "number": "1382", 
        "title": "holding <enter> on repeated readline causes \"Don't call oob_message_handler more than once.\""
      }, 
      {
        "comments": [], 
        "number": "1381", 
        "title": "caching of displayed results within a notebook"
      }, 
      {
        "comments": [], 
        "number": "1380", 
        "title": "color cells in readonly mode?"
      }, 
      {
        "comments": [
          "@shaneporter, here's an interesting one for when you're back, or if you want an interesting design problem (architecture and UI) while you're on vacation.\n\nA really bright programmer from another division of our company came out to the Hackathon at the company Software Symposium a year ago, and built the tool that he wished he had when he was working with RCloud.\n\nHe had built a very complex dashboard using a version of mini.html and [rcloud.dcplot](https://github.com/att/rcloud.dcplot) and got engrossed with what it's like trying to build an application from the HTML and JavaScript side, with less emphasis on R code, or with the R code provided by others. \n\nMuch as you've been doing with RCAP, but without the time to build a framework.\n\nSo the UI he designed in this PR is for when you are only working on the layout and html/css/js of a notebook. The command-prompt / editable-markdown interface of the notebook itself is gone: instead the live dashboard output is in the notebook area in an iframe, and you work in the assets pane with your modified mini.html in an asset, plus JS and CSS and R assets; and you refresh the output frame as you fix stuff.\n\nGiven this raw hack of an implementation, put together over a night or two at the Hackathon, and your experience with the code of RCloud core, how would you merge this or implement this differently? How would you generalize this, and does this suggest that RCloud needs other extension points?\n", 
          "BTW, yes, as the title implies, this brings RCloud closer to JSFiddle (or [Building Bl.ocks](http://blockbuilder.org)).\n", 
          "@shaneporter, this one might have slipped past your radar because it's a pull request I want you to review, rather than an issue. Please take a look when you have time.\n\nI will also find more issues and determine where we are for the release, but that might not be tonight because I've worn myself out at a conference the past few days.\n", 
          "It's beeping on my radar; will take a look in the next 24 hours.\n", 
          "It's been a while since I commented on this. I did take a look at it, but couldn't get things working because of an apparent R issue (it can't find a resource.)\n\n![image](https://cloud.githubusercontent.com/assets/2493614/15150468/39f7e35e-16c5-11e6-931e-2906888fac73.png)\n\nI'm going to attack it from a different side and see how I get on.\n", 
          "Hoping we can get to this in the next point release.\n", 
          "When is 1.6.1 due to be released?\n", 
          "There is no particular schedule but I think September is a reasonable target. It also may be that what's now marked 1.6.1 will become 1.6.2 if there are things that need to be patched in 1.6. Right now I'm using it as a bucket for \"what's next\".\n", 
          "I know I mentioned this on a call, but stating here that I got this working.\n"
        ], 
        "number": "1379", 
        "title": "fiddleR"
      }, 
      {
        "comments": [
          "The source of `notebook_runner.py` is https://github.com/paulgb/runipy\n\nThe PR to `notebook_runner.py` which did (most of?) the upgrade is https://github.com/paulgb/runipy/pull/49\n", 
          "Meanwhile (at around the same time), @sisukapalli updated our copy of notebook_runner.py to track the asynchronous output of RCloud 1.3 in 5b736c613e99affe4fb23ef3096a02d2879bc400. So I think the bulk of the work is reconciling the divergence here.\n", 
          "If we go by just the number of changed lines, then paulgb/runipy@98794e08572da355ddb0b096e7a20680f50d960e seems to be the commit closest to the earliest `notebook_runner.py` we have (back when it was in rcloud.support at fe0ac1d964e86c3104d717e1145185bcbc93dc19). That's January 2014, which is about the right timeframe.\n", 
          "[Earliest rcloud.support/inst/python/notebook_runner.py](https://github.com/att/rcloud/blob/fe0ac1d964e86c3104d717e1145185bcbc93dc19/rcloud.support/inst/python/notebook_runner.py)\n", 
          "@s-u has done this but he's suppressing it."
        ], 
        "number": "1378", 
        "title": "upgrade ipython2 to jupyter"
      }, 
      {
        "comments": [
          "I've looked into this a little further. rserve.js is properly tagging the result with `RESP_ERR`, but apparently Rserve is ignoring this on the server side?\n\n``` js\n                    params.push(function(err, result) {\n                        if (err) {\n                            _send_cmd_now(Rserve.Rsrv.RESP_ERR | cmd, _encode_value(err), msg_id);\n                        } else {\n                            _send_cmd_now(cmd, _encode_value(result), msg_id);\n                        }\n                    });\n```\n\nhttps://github.com/att/rserve-js/blob/develop/src/rserve.js#L229\n\nI think we still have a window to fix this, even if it breaks existing code. There aren't a lot of users using the R-JavaScript integration directly, and it isn't fully documented.\n\nOne kind of hacky way we could make this backward compatible is to add a condition to rserve.js that if there is only one argument, it should be assumed to be success. That might haunt us, however. It might be better to go with a clean break and let any existing functions fail when calling the continuation with a single argument.\n\nIt would be nice to be able to throw exceptions from JavaScript as well as we can from R. The final step would be to interpret the JavaScript `Error` object, which currently seems to come across as an empty `Named list()`\n", 
          "This needs to happen at the beginning of a release cycle. Delaying.\n"
        ], 
        "number": "1376", 
        "title": "can't return error via JS continuation"
      }, 
      {
        "comments": [], 
        "number": "1375", 
        "title": "ace line-breaks anywhere, unactivated source breaks on spaces"
      }, 
      {
        "comments": [], 
        "number": "1374", 
        "title": "add download link to Dataframe viewer"
      }, 
      {
        "comments": [
          "This is indeed weird: at least I wouldn't expect the shiny notebook to work. I expect if we tested it more thoroughly we would see subtle errors.\n"
        ], 
        "number": "1373", 
        "title": "Shiny notebooks can be viewed as mini.html and vice versa"
      }, 
      {
        "comments": [
          "Content\n- [x] rcloud.dcplot\n- [ ] rcloud.lux\n- [x] rcloud.shiny\n- [ ] rcloud.web\n\nUI\n- [ ] rcloud.enviewer\n- [ ] rcloud.notebook.info\n- [ ] rcloud.viewer\n\nLanguages\n- [ ] rcloud.python\n- [ ] rcloud.r\n- [ ] rcloud.rmarkdown\n", 
          "Out, damn spot! Out, I say! ... What need we fear who knows it, when none can call our power to account?\n", 
          "I think rcloud.dcplot is now complete. (d3.js is still loaded directly by RCloud, but dc.js and crossfilter are now in the package.)\n"
        ], 
        "number": "1371", 
        "title": "Expel rcloud.packages"
      }, 
      {
        "comments": [], 
        "number": "1368", 
        "title": "In view.html mode of history version of any notebook, Clicking 'Edit notebook' option redirects to current version of that notebook "
      }, 
      {
        "comments": [], 
        "number": "1365", 
        "title": "do something with results for enqueued deleted cells"
      }, 
      {
        "comments": [
          "This is a known issue with the way we are doing resizing, by replaying display lists.  You can see this even more dramatically with word clouds.  \n\nThe thing is that these plots require knowing the font size, which only gets calculated once. When resizing, text gets drawn at the same size (and there seems to be no way to resize it).\n\nSo you would have to redraw the plot from scratch instead of just replaying it.\n", 
          "The workaround I hope to allow in the future is to preserve the requested size, so that when the cell is rerun, it gets redrawn at the requested size.  (I think there are some cases where this already works by accident.)  You can't avoid rerunning the cell but at least you can determine the size.\n\nI think @s-u told me there is actually no way within R to set the device size, which blows my mind.\n", 
          "@gordonwoodhull I don't understand anything in your last comment. Of course you can set the device size, but that has nothing to do with the effect above. It does render what is requested - the issue is whether you want scaling or resizing - they are two entirely different things and R supports both. Scaling is just a change in the DPI but doesn't change any of the layout. Resizing changes the positions of elements drawn, so obviously you can't fit the same text in the same size in a smaller plot.\n\nThe issue here is that the user want so change the content that will be drawn which by definition is only possible by re-runnig the code (since the code will do a different things and thus produce actually different graphics elements). Maybe a good example are maps - when you change the plot size of a map the user will actually want to fetch different set of tiles (including URL requests and all), so it's not something you can do without re-runnign the code - it's not an operation purely on the graphics.\n", 
          "Hmm, maybe there is a need to affect both.  What I would expect is: when you rescale and then rerun, it actually resizes (tries to draw afresh into the new size).  But perhaps this is too simple, and we'll need some other modifier key to set the scaling separately from the size.  \n\nRight now I'm not saving or doing anything with the rescaled size, and the rerender happens in a temporary device, so the size gets lost and the plot reverts to its old size and scale when you rerun it.\n\nIs there some way in R code to set the size, so that people have a workaround if they need to redraw at a different aspect ratio/size?\n", 
          "I was just using `RCairoDevice` but in doing so I realized we should have an API call for it ...\n\nIt's a good question - it isn't hard to keep the size on re-run -- right now the only issue is that the R side doesn't know that a given resize rendering is tied to a particular cell. However, it can get a bit confusing in the UI - what if you have more than one plot in a cell and you resize one and not the other?\n", 
          "The resizing is really cool, but it opens a can of worms. It's not even clear what the right behavior should be... The underlying problem is that you're modifying state that is not part of the notebook - which is something we try to avoid otherwise ... more so that it actually modifies things that are programmatically  accessible - e.g. if you now use things like `par(\"din\")` you get the state of the original image, not the resized one (which is correct in some sense).\n", 
          "It might require some planning, but in principle I think it makes sense that notebooks have \"view state\" which is not in the notebook source. \n\nFor the simplest example, take #1161 persistence of view type. Just as notebooks have a natural page to view them with, which is set by the author but should be overrideable by other users of the notebook, I think the plots might have some natural size set by the author using the UI, but other users might prefer a different layout. \n\nIt is basically RCS  per-notebook per-user settings.\n", 
          "Well, that is ok as an override for the default initial setting (although even that is debatable since you don't want that to apply to other's notebooks), but not in the context above where the state changes in the middle of a notebook (unlike a default that is fixed for the entire notebook).\n"
        ], 
        "number": "1355", 
        "title": "plot elements based on font sizes do not resize when plot resizes"
      }, 
      {
        "comments": [
          "seems to appear on all panel headers when they are the \"active\" (last-clicked) one.\n"
        ], 
        "number": "1351", 
        "title": "odd underline on icons of panels"
      }, 
      {
        "comments": [
          "Yeah, I still don't want horizontal scrollbars.  I'd prefer to be able to change the width of the view.  Retitling\n", 
          "Also, check what edit.html is doing about this - why does it work there?\n", 
          "In edit.html, the side panels can be resized to see the stretched graph. Here the worst case scenario can be for the dense graph, when it needs to be stretched even more after all side panels are closed to see the point values as shown below in screenshot \nwhen all side panels are closed the issue is same as that is replicated in view.html \n\n![plot](https://cloud.githubusercontent.com/assets/9251570/6262786/54c2939a-b830-11e4-9ca3-ce7eb8c5987e.PNG)\n"
        ], 
        "number": "1349", 
        "title": "way to change the view width"
      }, 
      {
        "comments": [
          "I apologize, but I won't be getting to any SOLR bugs for this patch release.  The code is too alien to me and I don't have a decent environment for testing.  I will get back to it, and probably rewrite a lot of that code to make it more readable.\n"
        ], 
        "number": "1344", 
        "title": "SOLR error when updating a comment"
      }, 
      {
        "comments": [
          "- [ ] screencasts are pre-1.0 (i have done new ones but they need to be scrubbed)\n- [x] it links to cscheid/rcloud in two places\n- [x] update authors\n\nAs for the link from github, I think that just means adding a link to the README - at least, I don't know of anything built-in.\n", 
          "will be updated in 1.3.1\n", 
          "I got impatient and pushed these changes.  \n\nThe screencasts still need updating (although I get nostalgic looking at them).\n"
        ], 
        "number": "1341", 
        "title": "Update RCloud Github home page"
      }, 
      {
        "comments": [
          "In the cells? No, I don't think so. \n", 
          "in comments , When user enters some texts followed by white space characters, the posted comment eats up the div with blank spaces\nShould the white spaces be trimmed in this case ? \n", 
          "Hmm, probably, but it's not a high priority. \n"
        ], 
        "number": "1339", 
        "title": "shoud white space characters trimmed or not"
      }, 
      {
        "comments": [
          "As we discussed on the call, this seems to be OS-dependent.  (Which is kind of strange, actually.)\n\n@sanketd11, please update this ticket with the specifics.\n", 
          "I have updated the OS specifics.\n", 
          "This issue is still reproducible on both RCloud-2 and RCloud-local instance\n", 
          "Okay, thanks. I don't intend to fix any Python issues for this release, unless they are much more severe than this. We have lost the developers working on this side of things.\n"
        ], 
        "number": "1336", 
        "title": "Complete output is not visible for python cell "
      }, 
      {
        "comments": [
          "@sisukapalli looked into this but it didn't make it into this release.\n"
        ], 
        "number": "1334", 
        "title": "provide run time inputs in python code"
      }, 
      {
        "comments": [
          "Here is `reread_buffers`:\n\n```\n        reread_buffers: function() {\n            // force views to update models\n            var changed_cells_per_view = _.map(this.views, function(view) {\n                return view.update_model();\n            });\n            if(changed_cells_per_view.length != 1)\n                throw new Error(\"not expecting more than one notebook view\");\n            var contents = changed_cells_per_view[0];\n            var changes = [];\n            for (var i=0; i<contents.length; ++i)\n                if (contents[i] !== null)\n                    changes.push(this.cells[i].change_object());\n            var asset_change = RCloud.UI.scratchpad.update_model();\n            // too subtle here: update_model distinguishes between no change (null)\n            // and change-to-empty.  we care about change-to-empty and let github\n            // delete the asset but leave it on the screen until reload (as with cells)\n            if (asset_change !== null) {\n                var active_asset_model = RCloud.UI.scratchpad.current_model;\n                changes.push(active_asset_model.change_object());\n            }\n            return changes;\n        },\n```\n", 
          "It looks like we could perhaps eliminate `if (contents[i] !== null)` or just go ahead and fetch the change object but only use it if it is not empty - we have ensured that the model has been updated, now just check if there is a change to report, which may have been made not through ace.\n\nI don't think we have a way to check if the change object is empty, but the buffer model has only the one special behavior that it remembers the last saved content.  I.e. the only reason a buffer model should have a change in itself (with no new action) is that the content has changed. Needs to be clarified and tested.\n", 
          "This will make writing extensions that modify code (like find and replace really is, although it looks bound to the cell view right now) much safer.\n"
        ], 
        "number": "1330", 
        "title": "allow changing the cell model content not through ace"
      }, 
      {
        "comments": [
          "We still didn't get to this for 1.3, just needs a minor refactoring of notebook.R\n", 
          "this has gotten harder since we are doing html output\n", 
          "You can get a decent, simple output with Print and Save to PDF."
        ], 
        "number": "1320", 
        "title": "Export as PDF"
      }, 
      {
        "comments": [
          "Ideally, there should be a place for cell-less input since technically R can issue ReadConsole requests even outside of cell execution.\n", 
          "the problem here is that if we add an input to the session pane then everyone will want to just use the session pane as a console, and we'll lose reproducibility again.  :-(\n", 
          "This would be just a fall-back in case no cell is active, so normally users would never see it, but it would save us in the odd cases where we run into infinite loops due to missing input.\n", 
          "a hidden feature.  i like that.  will turn into an enhancement request and implement for 1.4 (unless my next 36 hours open up magically, in which case i'll do it sooner).  \n\nit would actually be super helpful for debugging rcloud itself, at least until we enable compute separation - i was trying to decipher `rcloud.search` so I thought I would give it a try.  \n", 
          "man, this would sure be helpful. it's a pity that it's a week of work that i can't spare.\n", 
          "Of course, there are special problems with this and compute separation. It's a security hole (so we'd need admin access or debug mode), and I'm not sure if Rserve/RCloud code is expecting the control process to request input?\n", 
          "This would still be on compute, not control. We never ever want any user input to control.\n", 
          "So this is of limited usefulness. It would basically only help with debugging callbacks from interactive cells, not the core RCloud code I was imagining.\n"
        ], 
        "number": "1310", 
        "title": "add secret console input to session pane"
      }, 
      {
        "comments": [
          "More generally, panels' default width should be in pixels, not twelfths of a screen width.\n", 
          "I wonder how much we really need bootstrap for the columns in particular, given that they are not responsive. It might be a case where we think they are doing more just because we don't know what they're doing.\n"
        ], 
        "number": "1309", 
        "title": "on very large screens, side panels should not hide at width 1"
      }, 
      {
        "comments": [
          "when changing notebooks?\n", 
          "yes, i.e. when creating a new session. haven't seen it for a few hours but it was biting me all morning.\n", 
          "I seem to get the familiar\n\n```\nWebSocket is already in CLOSING or CLOSED state.\n```\n\nwhen this happens.  I don't think I have been switching notebooks very fast though.  Maybe I am clicking on a notebook while it's doing something else.\n"
        ], 
        "number": "1307", 
        "title": "rcloud frequently hangs on loading new notebook"
      }, 
      {
        "comments": [], 
        "number": "1301", 
        "title": "Testing in Rcloud-2"
      }, 
      {
        "comments": [], 
        "number": "1299", 
        "title": "Testing in RCloud-2 "
      }, 
      {
        "comments": [
          "This would be great but I was focusing mostly on search and replace, and obviously results can't be modified.  Will have to put off for 1.4.\n", 
          "just to confirm, we'd want to replace the results of any executions only on the front end? Should the replacements persist if you reload the page or re-run the cells?\n", 
          "I don't think we should allow replacements in the results, just searching. Otherwise one would be literally falsifying results. So if you're in replace mode, the replace button/command should not work whenever in a result area, the only thing to do on those finds is go to next.\n", 
          "Makes sense.thanks \n\n> On May 18, 2015, at 3:57 PM, Gordon Woodhull notifications@github.com wrote:\n> \n> I don't think we should allow replacements in the results, just searching. Otherwise one would be literally falsifying results. So if you're in replace mode, the replace button/command should not work whenever in a result area, the only thing to do on those finds is go to next.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", 
          "It would be nice if find was global (not just code and/or results), e.g. so it would work in the notebook tree as well (so you can search for a notebook name, user name etc.) It may require some separation of the search functions or some notion of focus.\n\nThe current behavior is not unreasonable and is very helpful as a search within the notebook, but from a browser-user perspective one would expect to be able to use `<Cmd><F>` to find any content on the page.\n", 
          "I think that would be a good feature too. And should be doable on the FE\nalone, since things like username and notebook name are present in the\ntree's html, so we won't have to search any models for matches, just the\ndom, then highlight tree's nodes and sub-nodes and scroll them into view\nwhen a match is found. And maybe we can add some notion of focus to the\ncurrent cmd+F prompt.\n", 
          "It's a good idea but it really merits a separate issue because it would require work unrelated to what this issue is about. I don't think the browser's built-in search would help, so it's a matter of implementing incremental search on top of the jquery.tree.\n"
        ], 
        "number": "1297", 
        "title": "find should search in results"
      }, 
      {
        "comments": [
          "which is weird, because it was grey before and that worked fine.\n", 
          "1. the notebook got so much greyer\n2. active, editable things are colored now\n"
        ], 
        "number": "1287", 
        "title": "asset and prompt should have color background."
      }, 
      {
        "comments": [
          "@prattatx writes:\n\n> I'm seeing edit.html hanging intermittently as well. As a side note, none of the buttons work in the toolbar while RCloud is in this state. Logout should work always.\n\n![image](https://cloud.githubusercontent.com/assets/1366709/6114198/7b2fd18c-b06a-11e4-8b48-9f23bd803ec7.png)\n", 
          "I simply reload when I hit this.  Not that it's acceptable,  but it's too hard to reproduce.\n\nI am surprised that Logout doesn't work.  I'm not sure why we are using an event handler rather than a simple link here - looks like we used to need something more complicated but a833d517f4f9d58568107005fc719a30f6cfa031 made it simpler.\n", 
          "Fixed the link...\n", 
          "we think this may be solved by the proxy. please comment if you continue to see this.\n", 
          "Saw this yesterday, definitely still an issue. Reload is the workaround.\n", 
          "The underlying error seems to be `504 Gateway Time-out`\n", 
          "Note: in testing this, I have also seen bootstrap.css and fontawesome fail to load with 504, resulting in hideous results that won't be caught by #1710.\n"
        ], 
        "number": "1283", 
        "title": "edit.html sometimes hangs on load"
      }, 
      {
        "comments": [
          "Given his transferring notebooks around from training classes, @prateek05 might have a script that could be adapted for this.\n", 
          "I didnt catch up \"outside normal permissions\". The migration I do is with different github backends so its more like\n1) If notebook exists by name for the current logged in user then rcloud.update.notbook with the title matched id and $content$files of the source notebook dump\n2) else create new notebook with $content and register with create notebook API and then have to self star it and mark it as visible. The three operations dont happen together or I might have missed the API which performs all three operations in sequence\n", 
          "Thanks @prateek05, that is actually a lot more than we need to do here, because in this case the notebooks definitely exist and we don't need to port any content.  We just need to add them under a user in a situation where we can't log that user in. \n\nIt can be done with a looping redis script.\n"
        ], 
        "number": "1272", 
        "title": "way to mass-add existing notebooks"
      }, 
      {
        "comments": [], 
        "number": "1269", 
        "title": "buffering of python output is odd"
      }, 
      {
        "comments": [
          "\"It's a feature.\"  It just wasn't visible before.\n\nThe idea here is to minimize the number of changes, to make the diffs small and comprehensible.  We are tracking each cell as its own file within the gist/repo.  So when cells are inserted/moved/deleted, we didn't want to change all of the cells down to the end of the notebook.\n\nBut it's worth considering if having contiguous cell numbers is more important than minimal diffs.\n", 
          "Related: #1219 force cell renumbering\n", 
          "We could also consider just showing numbers which have nothing to do with what's stored in the gist.\n"
        ], 
        "number": "1261", 
        "title": "Dragging cell, changing titles"
      }, 
      {
        "comments": [
          "Thanks @tejas1493, good catch.  \n\nIt looks like  `update.solr` only gets called on `rcloud.update.notebook`, not on `rcloud.star.notebook` or `rcloud.unstar.notebook`.  It should be trivial to also call `update.solr` in those cases.\n"
        ], 
        "number": "1242", 
        "title": "Star count of notebooks dont match in search"
      }, 
      {
        "comments": [
          "Heh.  This would be a piece of work.\n\nCurrently we consider Python to be a second-class language and we have no plan to support this.  It's not even the same process, so technically we would need different Workspace viewers for the different processes.\n"
        ], 
        "number": "1240", 
        "title": "reflect python variables in workspace panel"
      }, 
      {
        "comments": [
          "This is an old bug but it will be fixed along with #1234 - we will have a session reset message and all extensions will be able to clear any necessary state in reaction.\n", 
          "This is harmless, really just an inconsistency. It might even be helpful to some users if they are working with the same files across different notebooks\n"
        ], 
        "number": "1238", 
        "title": "In file upload feature, selected file path is not refreshed after switching notebook "
      }, 
      {
        "comments": [], 
        "number": "1234", 
        "title": "add-ons need to be reset on new session"
      }, 
      {
        "comments": [], 
        "number": "1229", 
        "title": "lines wrap wrong if ace will show a scrollbar"
      }, 
      {
        "comments": [], 
        "number": "1220", 
        "title": "Super skinny cells"
      }, 
      {
        "comments": [
          "we could just show the screen order, not the gist order\n"
        ], 
        "number": "1219", 
        "title": "Force cell renumbering "
      }, 
      {
        "comments": [
          "... at least it dies when you reload the page!\n", 
          "This is tough to address, because without I/O on the other side we can either raise an error or return -1, but not both. Using -1 will cause things like `readLines()` to loop while using error will cause `browse()` to loop. So I'm inclined to set this to \"Won't fix\", because if you don't have input all bets are off if you try to use debugging. I may also change the default to enable input console by default (if console I/O is enabled) so it doesn't need to be enabled separately.\n"
        ], 
        "number": "1215", 
        "title": "debug goes into an infinite loop if console input is not enabled"
      }, 
      {
        "comments": [
          "I think this was a transient problem, have not seen it since.\n", 
          "I think something causes all tooltips to die, as I just saw this again, but reloading the page brought them back.  Reopening.\n", 
          "Currently, no tooltips on Notebooks and center panes on hosts rcloud-5, rcloud, rcloud-core.\n\nrcloud-6 does have those tooltips, and rcloud-6 has no addons/extensions.\n\nLooks like rcloud.iip is the culprit, as when I enable that one, the tooltips disappear.\n", 
          "I think they come and go of their own volition. There are many things that may appear to cause or solve the problem temporarily.\n"
        ], 
        "number": "1211", 
        "title": "tool tips are missing for cell controls"
      }, 
      {
        "comments": [], 
        "number": "1203", 
        "title": "search/replace with regular expressions"
      }, 
      {
        "comments": [], 
        "number": "1201", 
        "title": "example(txtProgressBar)"
      }, 
      {
        "comments": [], 
        "number": "1199", 
        "title": "different markdowns should join as one"
      }, 
      {
        "comments": [], 
        "number": "1198", 
        "title": "splitting code inside markdown does not open/close the code block"
      }, 
      {
        "comments": [
          "@s-u, I just tested the interaction on develop (which has input & compute combined), and the behavior is kind of strange:\n1. sending an interrupt with the stop button during `readline()`, does not stop the current cell, but it seems to get queued up and stops the _next cell_.  Seems you can even send two SIGINTs and cancel two later cells.\n2. sending an interrupt during debug gets completely eaten.  this appears to be the same as the R command line behavior, where it just sends you another `Browse[1]>` prompt. maybe there is nothing we can do about this, but it seems weird to me.\n", 
          "ESC might be better than ctrl-C because ctrl-C is copy on Windows and might be unexpected in a browser application.\n"
        ], 
        "number": "1196", 
        "title": "ways to cancel input"
      }, 
      {
        "comments": [
          "R is usually not expecting multi-line input anyway, delaying.\n"
        ], 
        "number": "1195", 
        "title": "input widget should expand when there is more than two lines"
      }, 
      {
        "comments": [], 
        "number": "1194", 
        "title": "The 'notebook info' popover appears at a fixed position after resizing the Notebooks div"
      }, 
      {
        "comments": [
          "Yes it would be nice. One complication is that for now, selecting a notebook opens it. It might be confusing to have an interface where the first click opens a notebook but later shift-clicks just add to the selection.\n\nThe folder commands are easier, #716 and #1149 cover these.\n"
        ], 
        "number": "1186", 
        "title": "Multiple notebook selection"
      }, 
      {
        "comments": [], 
        "number": "1184", 
        "title": "broken add-ons cause RCloud not to load"
      }, 
      {
        "comments": [
          "The reason for the current behavior is kind of weird.\n\nWhen we load a notebook in the notebook controller's `on_load`, we take the content and language, but not the extension.  Then later, in the cell model's `change_object`, we regenerate the part name from the cell id and language, fetching the extension using the language.\n\nObviously we can't generate a part name for an unknown language, but if we held onto the part name, then we wouldn't have this problem.\n\nBut the idea that a cell doesn't have a filename goes back to prehistory, so this is somewhat hard to unravel.\n", 
          "Strangely, if a notebook contains Python cells but Python support is not enabled through rcloud.conf, the notebook will load but cells won't run and trying to insert a new python cell throws\n`Error: rcloud.update.notebook: Validation Failed`\n\nThis is worse than outright failure, IMO.\n"
        ], 
        "number": "1166", 
        "title": "notebook dies if any of its cells are unsupported languages"
      }, 
      {
        "comments": [
          "Note: if it's someone else's notebook, then it should not get saved.  It should stay on the setting while the notebook is open, but `rcloud.set.notebook.property` will not allow setting the property for someone else's notebook.\n\nIt's possible this was user error, but I will test again when I have a chance.\n", 
          "Really should be per user per notebook setting, defaulting to what the owner set it.\n"
        ], 
        "number": "1161", 
        "title": "shareable link type does not always persist"
      }, 
      {
        "comments": [
          "That's a great idea. I am looking into how to make the cell commands tab extendable. It should be possible to implement this as an extension in 1.3.\n", 
          "It's possible to add the UI as an extension.  It may be possible to get the timings by [monkey-patching](https://en.wikipedia.org/wiki/Monkey_patch) the `rcloud.r` language extension, or the cell views, or some other deviousness; I can't think of a place to get the timings directly.\n", 
          "As noted in #1926, now that we have a cell status light, we just need to expose those state transitions as an event, and then this can be implemented as an extension (or at least outside of the convoluted cell_view.js).\n", 
          "Do you see it looking something like this?\n\n![image](https://cloud.githubusercontent.com/assets/2493614/19569771/d4bf40e0-96ee-11e6-95f7-47d6d83d0c56.png)\n\nI was originally thinking of a tooltip, but that's a little annoying if you wanted to check the performance of multiple cells. Perhaps we can adopt a tooltip _and_ a bit of text?\n"
        ], 
        "number": "1158", 
        "title": "Feature Request "
      }, 
      {
        "comments": [
          "I think this is an OSX issue not an RCloud issue. It does cause us some grief though, see esp #493.\n\nYou can make scrollbars visible everywhere:\nhttp://osxdaily.com/2011/08/03/show-scroll-bars-mac-os-x-lion/\n\nThat's not very satisfying though. Suggestions welcome.\n", 
          "I think I misunderstood this ticket.  When this bug manifests, there is no scrollbar at all. It is not just that the scrollbar is not visible.\n\nWe don't support old firefox - it should be in the 30s, anyway. But I think I have seen this on recent browsers, so keeping it open.\n"
        ], 
        "number": "1157", 
        "title": "no scrollbar for file upload on firefox"
      }, 
      {
        "comments": [
          "I guess even publish notebooks option should also go into settings panel.\n", 
          "Actually, Publish Notebook is a per-notebook command.  \n\nMaybe removing Show Source will make this slightly less confusing. Probably not.  But at least it's one less thing in the Advanced menu.  :wink:\n"
        ], 
        "number": "1152", 
        "title": "put \"Show Source\" in Settings"
      }, 
      {
        "comments": [
          "Note this is sort of a crop/cull in the time dimension.  :wink: \n", 
          "One way to do this without rewriting history (which is generally considered a bad thing; see [Fringe](http://en.wikipedia.org/wiki/Fringe_%28TV_series%29)) is to create a new notebook with only the chosen versions, and then remove the old notebook from view.\n\nOn the one hand, this would not help if there are references to this notebook id, either within the notebook or from another notebook.\n\nOn the other hand, if other notebooks would break because they refer to a version of this notebook that is getting deleted, that is probably worse.\n", 
          "Blue-sky thought here.  Maybe notebook versions (say, my notebook \"foo\" version \"bar\") could have an attribute of \"referred to by another notebook\"?  To go further, we could keep track of all the specific notebook versions that reference notebook \"foo\" version \"bar\". This would likely mean implementing and constantly updating something like a notebook version cross-reference tree somewhere.\n\nThen, if the owner tries to delete/squash a referenced version of \"foo\", they could be warned that they might be breaking the referring notebooks, and what those specific referring notebooks are.\n", 
          "We don't really keep track of references: like everything Web, links are one-way. So that would be a pretty huge undertaking and not guaranteed to work. \n\nSince users are used to forking their own notebooks without history, I think forking with specific history versions would be easy to understand.\n\nProbably users will use this when they are just about to publish, so this works well for the first release. Unfortunately it does not cover the case where they want to clean up for release 2.0 of the notebook. One could imagine some imitation of branching where you have a release notebook you are  repeatedly merging to, but that's another topic for another day.\n", 
          "Also github gist does not support history rewriting, so we would have to do an end run and check out the gist as a repo if we wanted to rewrite. \n"
        ], 
        "number": "1145", 
        "title": "squash untagged history versions"
      }, 
      {
        "comments": [], 
        "number": "1142", 
        "title": "interruption for python"
      }, 
      {
        "comments": [], 
        "number": "1139", 
        "title": "refresh version histories on selecting \"terse dates\""
      }, 
      {
        "comments": [
          "@sujitbehera27 also points out,\n\n> when we write something in command cell and without executing we fork it it's lost in the new notebook command cell.\n\nwhich is scary\n"
        ], 
        "number": "1127", 
        "title": "prompt history should be duplicated to a forked notebook"
      }, 
      {
        "comments": [
          "Thanks @sneha-bharti. Good catch!\n\nWe may not be able to fix all of these concurrency bugs but it's important to think about them. We designed the architecture as if nothing is interruptible but of course that's not so when there are continuations / promises involved. \n\nPlease continue to look for more odd behavior when interacting with RCloud while it's working on stuff.\n", 
          "Is the error displayed in the file upload pane related to this bug?\n", 
          "No, that error isn't related to the bug.\nAsset files automatically detect a known language. I think since the asset has been deleted, it cannot find the language of the file. So the error.\n", 
          "To make sure , user can not click remove icon until the content is loaded, Can we append remove icon to the filename_span once content is completely written to the body?\n", 
          "I guess that might work.  I'm not sure it's worth the effort though. As I said, there are bound to be a lot more of these bugs and I'd hope for a more comprehensive solution rather than trying to fix each one as it comes up. \n"
        ], 
        "number": "1120", 
        "title": "Deleting an asset before its content gets visible shows the asset content"
      }, 
      {
        "comments": [], 
        "number": "1114", 
        "title": "drag asset feedback is wrong on Windows"
      }, 
      {
        "comments": [
          "I think this is pretty far out of scope.  \n\nWhy wouldn't you just use gchat? Is the problem discovering someones social network aliases?\n", 
          "Makes sense.:)\nAnd a huge work too.\n", 
          "It would be great to be able to click on the user and get more info.  I do this in github all the time, to find out what other projects they are contributing to, if they have a public email address, etc. \n\nMaybe once we have a popup for notebook info we should also consider one for user info. I don't know if there is a way to link from there to a new \"hangout\" (or whatever they are calling it now), a link that opens a new chat.\n", 
          "Can we have something like this in jsfiddle. Look at the right sode where users have links for \ntwitter,github we can also add other links also which may be suitable for us.\n![links](https://cloud.githubusercontent.com/assets/391355/5236902/155086ea-782a-11e4-90bd-c2b7e53b1d22.png)\n", 
          "Yeah, exactly.  That's the same kind of info that GitHub provides.  Again, I'd vote for a popup, since it's not the kind of info you keep around, and we're pretty tight on screen space.  But I could be convinced otherwise.  Once we get some feedback on the notebook info popup, let's take another look.\n", 
          "I agree the info pop up is the right place to put.\nBut currently we can add only github as we have the githubuserid with us. Not sure if we need any other link also.\n"
        ], 
        "number": "1111", 
        "title": "Can we have live chatting functionality in Rcloud."
      }, 
      {
        "comments": [
          "like \"stop\" and \"really stop\"? ;)\n\nYes interrupts in R are cooperative, i.e. they are only signaled, but the code has to enter a safe point before they are honored - and packages that don't check interrupts in their C code will prevent interrupts.\n\nMaybe the first click is INT and the icon changes to something like skull and bones at which point another klick kills the session.\n\nI'm not sure if it's a UI issue (just need better visual feedback that stop was signaled just not honored yet) or a terminate-vs-interrupt issue.\n", 
          "That sounds good. Retitling and labeling as enhancement\n\nI haven't yet seen the problem myself, guess I need an uncooperative C library to test it.\n\nI suggest:\n- Icon turns to something animated while it's trying to interrupt. Maybe a throbbing square.\n- Tool tip now says Kill.\n- Clicking again brings up confirmation dialog: do you really want to kill your session?\n- Killing needs to both send the stronger signal and immediately create a new session. Shouldn't be too hard but not trivial.\n"
        ], 
        "number": "1089", 
        "title": "Something stronger than SIGINT"
      }, 
      {
        "comments": [
          "My Notebooks are different between Notebooks I Starred and People I Starred, because I may not have all of my own notebooks starred.  \n\nThe notebooks under People I Starred and All Notebooks are the same, but it's a different set of users.\n\nI agree it's confusing, but I think the confusion arises from thinking of oneself as just another user.  This design has sort of evolved this way.\n", 
          "I guess no one has any thoughts on this.  :-(\n", 
          "I like having My Notebooks under all 3 trees (Notebooks I Starred, People I Starred, and All Notebooks).  It provides quick access to My Notebooks (or a subset in the case of Notebooks I Starred) not matter what sub-tree I am looking at.\n\nIf we removed My Notebooks from \"People I Starred\", then the only place to find all my notebooks would be under All Notebooks.  I like having my own full list of notebooks as part of the \"short list\" under People I Starred.\n", 
          "Thanks Gus.  Well said.\n", 
          "My Point of View was to have My Notebooks as a separate category itself just as People I Starred , All Notebooks etc. For us who understand the layout it seems trivial but for new users logically it should be separate from People I Starred. I am only expanding the notion of say having 'My Documents' in our PC's being treated as a separate category from Public Documents and things like that. \nSo if we remove My Notebooks from \"People I Starred\" It should be listed on the top as a separate category of its own . It would also going forward help when we introduce concepts such as \"Team Notebooks\". Thoughts ? \n", 
          "Ah!  I had not realized that elevating \"My Notebooks\" to a top-level was what you were suggesting.\n\nI am open to that, especially if the plan is to have \"Team Notebooks\" also be a top-level.  I would still lean toward having My Notebooks under all 3 trees (Notebooks I Starred, People I Starred, and All Notebooks), as removing My Notebooks from all the Notebook trees seems like it might be counter-intuitive.\n", 
          "Okay, reopening, retitling, relabeling\n", 
          "Would a better title be \"duplicate My Notebooks at top level\" ?  Removing My Notebooks from the other sub-trees seems like it might confuse folks, IMHO.\n"
        ], 
        "number": "1081", 
        "title": "Duplicate My Notebooks to top level"
      }, 
      {
        "comments": [], 
        "number": "1075", 
        "title": "sort all notebooks by date"
      }, 
      {
        "comments": [
          "Unfortunately, the side panes can still load before they are sized, continuing the distracting \"curtain effect\".\n", 
          "Is it. It was very fast in my local so for testing I had put breakpoints to see if it loads after both panels are loaded. I think my testing was not correct then. Let me check it in a different way.\n", 
          "Not your problem, I was just noting that the original motivation for this issue still is not resolved. Your PR still helps.\n\nI am actually seeing different behavior running locally than on rcloud-2, so I think it may work there.\n", 
          "Ok so now am loading message after loading the tree (load_tree) . Ideally we should show it after this because this is the first item which gets loaded for the user once he is authenticated and authorized.\nI took some screen shots by placing breakpoints.Let me know if this is right.\n![delay1](https://cloud.githubusercontent.com/assets/391355/5398079/8470e0ae-812d-11e4-9223-af39694fb9ea.png)\n![delay3](https://cloud.githubusercontent.com/assets/391355/5398080/8693606e-812d-11e4-9255-449307023415.png)\n"
        ], 
        "number": "1074", 
        "title": "delay welcome message until side panels are in place"
      }, 
      {
        "comments": [
          "Hi Ralph, \nIf you mean evaluate issue then no. I haven't looked at googleViz. Will see what is going on there and get back to you. \n", 
          "Ok \u2013 it\u2019s a new problem with 1.2.  Also note that it is context dependent \u2013 it doesn\u2019t happen in my example if you put it first\n\nRalph\n"
        ], 
        "number": "1068", 
        "title": "googleViz -  comment line printed "
      }, 
      {
        "comments": [
          "Completed implementation and tested its working fine in SOLR 4.7 .\nNeed thorough testing.\n", 
          "Today I heard from IT. We are upgrading to SOLR 4.9. They have started bench pressing the 4.9 release and should have it by the end of this month if it passes all checks. Just thought if there are some specific features of 4.9 we would be interested in\n", 
          "I have changed the delete query in xml format so it will work in all versions. But there are lot of features in 4.9 (http://lucene.apache.org/solr/features.html) which we can make use of.\nIt might solve our sorting problem too  as it has\n\" Allow configuration of top results for a query, overriding normal scoring and sorting Simple join capability between two document types\"\nI will do a set up with 4.9 and explore.\n", 
          "@sujitbehera27 I will keep you updated of the result from the bench press once IT completes and send out a formal notice to me.\n", 
          "Deferring\n"
        ], 
        "number": "1062", 
        "title": "Deleted notebooks still appear in search results. Implementation of delete functionality in SOLR."
      }, 
      {
        "comments": [
          "If it is size, it is another manifestation of #984.  Does look like the same symptoms.\n", 
          "Pretty sure this is a duplicate but leaving open to test this important file.\n", 
          "Wasn't able to repro this on Chrome/OSX, where I was seeing similar problems earlier.  (#984 is Chrome-specific.)  \n\nWill try Ubuntu & Windows another day.\n", 
          "Was not able to reproduce on 3 OS x 2 browsers.  However, I was able to reproduce #984 file upload using d3.js as the test file.\n\nWill keep this open but put it on Unknown until someone reports an operating system and browser where they are seeing this.\n"
        ], 
        "number": "1059", 
        "title": "Error in uploading certain files as Assets"
      }, 
      {
        "comments": [
          "It would be neat if when the title is edited, the navbar layout fits it vertically,  as happens now by accident. \n", 
          "Automatic ellipsis might help for the last step\n\nhttp://daniel.furzeface.com/blog/snippet-text-overflow-ellipsis/\n", 
          "I will look into it.\n", 
          "Behavior : Make responsive layout for navbar\n\nDesign :\n      1> Using text-overflow ellipses\n      2> Fix navbar width\n      3> Show component in block(Style)\n      4> Need to look into fluid layout as different components on navbar gets cluttered if window size changes\n\nQuestion : Is it worth implementing fluid layout, as it is a change in container but it doesn't break any feature as such apart from style issues?\n"
        ], 
        "number": "1055", 
        "title": "give navbar responsive layout"
      }, 
      {
        "comments": [
          "What the..?  Thanks!\n", 
          "Followed the above steps and tried a lot not able to reproduce,couldn't. Are you on windows?\n@sneha-bharti please give the steps to reproduce.\n", 
          "The steps are:\n1. Make sure you have, say, two or three cells in the notebook\n2. In the prompt cell, write some code (which takes a bit of time to execute) and enter\n3. RCloud will leave the cell and wait for its execution, with cursor in the next prompt cell\n4. Click on the cell in which you ran the code and type something. (you have to be really fast in this)\n5. After the output comes, delete any previous cell\n6. The moment you delete, cells will shift upwards and will overlap the previous cell.\nSometimes, the behavior comes even on skipping the 5th step!! (rare)\nIf it still doesn't come, please let me know\n", 
          "@sneha-bharti, is part of the problem #993, that it's inviting you to type in a cell that actually is executing?\n", 
          "Yes. But the cursor won't appear. \n", 
          "I'll be working on this.\n", 
          "@agrawal-mohit, we are considering a design where the cells only become editable on demand, for efficiency reasons as well as to make it feel more like an interactive shell.\n\nPlease test whether this bug is present on the feature/passive-cells branch.  I'll know in about a week whether we are going with this new approach.\n", 
          "I am unable to reproduce this on Firefox/Chrome on OSX/Ubuntu.  \n\nThe cell behavior has changed a lot, but I don't know if that would affect this, because I have never seen it.\n\nIf anyone can repro, please comment.\n"
        ], 
        "number": "1048", 
        "title": "Prompt cell overlapping the output"
      }, 
      {
        "comments": [], 
        "number": "1041", 
        "title": "timestamp on notebook may be inconsistent with history timestamps"
      }, 
      {
        "comments": [
          "IMHO, it should fail.  Say I was told by the notebook developer to use tag \"foo\", then the developer changed the tag to \"bar\" without telling me.  I'd want that to fail instead of silently directing me the latest version.\n", 
          "@gordonwoodhull , Can we have confirmation dialog whether user wants to continue with current version of a notebook OW load previously opened notebook/login.R page, please suggest\n\n![image](https://cloud.githubusercontent.com/assets/4454555/4991229/0f5863ec-69b7-11e4-9d30-6e0e5cb21d61.png)\n", 
          "Sure, but please use the fatal_dialog (Aw Shucks): this is exactly the kind of situation we created for.\n\nThe second sentence of the message should read: \"Please click Continue to load the most recent version of the notebook\".  \n\nThe fatal_dialog provides an Ignore button which just closes the dialog and leaves the GUI in an unusable state.  It doesn't need to be mentioned.  It is really only useful for copying any error messages from the session pane.\n", 
          "Patch was delivered, but is incorrect / needs rewriting.  Deferring this issue.\n"
        ], 
        "number": "1039", 
        "title": "what if the tag doesn't exist?"
      }, 
      {
        "comments": [
          "@gordonwoodhull This is fixed I suppose. I was just testing and can see tags in both view as well as mini.html \nhttp://127.0.0.1:8080/view.html?notebook=8fe5406659540f8c1a4f&tag=testleaf\nhttp://127.0.0.1:8080/mini.html?notebook=8fe5406659540f8c1a4f&tag=testleaf\nLet me know if I failed to understand the issue here.\n", 
          "@sujitbehera27, it works when you are opening it from edit.html because we fixed #1044 shareable link using tags.  \n\nHowever, if you explicitly load a view.html or mini.html page using `&version=...` and the version is tagged, it doesn't automatically change the URL to show the tag, the way edit.html does.  That's what this ticket is about.\n", 
          "I will work on this.\n", 
          "Behavior :\n1> For edit.html if user selects version for a tagged notebook, url automatically changes to tag if it was tagged.\n2> Same should work for view.html and mini.html.\n\nDesign :\n1> Find the mapping of version and tag. \n 2> change the version to tag change logic in mini.js and view.js same as that of edit.js.\n3> Load changed url which contains tag in place of version if there is a tag available for that version.\n", 
          "Sounds good, @souravkjha.  \n\nJust to clarify, it's not necessary to load any new page; we can use the same html5 history api edit.html uses, to change the URL without loading anything.\n", 
          "This has been fixed, PR #1155  has been raised.\n", 
          "Patch was delivered, looks correct but still needs careful review.  Deferring this issue.\n"
        ], 
        "number": "1037", 
        "title": "view/mini.html show &tag= instead of &version= when there's a tag"
      }, 
      {
        "comments": [], 
        "number": "1035", 
        "title": "support tagged versions for notebook.R"
      }, 
      {
        "comments": [
          "It's a good idea but I don't think it can be done.  Unlike for assets, there is no URL to display a dataframe.\n\nInstead, we will have to have ways to expand side panels or open them in a floating window.\n"
        ], 
        "number": "1033", 
        "title": "Link in dataframe section to open in new tab"
      }, 
      {
        "comments": [
          "It is Chrome DevTools related bug [#424544](https://code.google.com/p/chromium/issues/detail?id=424544), [stackoverflow.com/questions/26894718](http://stackoverflow.com/questions/26894718/error-shows-failed-to-get-text-for-stylesheet-no-style-sheet-with-given-id#26927842).\n", 
          "Thanks @laukstein! That's good to know.\n"
        ], 
        "number": "1010", 
        "title": "Failed to get text for stylesheet 104"
      }, 
      {
        "comments": [
          "I will work on this.\n"
        ], 
        "number": "996", 
        "title": "environment viewer could allow expanding/collapsing arrays/objects/etc"
      }, 
      {
        "comments": [], 
        "number": "995", 
        "title": "workspace viewer should have a link for function text"
      }, 
      {
        "comments": [], 
        "number": "992", 
        "title": "use icon-button for search results ordering"
      }, 
      {
        "comments": [
          "One question if a notebook has been forked then how it is readonly because it belongs you now and you can write on it. Please let me know if my understanding is wrong.\n", 
          "It belongs to someone else (someone else forked it) or you are looking at an old version. \n"
        ], 
        "number": "963", 
        "title": "readonly indicator has weird layout now"
      }, 
      {
        "comments": [
          "It's a good idea.  I guess I would side with the automatically generated kind, generated from headers like on Wikipedia or some Markdown TOC implementations.\n\nHowever, as you note, there might have to be some tricks to make the pieces of Markdown in different cells be numbered together. And also as you say, it would either require running the whole notebook or some sort of caching.\n\nWe are planning to have some sort of result/output caching like IPython has; perhaps this will help. \n\nI have no idea how to get the numbering right in the face of cell reordering, but where there's a will...\n", 
          "Thanks about result caching note... It will make life very easy (and has additional benefits like publishing notebooks as html with some \"representative results\").\n\nFully agree about how hard it is to get numbering after reordering. The IPython stuff is pretty mundane and refreshes after rerunning the TOC generation. It is simple enough if we do not insist on realtime numbering. \n"
        ], 
        "number": "929", 
        "title": "Feature Request"
      }, 
      {
        "comments": [
          "Yes I've had trouble with this too.\n\nHmm I wonder what we could do about this. The whole point of mini.html is that it has no built in UI; it's entirely generated from R. Logging something to the console will not help most users. \n\nI guess it could maybe have its own UI just for when the notebook.R call fails.\n"
        ], 
        "number": "928", 
        "title": "Some message or hint on session out for mini.html page"
      }, 
      {
        "comments": [], 
        "number": "914", 
        "title": "ensure_image_has_hash is choking on random UI images"
      }, 
      {
        "comments": [], 
        "number": "912", 
        "title": "firefox"
      }, 
      {
        "comments": [
          "Wow, that's scary.  I've never seen it.  Any idea how to reproduce this consistently?\n", 
          "I still haven't seen this.  Did it ever reappear?\n", 
          "@sneha-bharti were you able to reproduce this again with the latest code.\nI tried this in three machines and in both chrome and firefox but didn't get a single time.\n@gordonwoodhull If we are not able to reproduce this we can close this issue I think.\n", 
          "This behavior occurs rarely, so hard to capture. I guess I haven't noticed it yet with the latest code\n", 
          "Again faced the issue with the latest commit 8c6d046f559eb18ce25779a408be724ae641b592: \n1. Delete the notebook\n2. Load the notebook using its ID\n![notebook_name_change](https://cloud.githubusercontent.com/assets/5227441/4703076/dd6aa8dc-5867-11e4-9f70-3b3dad551950.png)\n", 
          "Hey @gordonwoodhull , just to update on this issue. Previously I didn't face the above problem . But today I am also getting the issue (commit : a2e618794b2eef836d18b78e7240345a2d0c672b) \n\n![image1](https://cloud.githubusercontent.com/assets/5258841/4766126/81513e08-5b4b-11e4-92a4-41a67efaffbb.png)\n\nOn reloading, the problem disappears\n", 
          "eerie... i'm scared of this one\n", 
          "with commit: f395713ab963c414faeb47063df1e92b12efc341, i haven't faced this issue yet. Its working fine on the test case!!\n", 
          "I'm guessing this may be another platform (Linux)-specific bug. \n\nLike #1031, this is the kind of thing that can sometimes happen with resource exhaustion... not so much memory but graphic resources.  I am going to go out on a limb and guess that Chrome has bugs.\n"
        ], 
        "number": "896", 
        "title": "Notebook's Panel is reflecting the name of the deleted notebook"
      }, 
      {
        "comments": [], 
        "number": "891", 
        "title": "quicker credential re-up"
      }, 
      {
        "comments": [
          "finding:\nrjson package fromjson method is throwing error.\nsolr.res <- fromJSON(solr.res)\n", 
          "The simple word \"content\" fails.\n\n@sujitbehera27 is this something you can handle for 1.2?  \n", 
          "No I had investigated. This is thrown from Rjson package itself. Not sure might be we need to do something in the rjosn package itself. I wil give a try at the last.\n", 
          "@gordonwoodhull : This bug is very unlikely to happen . The cheap solution is I can put a check on this and not process it. But that will be ugly. Need to spend time fixing rjson package. So we can move it to next milestone.\n", 
          "It seems like any string containing the word \"content\" will fail, so maybe it's not so rare.  But I agree it is not a serious problem and we shouldn't special case it.  Moving to 1.3.\n", 
          "investigate better json libraries\n"
        ], 
        "number": "883", 
        "title": "\"content-type\" as a search field throws error "
      }, 
      {
        "comments": [
          "It is indeed annoying to have these workaround at the UI level, but I think it will take some effort to untangle them.  Pushing to 1.3\n", 
          "This essentially means implementing [shell.fork_my_notebook](https://github.com/att/rcloud/blob/develop/htdocs/shell_tab.js#L137-L161) somewhere in `githubgist`. \n\nI think @s-u said the copy-instead-of-fork functionality has already been implemented server-side - perhaps just for the foreign case?\n\nBut I just noticed one annoying special case: notebook numbering happens [very much on the client side](https://github.com/att/rcloud/blob/develop/htdocs/shell_tab.js#L137-L161) right now, examining the cussin' jQuery.tree because that's the only record we have of folders and the notebooks in them.\n\nA hacky solution might be to determine the names client-side but implement the copy-instead-of-fork server-side.\n", 
          "We'll need to finally do this for 1.8, since we finally have a gist server without this limitation.", 
          "@gordonwoodhull will add flag to disable the workaround on the client side.\r\n\r\nEventually @s-u may implement the workaround for the GitHub backend."
        ], 
        "number": "831", 
        "title": "self-fork work-around should not be part of RCloud core"
      }, 
      {
        "comments": [
          "In particular, the mouse events over the Help pane (which is an iframe) get lost.  \n\nhttp://stackoverflow.com/questions/5261328/receive-mousemove-events-from-iframe-too\n"
        ], 
        "number": "820", 
        "title": "Resizing left panel over help pane doesn't work"
      }, 
      {
        "comments": [], 
        "number": "819", 
        "title": "The user should be able to resize by dragging the boundaries for all the divs ( File upload, Assets, Sessions, Search, etc.)"
      }, 
      {
        "comments": [
          "I can think of an even easier approach: simply prepend trash/ to the name, and then add the special cases so that the trash folder is not shown in the regular folders, and is shown at the top level. \n\nHowever, now we run into the inconsistency of having trash be top-level when My Notebooks is not #1081\n", 
          "For notebooks in the Trash folder, the trashcan icon for deleting would be replaced by some other icon and an \"undelete\" function?\n", 
          "Right, it should work pretty much like the trash can in Windows or OSX. \n\n(Except that even when the trash can is emptied, the notebooks are still on GitHub.  We could consider adding a stronger command Empty and Delete from GitHub/Repo, with a key modifier, but that's a separate issue.)\n", 
          "I guess it's an open question whether there are subfolders in the trash can: when I first filed this, I thought no, but now I'm thinking you might want to restore a folder.\n", 
          "@sujitbehera27, this one is particularly tricky, so don't get hung up if you can't solve it. \n\nThe notebook tree code is some of the earliest RCloud code, and it got really tangled because it went through rapid growth last year. I think I have cleaned it up a lot but don't feel bad if you have to give this back to me. (Same with #522.)\n", 
          "If there are not subfolders, then the display problem becomes very similar to #522 sorting user's notebooks by date, because the folders go away and notebooks are displayed with their full path.\n", 
          "@gordonwoodhull : Am thinking of below design. Please let me know if its ok.\n\nBehaviour:\n1>There will be a small trash can ikon with label as \"Deleted Notebooks\" at the root level as \"Notebooks I starred\".\n2> It will not have any folder structure and shown plat at same level.\n2>On click of that it will show all the notebooks which have been deleted.\nQuestions : What should we show in the notebook-right section?\nI think we should show only last updated date , restore icon and permanently delete icon. \nOn click of which it will restore the notebook to its respective folder.\nOn click of permanently delete of that NB we will call our current delete function and delete it from RCS.\nThere will be a small ikon for clearing the entire trashcan just after \"Deleted Notebooks\" label at root level. On click of this we will delete all the notebooks in the deleted folder.\n\nDesign :\nCurrently we are removing the notebook from RCS using the current delete function.\nWe will use this function to clear items from trashcan.\nWe will have another function with will tag that notebook as \"deleted\" in RCS as explained below.\n\nFor non starred notebooks (\"sujitbehera27/system/config/notebooks/_\" ) we will store deleted notebooks(update RCS) as \"sujitbehera27/system/config/deleted/notebooks/_\"\nand for my_starred_notebooks\n.notebook/_/stars/sujitbehera27\" will go to .notebook/_/deleted/stars/sujitbehera27\n\nNow In order to populate the notebooks in the trashcan we will define two functions \"rcloud.config.get.deleted.notebooks\" & \"rcloud.config.get.deleted.starred.notebooks\" to get all deleted notebooks starred and unstarred.\n\nOn restoration from trascan \nFor unstarred :\n\"sujitbehera27/system/config/deleted/notebooks/_\" will go to \"sujitbehera27/system/config/notebooks/_\"\nFor starred:\n\".notebook/_/deleted/stars/sujitbehera27\" will go to \".notebook/_/stars/sujitbehera27\"\n\nFor properties restoration.\nFor restoring path currently we are deleting the \".notebook/da4f9138f18cbb4deaa8/description\" from the notebooks on click of delete\nBut we will not delete it from RCS as this can help us to restore the folder structure.\nRest all properties like starcount,visibility,last_commit etc are anyways retained.\n\nA.The state of metadata in rcs is as below :\n1) \".notebook/da4f9138f18cbb4deaa8/username\"\n2) \".notebook/da4f9138f18cbb4deaa8/description\"\n3) \".notebook/da4f9138f18cbb4deaa8/last_commit\"\n4) \".notebook/da4f9138f18cbb4deaa8/stars/sujitbehera27\"\n5) \".notebook/da4f9138f18cbb4deaa8/visible\"\n6) \".notebook/da4f9138f18cbb4deaa8/starcount\"\n7) \"sujitbehera27/system/config/notebooks/da4f9138f18cbb4deaa8\"\n8) \"sujitbehera27/system/config/recent/da4f9138f18cbb4deaa8\"\n\nB.State after delete(current delete)\n1) \".notebook/da4f9138f18cbb4deaa8/username\"\n2) \".notebook/da4f9138f18cbb4deaa8/description\"\n3) \".notebook/da4f9138f18cbb4deaa8/last_commit\"\n4) \".notebook/da4f9138f18cbb4deaa8/visible\"\n5) \".notebook/da4f9138f18cbb4deaa8/starcount\"\n\nC.With the above design it will look something like this:\n1) \".notebook/da4f9138f18cbb4deaa8/username\"\n2) \".notebook/da4f9138f18cbb4deaa8/description\"\n3) \".notebook/da4f9138f18cbb4deaa8/last_commit\"\n4) \".notebook/da4f9138f18cbb4deaa8/deleted/stars/sujitbehera27\"\n5) \".notebook/da4f9138f18cbb4deaa8/visible\"\n6) \".notebook/da4f9138f18cbb4deaa8/starcount\"\n7) \"sujitbehera27/system/config/deleted/notebooks/da4f9138f18cbb4deaa8\"\n\nTo summarize on delete of notebooks State A will go to State C and on permanent delete of notebooks from trashcan State C will go to State B.\n", 
          "As we discussed, I think it will be simpler to just rename the notebooks into trash/, if that is possible.  \n\nThis will not require any additional RCS keys, because the notebook will still be owned by the user, and starred if it was starred before.\n\nThen, emptying the trash (or permanently deleting a single notebook) will execute deletions as is done now.\n", 
          "Sure I am in mid of another issue after finishing that I will reanalyze it based on the comment and option 3.\n", 
          "We could consider having \"empty trash\" delete on github... or have multiple levels of delete, sort of similar to OSX Secure Empty Trash and the like. Not sure how you would wipe notebooks that have been deleted but not _really_ deleted.\n"
        ], 
        "number": "789", 
        "title": "notebook trash can / recycle bin"
      }, 
      {
        "comments": [
          "I can reproduce it. This is really strange. Thanks, Gus.\n\nEDIT: ok, we're not escaping the cell contents appropriately when they are executed, which means that cells containing HTML leak the content. Now, why does this _not_ happen when executing cell by cell?\n\nEDIT2: because `run_all` does extra things which trigger the bug. Fixing.\n", 
          "Reverting the commit which broke a lot of other things while fixing this.\n", 
          "@cscheid, could you have another look at your patch 670b39b345, when you have a chance.  It seemed to be incomplete and seriously broke other stuff, so I reverted it.\n"
        ], 
        "number": "786", 
        "title": "mini.html notebook inconsistent behavior when run in RCloud UI"
      }, 
      {
        "comments": [
          "Delayed to 1.3\n"
        ], 
        "number": "777", 
        "title": "session management"
      }, 
      {
        "comments": [
          "Also, #325, flashing the anchor cell.\n", 
          "And a related bug #773\n"
        ], 
        "number": "774", 
        "title": "scroll to matching cell from search result"
      }, 
      {
        "comments": [
          "Actually it's worse than #715, the whole window can scroll completely out of sight and there is no way to get it back:\n![image](https://cloud.githubusercontent.com/assets/1366709/3656540/9c508c08-1187-11e4-8890-62485bab25b6.png)\n"
        ], 
        "number": "773", 
        "title": "scrolling to cell using #partN causes scrolling bug"
      }, 
      {
        "comments": [], 
        "number": "772", 
        "title": "marshaling data from Python to/from R"
      }, 
      {
        "comments": [
          "that ocap needs to be emitted by knitr in the middle of a bunch of markdown. How do you propose to do that?\n", 
          "Hmm. However shiny does it? But I admit I haven't looked.\n", 
          "... which is just R generating html, apparently. Although they use iframes for safety.\n", 
          "So they hook deeply into the markdown-to-html generation?\n\nOur main problem when we use knitr is that knitr _quotes_ (understandably, and correctly!) the output. So we can't say \"<div>some fancy<script>javascript</script></div>\" as the result of a function call that is being evaluated inside knitr. That's the fundamental problem we'd have to solve.\n\n(ditching knitr is not an option, no :))\n", 
          "I am unclear, has knitr been replaced with rmarkdown?\nhttps://github.com/rstudio/rmarkdown\n", 
          "@s-u here's the conversation @cscheid and I had about unknitring over the summer.\n\nI guess we can avoid knitr for R cells, and we can use a single knitr and device context for Markdown cells... but how do we get at the charts that are within Markdown cells..? \n\nFor that we will probably need to voyage deeper into the RMarkdown universe.\n", 
          "We don't need to change anything about markdown cells - we keep everything as-is there, the knitr problems are only related to R cells.\n", 
          "For the record, the consequence is that you won't be able to debug markdown cells, but I don't think there is anything we can do about that.\n", 
          "Solved for R cells; the GUID capturing is still needed for Markdown cells.\n"
        ], 
        "number": "767", 
        "title": "Change deferred results to ocaps?"
      }, 
      {
        "comments": [
          "Being the owne, user should be able to see his private notebooks right. Only for other users private notebooks shouldn't be searchable. Please confirm.\n", 
          "That is consistent with my understanding.\n\nAlso, seems to me that when a notebook changes between private/not-private, the visibility in search results should also change appropriately\n\nOn Jul 17, 2014, at 11:50 PM, \"sujit\" <notifications@github.com<mailto:notifications@github.com>> wrote:\n\nBeing the owne, user should be able to see his private notebooks right. Only for other users private notebooks shouldn't be searchable. Please confirm.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/att/rcloud/issues/766#issuecomment-49392977.\n", 
          "Currently the visibility of notebooks is stored in rcs (in function rcloud.set.notebook.visibility) but we are not storing the \n \"public\": false/true\"\n attribute in git(ref https://developer.github.com/v3/gists/). Is there any reason why we are not storing it in git ?\nIn the current search code there is a bug in which the visibility param is not stored in solr when the user makes it public or private. Even the \"update.solr\" function is storing wrong param \"session.content$public\" which always returns false.\n So am changing that layer in order to get it from rcs (using rcs.get(rcs.key(\".notebook\", id, \"visible\") and store it in SOLR and then change the SOLR to take care of visibility of private notebooks if it doesn't belong the owner.\nPlease confirm if my approach is correct.\n", 
          "First, gist public/private means something different: it determines whether the id of the notebook is just a number or a 20-hex unguessable key.  Since there is no way to turn a public gist into a private one,  we decided to always use private gists in that sense.\n\nYour approach sounds right - the only thing I would suggest is please use the existing API `rcloud.is.notebook.visible` rather than copying and pasting that code.\n\nIn my opinion it would be okay, if it's easier, just not to return results for private notebooks even if they belong to the current user, although as Gus said, as soon as it becomes public it should be searchable.  I guess this would save SOLR even having to know about private notebooks or caring who is searching.\n\nMy rationale is that it would actually be kind of scary if you searched for something and got results in a notebook that you've kept hidden because you know it doesn't work very well.  At the very least we'd have to clearly mark that it's private.\n", 
          "Raised PR #807\n", 
          "It turned out that this did not interact well with using solr for pagination, and we ran out of time for this release, so regretfully, we are showing private notebooks in search again.  :frowning: \n", 
          "I will take it up for next release and make sure its done in the proper way by deleting from Solr.\nThere is another issue also related to solr delete. As in the current approach there is no delete from solr so if you search for a deleted notebook it shows up.  There is some issue with the current version fo solr in terms of deleting documents. So am planning to do a set up with the newer version and see how it responds to delete commands. Based on the outcome will implement the whole private public and delete of notebooks from solr.\n", 
          "Depends on #1062. \nWhen made private the delete function is called and on making it public need to make new insertion.\n", 
          "Completed. Need to raise PR.\n", 
          "Deferring this, need to upgrade SOLR and test the delete functionality.\n"
        ], 
        "number": "766", 
        "title": "Searching private notebooks"
      }, 
      {
        "comments": [
          "[init.js : 284]\npersisting the last loaded/shared notebook in local-storage using <code>window.localStorage['last_shared_notebook'] = getUrlParameter(\"notebook\");</code>\n\n[editor_tab.js : 405] \nloading the shared notebook from local-storage if local-storage contains last loaded notebook.\n<code>current.notebook=(window.localStorage['last_shared_notebook']===\"\"? current.notebook : window.localStorage['last_shared_notebook']);                                        window.localStorage['last_shared_notebook'] = \"\";\ncurrent_ = current;</code>\n", 
          "As noted in #836, persisting the notebook that was requested through the edit notebook button only solves a small part of the problem - the bug can occur whenever the notebook in the query parameter is not the same as the \"current notebook\" stored in RCS.\n", 
          "I'm not seeing this but I'm still seeing #629.\n", 
          "not fixed this release\n"
        ], 
        "number": "762", 
        "title": "reload doesn't always go to the same page"
      }, 
      {
        "comments": [
          "I am not sure but it is worth considering. \n\nI think when we have named versions it might be more helpful to keep the history open. But then if you really want to cross reference then two tabs/windows is the way to go.\n"
        ], 
        "number": "759", 
        "title": "Automatic closing of the list of history versions on switching to a different notebook"
      }, 
      {
        "comments": [
          "Over any inactive area of the notebook, such as area below notebook, below notebook tree, behind comments, etc.\n", 
          "explicitly cancel please wait mode when the dialog is closed manually. of course, this makes #1587 worse, but at least it's consistent.\n", 
          "endless spinny can still happen if loading doesn't take long enough for the please wait to show, but not due to the please wait\n"
        ], 
        "number": "758", 
        "title": "spinny cursor never goes away"
      }, 
      {
        "comments": [
          "notebook ced0bfe45ff688354b6c on public github\nmake.oc function\n"
        ], 
        "number": "753", 
        "title": "Silent failure calling js from R with bad parameters "
      }, 
      {
        "comments": [
          "I should have said sink(\"/data/users/rhknag/output\") - not sink() the end of sink\n", 
          "I haven't tested on the new version\n", 
          "`sink` works, but only in a compound statement, because `evaluate` uses `sink()` to emulate the event loop output. This will go away when we get rid of `evaluate` and use a proper REPL.\n"
        ], 
        "number": "751", 
        "title": "sink() doesn't work  - perhaps old news"
      }, 
      {
        "comments": [], 
        "number": "746", 
        "title": "preload python if there are any python cells?"
      }, 
      {
        "comments": [
          "this behavior seems to be consistent with IPython but not with knitr.\n"
        ], 
        "number": "740", 
        "title": "multiple python statements return one result?"
      }, 
      {
        "comments": [], 
        "number": "735", 
        "title": "do atomic asset rename"
      }, 
      {
        "comments": [
          "- this can land me in an inconsistent state with \"Could not initialize session. GitHub backend might be down or you might have an invalid authorization token. (You could also try clearing your cookies, for example).\" looping, unable to login, and clearing the cookies doesn't help.\n", 
          "No doubt this is a power-user bug and won't affect most people.  I mostly want to document it and eventually find a fix.\n\nWorkarounds:\n\n```\nsudo killall -9 RsrvCHx\n```\n\n(for now, on this Mac)\n\n```\nsudo kill -9 `ps -e | grep -i rser | cut -f 1 -d' '`\n```\n\n(more general, ugly and dangerous as heck)\n", 
          "The way this works is that any existing connections stay on the last version while all new connections get the new version (including packages, config etc.). That is very consistent and doesn't really cause problems in development, you just have to make sure you create a new connection when you want to test the new version. By killing all children, you just close all old connections, it has no effect on the new ones. Hence I don't see the issue here - the subject is false IMHO - nothing goes stale.\n", 
          "Of course I am talking about new sessions. Otherwise I wouldn't have opened the bug. Maybe it's specific to my machine.\n", 
          "Hey, you're not supposed to be online ;) I was changing `rcloud.conf` \"live\" on ecaz while switching between back-ends and had no issues. I really can't think of a reason why a session form teh new instance should be in any way affected by running children. Even if you upgrade a package it gets deleted, so the old session is referring to the orphan inode while the new session is using the new version - even if the old one is still being references by another process.\n\nThe only issues I saw were due to Chrome caching - we don't do a good job with headers from the HTTP pieces to specify cache validity, time etc.\n", 
          "I see.  If I restart Chrome completely, I can get through.  I am continually switching between public and enterprise github, so this is an issue for me.  \n\nIs it (the HTML generated by) login.R itself which is cached? Could we set that one file to expire immediately, somehow?\n", 
          "I don't know which piece in particular is problematic, but we're not setting any cache headers at all. We'd have to figure out under which circumstances Chrome caches and which pieces is crucial here and then set the headers accordingly (which in itself is trivial). The main issue here, though, is when does Chrome create a new WebSocket connection? The key here is that it may not re-use a socket that's already connected from earlier, but instead has to create a new one. So in that sense it may not be caching, but rather Chrome's optimization techniques that get into our way - but I'm not sure.\n", 
          "Okay, I can prove that RCloud is still _generating_ the wrong page after fresh_start - presumably Chrome holding open a connection to the old server.  \n\nI added a `<script>debugger;</script>` to the redirect page generated at the end of login.R.  I also tried adding a `<meta http-equiv='expires' content='-1'>` thinking that that might stop caching.\n\nNow Chrome breaks every time I try to load login.R - great.\n\nI swap rcloud.conf and do a fresh_start.  Load login.R - breakpoint still showing the old github authorization redirect.\n\nNow I can **change login.R to get different generated content** - e.g. change \"expires\" to \"EXPIRES\" and see the change reflected when I hit login.R again.\n\nSo it is not caching but the old server is still alive.  If I then use one of the nasty killall methods above, I force it to spawn a new Rserve and the new rcloud.conf is active.\n", 
          "Ok, so this is as I feared a Chrome problem - it's re-using the old connection. I don't know if there is any official way to control that. One way around that would be to force `Connection: close` so that Chrome cannot re-use old connections, but I suspect that may have performance implications -- but maybe we won't even notice.\n", 
          "BTW: is this specific to localhost? I have never seen this problem with naraj/tupile ... but then I always force-reload when testing RCloud ...\n", 
          "Force-reload doesn't help (you're never actually on login.R to force), and even closing the tab doesn't help. Only restarting Chrome or killing Rserve helps.\n\nI am pretty sure I saw this once when updating naraj in your absence, but I can't remember why it was an issue. I don't normally change rcloud.conf except on my own machine.\n", 
          "Update, I now use\n\n```\nscripts/shutdown.sh; sudo killall RsrvCHx; sudo killall RsrvSRV\n```\n\nin order to be sure to destroy all running processes.  Otherwise it is very difficult to rebuild `rcloud.support`\n"
        ], 
        "number": "734", 
        "title": "fresh_start goes stale"
      }, 
      {
        "comments": [
          "Good point.  Clarifying the title a little, because there's a \"view source\" option which is not working.\n"
        ], 
        "number": "729", 
        "title": "\"Hide Source\" doesn't work for Python cells in view.html"
      }, 
      {
        "comments": [
          "Such cells can be non-executable(disable Run button), but should be editable, can we make it similar to <cell-laguage>-Markdown?\n", 
          "I'm not sure if I understand: Markdown _is_ executable, because it can contain code.  (Right now only R code, but the intention is that it could be code of any supported language.)\n\nBut otherwise, yes I think you are on the right track.  The best way to test this is to add, say, a \"part12.c\" file to an existing notebook using the github gist interface.  \n\nFor example, I did this in notebook 12042f05fe4f913bc4b6 on public github, and get\n\n```\nError: Unknown language C\nat Object.Notebook.part_name (http://127.0.0.1:8080/js/rcloud_bundle.js:2783:15)\nat Object._.extend.change_object (http://127.0.0.1:8080/js/rcloud_bundle.js:1884:41)\nat Object.append_cell (http://127.0.0.1:8080/js/rcloud_bundle.js:2065:41)\nat append_cell_helper (http://127.0.0.1:8080/js/rcloud_bundle.js:2312:61)\nat Object.on_load (http://127.0.0.1:8080/js/rcloud_bundle.js:2361:17)\n```\n\nand RCloud completely fails to open the notebook.\n"
        ], 
        "number": "718", 
        "title": "what to do if a notebook language is not supported"
      }, 
      {
        "comments": [
          "Can I +1 my own issue?  I am always forgetting what notebook I was just looking at, would love to press back to get there.\n"
        ], 
        "number": "698", 
        "title": "browser history 'back' and 'forward' through notebooks"
      }, 
      {
        "comments": [
          "A lot of this is really just #681 - we don't have any defined behavior for merging Python and Markdown/R cells.\n"
        ], 
        "number": "696", 
        "title": "Error while trying to execute a Python cell after joining a Markdown and a R cell in it"
      }, 
      {
        "comments": [
          "Oh, crap.\n\nThis is going to be a hard one to fix, because we need to decide on a language-agnostic help functionality.\n\nWe should discuss this when we plan the merge of the `feature-langs` branch, where language support is provided via specific packages.\n\nGood catch.\n"
        ], 
        "number": "695", 
        "title": "No Help provided for Python commands"
      }, 
      {
        "comments": [], 
        "number": "682", 
        "title": "Make the automated test suite count"
      }, 
      {
        "comments": [
          "Yes, this is a really a mess right now. The right time to solve it will be after we merge the `feature-langs` branch, where languages are defined externally via configurations and extra packages.\n", 
          "What are the issues with merging `feature-langs` - does it just need to get reviewed?\n", 
          "Yes. I use a somewhat non-standard package convention in R that I'd like @s-u to review.\n", 
          "I think I can define the desired behavior pretty easily:\n- join python + python => python\n- join python + any other language => create markdown that embeds the python in the same way that R is currently embedded\n\nRight now it sounds like we might not be able to merge that branch in time for the release, so we probably can't embed python in markdown for 1.1, and we should just fail if the pythonness of the two cells differs.\n"
        ], 
        "number": "681", 
        "title": "Define behavior for Split and Coalesce of Python Cell with R cell and RMarkdown Cell"
      }, 
      {
        "comments": [
          "Those strange codes are escape codes for color in terminals: http://en.wikipedia.org/wiki/ANSI_escape_code\n\nWe get those from ipython when it tries to be cute about coloring its output. We should strip it or, if feeling brave, interpret them correctly :)\n", 
          "As I said elsewhere (not sure where :)) we should check the availability on startup and enable/disable Python support accordingly - with appropriate message, preferably.\n", 
          "In the feature-langs branch, we have a per-languag esetup/teardown procedure that could make RCloud report and error and quit if support for a requested language is not available.\n", 
          "Even if Ipython packages are pre-installed , sometimes, after I clone a new commit of RCloud, the python cells don't execute. I need to re-run the following commands for the python cells to be executed correctly .\n\nsudo apt-get install python-software-properties python-dev python-zmq python-matplotlib\nsudo add-apt-repository ppa:jtaylor/ipython\nsudo apt-get update \nsudo apt-get install ipython\n", 
          "@Arko2013, that is a different, and more serious bug.  Could you file it separately please?  We might be able to solve it by documentation, but it's still worrisome.  \n\nFWIW, I don't have that problem, but I'm only updating an RCloud instance in place, not cloning it afresh.\n", 
          "Sure .\n"
        ], 
        "number": "679", 
        "title": "wild error thickets if ipython dependencies not installed"
      }, 
      {
        "comments": [], 
        "number": "678", 
        "title": "html5 doctype"
      }, 
      {
        "comments": [
          "Yeah, I think this is really a bug, actually.\n", 
          "I can fix that if you'd rather do something else.\n", 
          "Thanks..  I'm working on dc, actually... I just report bugs as I find them.  \n\nRan into this while trying to figure out whether leaflet notebooks still work with the AMD stuff.  I think they do but the particular notebook I was testing needed a library and some data which I don't have locally.\n", 
          "I would claim this is a bug in `rserve-js` rather than rcloud, but in the `rserve-js` test suite there is a test specifically about raising exceptions and making sure they're handled by the error path (it's a bluebird `catch`). So I'm confused now.\n\nEDIT: Yeah, there's definitely something bizarre happening. I'm going to have to confer with Simon on Friday to see what's up.\n", 
          "Related:\n- #674 failed javascript parse unreported.\n- #753 silent failure calling JS with bad parameters\n", 
          "@s-u, I believe this is the issue we were talking about. Almost three years old, wow.\r\n\r\nPretty intense systems hacking. I would love to work on this if I can find a few days of concentration.\r\n\r\nLike #1376, I think this may have unexpected consequences since there may be errors being thrown and ignored, accidentally or harmlessly, which actually should be ignored. So I'm going to be cautious and put this into 1.8 (which we can deploy to research early if we like)."
        ], 
        "number": "669", 
        "title": "Rserve.wrap_ocap should detect errors"
      }, 
      {
        "comments": [
          "Hmm.  What are you trying to do? migrate2redis is a 0.7-0.8 or 0.8-0.9 converter.  It ports the individual config.json files from data/userfiles into redis (migrate2ff goes into the ff).\n\nAfter running this (if you really want to) you would have to run upgradeRCS1_0.R in order to turn the 0.9 config into 1.0 config.  That one uses rcloud.conf to decide what RCS system to use.\n", 
          "Afaik we don't have a ff-to-redis migration tool.\n", 
          "I have a flat-file RCS running on Rcloud 1.0 that I want to move to redis. If that's not possible, it's fine, but I think we at least ought to delete the scripts from the develop branch :)\n", 
          "Or upgrade them. \n\nYes, that's a useful purpose and you would expect a script named that to do that. \n\nMy guess at how to do that would be something in pure R that sets itself up with rcloud.conf to get the redis parameters, and then calls the rcs functions with the engine explicitly set to ff to read the existing, and writes using rcs with no engine set to do the redis part.\n"
        ], 
        "number": "660", 
        "title": "migrate2redis script doesn't migrate RCS as expected"
      }, 
      {
        "comments": [
          "Hmm. This is nasty. A few problems here.\n\nThe consistent behavior should be to remove the asset from the gist once the content, but leave the asset editor in a \"waiting\" state, just like when you remove the content from a cell. The 'link' should become disabled when the asset is in the waiting state.\n\nSo:\n- [ ] save the content when clicking 'link'\n- [ ] when updating raw urls from a gist, don't assume that all assets still exist. Null out the raw URL if the asset is not in the gist.\n  - [ ] disable the 'link' when there is no raw url.\n\nThis will still require careful testing once implemented, but the same annoying logic about deleting empty cells etc #338 should already be enabled for assets because they share a common root.\n", 
          "Thanks @gordonwoodhull .Once implemented, please let me know the expected behaviors and I shall \ntest and get back to you accordingly.\n", 
          "This error has changed to now failing on trying to read language properties from non existent files in the gist, but it's essentially the same problem.\n"
        ], 
        "number": "653", 
        "title": "After removing all the contents of an asset and saving the notebook, clicking on the link for that asset still shows the contents"
      }, 
      {
        "comments": [
          "Thanks @Arko2013, this is an interesting one.  I'm changing the title to better reflect the problem.\n\nNote both 'priv' and 'public' are private/hidden, that's why they are greyed out.  It looks like you are on a fresh installation and they are hidden by default.  The other user would have to click the eye icon to make them visible. \n\nIf you open someone else's hidden notebook, it will show temporarily, but it doesn't become discoverable just because you open it.  \n\nHowever, once it's starred by you it seems like you should see it under People I Starred and All Notebooks, even if no one else does.  And you obviously shouldn't get an error for unstarring it!!\n"
        ], 
        "number": "644", 
        "title": "starred private notebook of another user disappears and errs when unstarred"
      }, 
      {
        "comments": [
          "Weird.  Everything that happens with these buttons also happens with trash and insert cell.  \n\nSort of like what happens with the scrollbar in #493?  Any steps to repro?\n", 
          "1) This was on windows, so no scrollbar influence.\n\nNo easy way to repro in our experience, but we were clicking around a bunch on split cell and coalesce cell.\n"
        ], 
        "number": "642", 
        "title": "Sometimes the split cell/coalesce cell fail to be clickable?"
      }, 
      {
        "comments": [
          "Error displayed in session info:\n\n```\nCouldn't get a file descriptor referring to the console\n```\n\nIs this another thing that should be sent to the help pane?\n\nIt looks like the intention is expanded help.\n", 
          "now it opens a new tab with the absolute file path and the current server, which is a file not found.\n"
        ], 
        "number": "641", 
        "title": "vignettes"
      }, 
      {
        "comments": [
          "Isn't this is pretty much just reload, except without having to rebuild the notebook list etc?\n\nOr do you mean without starting a new session?\n", 
          "Without starting a new session, since you can _run_ a read-only notebook. Right now, people following it will either not get the new cells or will hit reload and have to rerun everything.\n", 
          "Got it.  Then I guess we would have to assume that cells are only being appended, or else invalidate (remove the results from) any cells where the source has changed.\n\nThat's a bit subtle... might also want to show changes by temporarily showing a border or something.\n", 
          "retitling\n", 
          "It's not nearly as hard as google docs/etherpad, because there is still only one owner/editor.\n\nIf we had live merging (or a non-gist backend), that would be another problem.  But we don't even have merging.\n"
        ], 
        "number": "637", 
        "title": "follow a live notebook"
      }, 
      {
        "comments": [
          "How are you envisioning the usage. Will it be like\n1. On click of slide show ikon somewhere an overlay on the whole screen (having some opacity on the current screen ) where there is a right/top and left/bottom scroll ikons scrolling which it will show each part content for that notebook.\n2. On click of slide show ikon it will open another tab just like out view.html where we will show the part contents as slides with a different stylesheet in the above manner.\n"
        ], 
        "number": "636", 
        "title": "Slideshow mode"
      }, 
      {
        "comments": [
          "This is especially annoying because it makes the semantics of \"merge cells\" unexpected. You can't merge all cells safely because the behavior will change.\n", 
          "c.f. #320 - it's the same issue\n"
        ], 
        "number": "628", 
        "title": "Annoying options() behavior with knitr?"
      }, 
      {
        "comments": [
          "This hurts debugging, though.\n", 
          "oh right, because it uglifies.  hmm, maybe we should finally have some concept of \"distribution\".  eh.\n", 
          "Looks like our internal deploy is taking 5-6 seconds just loading require dependencies.\n", 
          "there are also source maps: http://requirejs.org/docs/optimization.html#sourcemaps\n", 
          "... but they don't help with variables being named a,b,c yet\n"
        ], 
        "number": "619", 
        "title": "do requirejs optimization"
      }, 
      {
        "comments": [
          "upon showing a panel, all other panels disappear entirely:\n\n![image](https://cloud.githubusercontent.com/assets/1366709/2892357/0cd66232-d53c-11e3-9eae-7430fd8f9900.png)\n\n![image](https://cloud.githubusercontent.com/assets/1366709/2892351/04807f6e-d53c-11e3-91b0-780c837715fa.png)\n"
        ], 
        "number": "618", 
        "title": "panel layout gets messed up when there are errors loading"
      }, 
      {
        "comments": [
          "I'll be working on this.\n", 
          "@gordonwoodhull , this is what I'm thinking:\n\nBehavior : \nOn coalescing  two cells - one of language 'R' with another of language 'markdown'  having R code embedded, the R codes in both the cell merge without any extra newline added between them. Any newline already present remains there.\n\nDesign : \nA function opt_cr in notebook_controller specifically appends a newline character to the contents of previous cell. This function is to be removed from usage. \n\nPlease provide feedback, if any.\n", 
          "Thanks @agrawal-mohit. As we discussed, I'm pretty sure `opt_cr` is needed for some of the cases; it's apparently not needed for this case.  The cases are R+R, R+Markdown, Markdown+R, Markdown+Markdown; please make sure the other cases are unaffected by your change.\n", 
          "This has been fixed, PR #1154 has been raised.\n", 
          "Patch was delivered, but is incorrect / needs rewriting.  Deferring this issue.\n"
        ], 
        "number": "611", 
        "title": "extra line when coalescing  into R embedded in markdown"
      }, 
      {
        "comments": [
          "Note that although backspace is now disabled for help at both levels, gestures and context menu back in the help pane will still go to the main window if there is no help history.\n"
        ], 
        "number": "604", 
        "title": "correct way to deal with history in help"
      }, 
      {
        "comments": [], 
        "number": "597", 
        "title": "Annotate data-url images with notebook source"
      }, 
      {
        "comments": [
          "this is rcloud-2\n", 
          "User Manuals in PDF form are simply not built on the deployment machines (there is no TeX there), so this is not really an RCloud issue.\n\nTechnical papers link to an external site so it is blocked by the browser, you can open in in a new tab/window. Again, this is not under control of RCloud. All help content is passed directly from R.\n", 
          "Well, there's something goofy happening anyway, because if you click on \"User Manuals\" there's actually an error, regardless of whether you open in a new tab or a new window:\n\n```\nError in vignettes[i, \"PDF\"] : subscript out of bounds\n```\n\nThis needs some kind of fixing. (And I would argue that it would be nice to force the external links to at least work. Showing a link that is blocked by the browser _is_ an RCloud bug)\n", 
          "See above - PDFs are not build on the deployment machine.\n", 
          "Yes, that's the bug we need to fix. Do you disagree that clicking on a help that we show the user and having a \"subscript out of bounds\" appear is a bug?\n", 
          "It's the same what you get in R. If anything, it's a bug in R. Note that we have absolutely no control over what R produces in those HTML pages - it could be anything. If we work around it, the next R release can give something entirely different, so I don't see a point. It this particular case, the deployment should have a complete installation of R - the missing manuals is not the default.\n"
        ], 
        "number": "593", 
        "title": "help.start() issues "
      }, 
      {
        "comments": [], 
        "number": "590", 
        "title": "errors are trying to escape"
      }, 
      {
        "comments": [
          "So, I'm being somewhat facetious, but is there anything in RCloud.UI that we actually have to init in view mode?\n"
        ], 
        "number": "585", 
        "title": "View mode refactor"
      }, 
      {
        "comments": [
          "If switching notebooks is involved, it could mean something goes wrong in session reset is `session.js`, for example.\n", 
          "Last time I ran into this it was concurrency problems caused by trying to handle the browser back button.  \n\nI suspect (but I'm not sure) that something is changing the panel layout state and either trying to read or write user options while there is no session. \n\nIt does seem to be non-deterministic, whatever it is.\n", 
          "One way to repro is to click on a bunch of notebooks really fast.\n", 
          "Pushing past 1.0.\n", 
          "We got into a useful discussion on the completely unrelated #1051, moving here.\n\n@prateek05 wrote:\n\nI am facing a completely different problem. \nIt does not affect the general users as they will hardly ever notice it. \n\nHowever if you swift between your notebooks \nWebSocket is already in CLOSING or CLOSED state. rserve.js:974\nWebSocket is already in CLOSING or CLOSED state. rserve.js:974\nWebSocket is already in CLOSING or CLOSED state. \n\nNetwork shows multiple WS negotiations: \nedit.html?notebook=3b1a5188ae3xxxxx GET 101 Switching Protocols\nedit.html?notebook=3b1a5188ae3xxxxx GET 101 Switching Protocols\nedit.html?notebook=aa8e82b932bxxxxx GET101 Switching Protocols\n\nI don't know if this somehow related. Still chasing.\n1) Each notebook shift requires a new WSS\n2) First WSS finishes with 2 frames establishing another WSS for a new session which remains stable\n", 
          "I wrote:\n\n@prateek05, I think you're staring into the cold and fearsome eyes of #572.  Some pretty bad race conditions occur when one event chain is trying to open a session while another is closing it.  (And loading a notebook always closes the previous session.)  We don't really know what the correct behavior should be in this case.\n\nThe workaround is to not switch between notebooks so fast.  ;-)\n", 
          "@prateek05 wrote:\n\nAh I see. Yeah I traced it till everytime a new notebook is opened location.href.replace(/^http/,\"ws\").replace(/#.*$/,\"\") in session.js constructs a new connection with changed NB id. \n\nI think this is the right workflow with the work around of not changing NB's so fast. \nWe wouldn't want session to carry across two different Notebooks if that was the intention. \nAll is fine then :)\n", 
          "I wrote:\n\nIt's still a bug and it's blocking stuff like having a functioning Back button. You would expect Back to go to the last notebook, right? It doesn't, because it's too easy to click Back too fast and break it. So we just replace URLs and Back usually goes to something not RCloud.\n\nIt's just not a very high priority bug, because it would be fiendishly difficult to fix right, and people don't seem to miss it very much. You would want each navigation to cancel the last one safely; and you couldn't just use a lock because then you run the risk of queuing up lots and lots of notebook loads and then having to wait minutes for each one to load in turn.\n\nSo, we offer a workaround. \"It hurts when I do this!\" \"Well stop doing that!\" ;-)\n", 
          "@s-u wrote:\n\nCouldn't we solve this by having all callback check some ID that is identifying the current session against what they expect and have them fail silently if it doesn't since it means someone else is in charge? Then when we are catching WS errors we can compare if it's something from a dead session or not and ignore the former case. Just thinking aloud - I didn't try to think through all the scenarios :).\n", 
          "I wrote:\n\nAll callbacks everywhere? Sounds onerous. The problem is that loading a notebook is fairly complicated and it could fail at any moment when another event decides to kill the old session.\n\nIt might be easier now that we are promified than when we first faced the problem and we just had a ton of unaffiliated callbacks. But still, it's some unknown amount of work and meanwhile people are asking for hundreds of other things. \n\nIt's certainly possible. It just isn't a priority, especially since the only people who have asked are developers. I would love to find the time.\n"
        ], 
        "number": "572", 
        "title": "WebSocket is already in CLOSING or CLOSED state"
      }, 
      {
        "comments": [
          "Do it manually for now. pushing to 1.1\n"
        ], 
        "number": "566", 
        "title": "force panels to collapse if there's really not enough space"
      }, 
      {
        "comments": [
          "In particular, collapse at the first place that says \"From previous event\".  Call the link \"Show details...\"\n\nBonus points if it's possible to copy the full text when this link is selected.  (I don't know if this is possible, but it would be helpful.)  I.e. user just selects the error including the link, copies it to report the error, and gets the full stack trace.  \n", 
          "I'll be working on this.\n", 
          "@gordonwoodhull , this is what I'm thinking  : \n\nBehavior : \nthe part of the error message starting from \"From previous event\" is hidden by default and a link is shown saying 'Show details'. When the user clicks the link, the message expands to show the full trace and the link changes to 'Show less'\n\nDesign : \nDifferent parts of the error message are contained within different div. The divs containing the parts from \"From previous event\" onwards will be minimized (the height is set to a minimum) similar to what we have in search. It will be changed to max-height on the click of the link to block and vice-versa on click of 'Show less' link. \n\nPlease provide feedback, if any.\n", 
          "Sounds good.  Thanks @agrawal-mohit!\n", 
          "This has been fixed, PR #1163  has been raised\n", 
          "Patch was delivered, but is incorrect / needs rewriting.  Deferring this issue.\n"
        ], 
        "number": "548", 
        "title": "consider collapsing error traces"
      }, 
      {
        "comments": [], 
        "number": "530", 
        "title": "notebook.R shouldn't assume hashes"
      }, 
      {
        "comments": [
          "I certainly agree - we already have that for `notebook.R`, but AFAIR the issue was that it breaks relative links so pretty much the whole RCloud as it is now. If there is a solution for that, I think it would be great.\n", 
          "Hmm, where do we have relative links?\n", 
          "I think what Simon means is that it would break relative links to use a URL scheme like the one we're talking about.\n\nIs that the case, Simon? If so, the solution is \"simple\", we put static assets in a non-overlapping part of the namespace (usually boringly called 'static' or 'assets')\n", 
          "Oh, duh.  Of course you're referring to e.g. js and css links in main.html.  I don't think we use relative links to notebooks or view mode or anything.\n\nAs a quick test, I replaced all `href=\"dir/file\"` and `src=\"dir/file\"` with `href=\"/dir/file\"` and `src=\"/dir/file\"`, and main.html loaded fine.  As Carlos says, we might have to do something more clever, but I think host-relative instead of path-relative URLs for static assets should work fine.\n", 
          "Yeah, that's exactly what I would start with as well.\n", 
          "Sure. I liked the fact that you could serve RCloud in a subdirectory (on the http side), but since we're actually running Rserve anyway and thus have control, it is not such a huge implication - especially since everyone is running rev-proxies anyway :).\n", 
          "A request for Friendly URLs was made on the latest RCloud User Summit (2015-08-31); seems like this issue is tracking that request.  Similar to notebook.R, the user would like this in all URLs (edit, view, mini, shiny, viewiip, etc).\n", 
          "In order to keep application style notebooks linking correctly even when the notebook name changes, it may be prudent to keep the GUID approach to URI and use the named path for in UI usage. For developing cross notebook or with static URIs for assets or resources the GUID could be used. \n\nFor the friendly URI, I would suggest:\n\nHost.../ user/notebook-name-including-path/operation. For example:\n\nThe rcloud.intranet.bigco.com/mattdugan/sample-notebooks/shiny-demo/edit \n\nIt would be semantically interesting to think about assets or resources as relative paths to their parent notebook, like assets/1x1.gif, or from another notebook: ../other-notebook/assets/functions.js. \n", 
          "All this already works using `notebook.R` paths (`/notebook.R/user/notebook-name-including-path[/asset...]`) as you describe it, you can access assets as subpaths etc. You can build entrie websites that way. The only missing piece here is that edit/view are not using this path structure, although there is no technical reason for it.\n", 
          "Cool. I never thought to try it with notebook.R viewer, but I do like the idea of using the same kind of URI transform for view and edit of notebooks, especially as it makes it easy to share links while working with others. \n"
        ], 
        "number": "514", 
        "title": "nice URLs"
      }, 
      {
        "comments": [
          "The same thing happens on public github, fwiw.\n", 
          "(In what sense does this impact discoverability, though?)\n", 
          "It's much easier to guess the gist name so we cannot hide it anymore. \n", 
          "Ah. Let's get our terminologies in sync here: I've been using \"discoverability\" as a positive thing, in the sense of \"RCloud enables discoverability of work in your organization\".\n\nYou're concerned about leaking secrets. You're right, but 1) that's by design on github, 2) that's why the default setting for `create_gist` is `public=false`: https://developer.github.com/v3/gists/#create-a-gist\n\nHow did this become a problem for you?\n", 
          "Yeah, these are public gists, therefore not hidden.\n", 
          "I think the thing to document here would be the three different kinds of public/private:\n- GitHub public gist (this one)\n- rcloud visibility/discoverability\n- rcloud publish\n", 
          "@cscheid it has never been a problem for me, I don't care :)\n\n@gordonwoodhull yes, I agree, this should be probably documented somewhere. \n\nMy main point here is that, technically, we cannot assume hashes.\n", 
          "Does this trigger a bug somewhere in RCloud right now?\n", 
          "I'm pretty sure such notebooks cannot be used in `notebook.R` by ID, because the distinction between by-id and by-name calls is whether it has a hash form or not:\n\n```\n## is this first part a notebook hash?\nif (grepl(\"^[0-9a-f]{20}$\", pex[1L])) {\n```\n", 
          "@s-u, great. I'll open an issue for that.\n"
        ], 
        "number": "513", 
        "title": "github doesn't always use hashes for gists"
      }, 
      {
        "comments": [], 
        "number": "502", 
        "title": "when you type ten lines in prompt it jumps"
      }, 
      {
        "comments": [
          "there's nothing in the folder.  starring a top-level notebook of that user and then unstarring it, makes the folder go away.\n"
        ], 
        "number": "500", 
        "title": "when unstarring friend's last notebook in a folder, folder doesn't go away"
      }, 
      {
        "comments": [
          "also, hiding history is incredibly slow - same bug at a different level\n", 
          "I'll be working on this.\n"
        ], 
        "number": "499", 
        "title": "unfriending is slow"
      }, 
      {
        "comments": [
          "What do you think about moving the cell tab from the right margin to the left?\n", 
          "Seems fine to me.  I guess that would also avoid #442, if the fix isn't correct.\n", 
          "This is really annoying in practice - coalesce and insert buttons are practically unusable.\n\nPutting this into 1.1.  Maybe there is some focus trick or something?\n", 
          "Also the chooser icon on the language select for the prompt - you can still click on the text itself but at least I tend to click on the \n![image](https://cloud.githubusercontent.com/assets/1366709/2845793/6a6b6ed4-d09a-11e3-9568-a29833713a10.png)\n", 
          "https://bugs.chromium.org/p/chromium/issues/detail?id=459626#\n", 
          "This is an issue on Webkit (Chrome, Safari, and Opera) but not Gecko (Firefox). \n"
        ], 
        "number": "493", 
        "title": "cell trash and insert icons get intercepted by scrollbar on osx"
      }, 
      {
        "comments": [
          "Want to finally take care of this for 1.3\n", 
          "Note the workaround @s-u put in da59c54bc50aedab14537da7bdbedc51c282e82a.  It seems `fork_of`, an undocumented attribute, might be inconsistent about whether it's beta or v3 about it's `owner` vs `user`.\n"
        ], 
        "number": "481", 
        "title": "switch to github v3 API"
      }, 
      {
        "comments": [
          "Oh yeah, that is a great idea!\n", 
          "A fine idea.\n", 
          "This shouldn't be very hard with the enhancements I'm putting in for #599 custom panels.  Once that is merged, let's give this a shot.\n", 
          "One of the difficulties is that we don't know the panel width.  Investigate using bootstrap navbar collapse to hide controls when they are too many / too wide.\n", 
          "although the framework is in place, putting this off due to lack of time.\n", 
          "@shaneporter, the heart of this is to apply the same extension mechanism to open up the headers / headings of the panels for customization. Some automatic layout like what we're doing in the notebook cell headers, except here there's an extra dimension which is that all panels have different controls, maybe similar to the way the menus are extensions of extensions (or maybe not similar).\n", 
          "Taking 'Help' as an example, the header would contain the 'get help on...' input/button _and_ the Keyboard link to show the shortcuts? But then when you click on the '?' button, it would open the panel (if closed) and then show the help details?\n\nFor a simpler example, such as the 'clear session pane' (#1734), wouldn't the inclusion of a button make it difficult to distinguish between the icon and the button?\n\nThere's also, as you say, the issue of dealing with this additional content when the width of the column falls below a certain size. If it isn't shown, then it's gone, meaning that it can't be used at narrow column widths.\n", 
          "Yes, that's the idea. Our buttons are mostly bright blue, so I won't worry about them being confused with the white-on-grey icons.\n\nThat's a good point about column widths. It will have to influence the \"natural width\" (`colwidth`) of the panel - so, if the panel is currently narrower than its `colwidth`, it's okay if the controls don't show.\n\nBut this does mean we'll have to implement some kind of hiding/collapsing. It was probably too ambitious for me to put this on 1.6.1 - guess I was just enthusiastic about the session clear button. We'll just have to figure out somewhere else to put that.\n"
        ], 
        "number": "463", 
        "title": "Put panel controls into panel headings"
      }, 
      {
        "comments": [
          "To elaborate on the OOB idea: if the serial number changes, the R code for any action could issue an OOB send about it and carry on with its regular purpose, leaving it to the UI code to decide whether to do anything or not.\n"
        ], 
        "number": "459", 
        "title": "notifications on changes in another session"
      }, 
      {
        "comments": [
          "Currently, there is not even a choice since we don't have lexical scoping of notebooks. In general, we have to rethink all places where we use `.session$notebook` which is in turn a hack and should be replaced by real API. Then the caller of `rcloud.get.notebook.asset` can choose whether to use `current.notebook()` (top-level notebook in the session) vs `this.notebook()` (notebook where the current code has been defined). Then we can argue about which of the two should be the default :)\n", 
          "Are you serious, called notebooks can return functions?\n\nDelaying.\n", 
          "That's actually the mechanism for making subroutines out of notebooks. Do you think theres a better altetnative?\n\nOn Apr 4, 2014, at 8:43 PM, Gordon Woodhull notifications@github.com wrote:\n\n> Are you serious, called notebooks can return functions?\n> \n> Delaying.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", 
          "No, it's great, I'm just surprised that it's possible. Is this with closures? And isn't the call from one process to another?\n"
        ], 
        "number": "453", 
        "title": "Fun bug in the interaction of rcloud.call.notebook and rcloud.get.notebook.asset"
      }, 
      {
        "comments": [
          "There are some issues in general when a connection is cut for some reason (e.g. proxy expiration), but I equally failed to open the debugger in that case to find out how it manifests itself. It may or may not be related, but is something we can test.\n"
        ], 
        "number": "445", 
        "title": "rcloud client maybe starts eating cpu after a while"
      }, 
      {
        "comments": [], 
        "number": "425", 
        "title": "view.html should try to set verbose=FALSE"
      }, 
      {
        "comments": [
          "This could be fixed by #2504 flexbox layout of panes."
        ], 
        "number": "395", 
        "title": "vertical layout is not responsive"
      }, 
      {
        "comments": [
          "gists cannot be owned by organizations. Before we do this we have to wean ourselves off of the github API, I think.\n", 
          "This looks like notebook tagging again to me, discussed previously in #163.  \n\nHaving organizations and permissions is a whole level of blah.  \n\nOn the other hand, I guess the problem with tagging is that unaffiliated users could use the tag on notebooks that are irrelevant, clouding the waters.  So I'm not opposed to this, but it seems like a fair amount of work whereas tagging is easy.\n", 
          "Using organizations would be preferable so that anyone in the organization can edit one particular notebook. Agreed this is painful and not worth the trouble for now.\n"
        ], 
        "number": "390", 
        "title": "project-based tree"
      }, 
      {
        "comments": [
          "1. alphabetize in notebook_controller's on_load\n2. insert in correct place in notebook_view.asset_appended\n\nstep 2 might be sufficient in itself (and we don't have to worry about the performance of insertion sort, here)\n"
        ], 
        "number": "388", 
        "title": "keep assets in alphabetical order"
      }, 
      {
        "comments": [
          "What do you mean by \"windows\"?\n\nDepends on what you're trying to achieve; if you're looking to have two\nplots, then RCloud already supports that out of the box.\n\nBut if you want to move them around the notebook, then you're right, RCloud\ndoesn't support that. We did have \"detachable images\" at some point in the\npast, but they interfered badly with the rest of the styling, so we got rid\nof them. Maybe we need to bring back some version of it.\n", 
          "Yeah \u2013 I know it\u2019s against the flow a bit, but I\u2019ve been wondering about this lately.\nI was thinking that it might be nice to popup a plot cell so I could see it more easily as I continued developing a notebook.  Is this what you called \u201cdetachable images\u201d ?\nPlotting matters a lot \u2013 not sure I know how to do it \u201cright\u201d\n", 
          "dev.new() is a no-op since there that just opens a new device which is implicit in RCloud. I think there is a lot of misconception of what the commands actually do.\n\nDetachable images are an orthogonal concept - it's just about what you can do to the image once you get it.\n\nRCloud goes beyond the concept of fixed device windows (since each output is a snapshot of what would be one device) - it's more analogous to tabbed devices, think of it as all the tabs weaved in the notebook. The traditional \"fixed windows\" device doesn't make sense in the notebook concept (but then neither does a detached prompt yet we have it in the new version so I guess there is a trend to abandon the fundamental concepts...).\n", 
          "Ok \u2026  perhaps some documentation would help if this is the answer.   These commands are in standard R tutorials.\n"
        ], 
        "number": "373", 
        "title": "dev.new() doesn't work"
      }, 
      {
        "comments": [
          "According to the documentation, fix() invokes edit(), which invokes a text editor. This is like prompt(); hard to support out-of-the-box.\n\nWe could add support for it the same way we do with password().. Is this a blocker for you?\n", 
          "We\u2019ve been going through some R tutorials and we\u2019re just reporting things that break.\nThere are work arounds for fix() I would say.    I think we should at least document workarounds for anything that doesn\u2019t work on RCloud.\n", 
          "Ok, perfect. Keep the bug reports coming; we're working on them :)\n", 
          "Some of those functions have hooks so we can make them fail with a message (sorry, unsupported...) if that is better...\n", 
          "@s-u some of them do not have hooks. Is it ok if I start adding overwriting these ones? They would fail with messages too.\n", 
          "Actually I see @s-u already added the pager and editor options. I'm downgrading this to an enhancement since the major annoyance (session is frozen) is gone.\n", 
          "For 1.0 we use OOB send just to show to the user that there was a visible action, but to handle this properly we need a modal action on the UI end and then we can switch to OOB msg which will send the modified content back. Since this is not trivial, we didn't want to start messing with this for 1.0.\n", 
          "Yeah, not hanging is good enough for 1.0. \n"
        ], 
        "number": "369", 
        "title": "fix() doesn't work "
      }, 
      {
        "comments": [
          "so should we go ahead and and add a `.meta` file to each gist, with json content for now just `{\"notebook_version\"=\"1.0\"}`?\n", 
          "ping @cscheid \n", 
          "Agh, I want to defer this to the next release. It's an important decision that needs careful thinking...\n", 
          "Not to make this a meta-issue, but other metadata we might include:\n- [ ] data sources\n- [ ] data outputs\n", 
          "Those are _much_ more complicated issues. Some people have written entire theses on trying to figure those out :)\n", 
          "@cscheid wrote:\n\n> how about simply notebook_metadata.json? It's long, I know, but we all type fast :p\n\nSo how about that file contains an object. One of the fields is `rcloud_version`, say, and perhaps `rcloud_build` for the hash.\n\nAnd then let's reserve a subobject in there for domain-specific data, say `domain`.\n\nAnother thing we talked about putting in there is possibly provenance tracking for when a notebook gets imported or copied and loses its history.\n\nBut let's keep this ticket for the original purpose of versioning, and leave space open in the json for arbitrary metadata.\n", 
          "I'm ok with that proposal. Note that if this is a well-formed json object, we can have RCloud API that manipulates the metadata; so if the notebook execution opens a curated object (via a well-specified API), we can have the execution actually update the metadata.\n"
        ], 
        "number": "367", 
        "title": "Tag the notebook version in some metadata"
      }, 
      {
        "comments": [
          "PUSH is not an HTTP method.. Not sure what you're referring to here. Can you clarify?\n", 
          "`s/PUSH/POST/g`\n"
        ], 
        "number": "347", 
        "title": "execution authentication is hard-coded to user/pwd GET"
      }, 
      {
        "comments": [], 
        "number": "346", 
        "title": "API for sharing/caching results across notebooks"
      }, 
      {
        "comments": [
          "Security will be the focus of release 1.3\n", 
          "#1661 plus the use of a DB password (already supported) should address this since the access control is then at the API level, i.e., control defines which RCS requests are allowed to go through by using the API while no direct RCS access is allowed.\n"
        ], 
        "number": "345", 
        "title": "Secure RCS"
      }, 
      {
        "comments": [
          "Partially implemented in 1.3. The next step would be to open up the rest of the architecture so that it's actually possible to write the extensions you want. This requires refactoring and I guess it will happen on demand.\n", 
          "In terms of UI, the last areas that need to be customizable are\n- [x] the main navbar buttons\n- [x] the menu area (#1313)\n", 
          "Things that could be improved about the current implementation include:\n- [ ] making extensions only load when appropriate (branch filter-rcloud-extensions)\n- [ ] loading extensions in batch so there are fewer ocap round trips\n- [ ] applying [RCloud.extension](https://github.com/att/rcloud/blob/develop/htdocs/js/extension.js) pattern uniformly to all extensions\n\nOver time we'll lift common patterns like flags up into `RCloud.extension`, and apply `extension_.create()` where we can. Uniformity helps make the extension point code easier to read.\n", 
          "Extension points that still don't use `RCloud.extension`:\n- [ ] `RCloud.UI.notebook_commands`\n- [ ] `RCloud.UI.settings_frame`\n- [x] `RCloud.UI.share_button` upgraded in 77ea028\n"
        ], 
        "number": "344", 
        "title": "RCloud UI plugin infrastructure"
      }, 
      {
        "comments": [], 
        "number": "339", 
        "title": "notebook scheduling"
      }, 
      {
        "comments": [
          "What is the expected behaviour of prompt.js? I mean how does the user use it?\nSo is it for getting arguments from users so that that can be dynamically assigned to the code at runtime while executing the NB.\n"
        ], 
        "number": "336", 
        "title": "password.js should have a prompt.js counterpart"
      }, 
      {
        "comments": [
          "(especially disappointing because it's read-only, so you really get nothing)\n", 
          "well, you get a boring scratch.R, right?, but agreed, it should be detected and handled.\n\nIt's annoying (but understandable) that the hash of the repo includes metadata, which means all of these notebooks will have the same content but different version hashes.\n\nThe contents of a version are easy to check, but should we do it without an extra round-trip to the server? Since we're getting the history incrementally, one extra trip might not be a big deal.\n"
        ], 
        "number": "326", 
        "title": "consider nixing first history entry"
      }, 
      {
        "comments": [
          "Also address #773 it triggering the scrolling bug.\n"
        ], 
        "number": "325", 
        "title": "'Flash' the cell if specified in the fragment (hash) part of the url"
      }, 
      {
        "comments": [
          "This should work - there should be no special functions to mask the bug.\n", 
          "NB: the bug doesn't affect all options but just `warn` (and possibly others that knitr and/or evaluate clobbers)\n", 
          "To suppress warnings, set `opts_chunk$set(warning = FALSE)`.\n", 
          "@yihui No, that's not the point - the point is that the `warn` R option is clobbered so it doesn't work - even though it's a very basic part of the R language. There are a lot of other things that get clobbered by `evaluate` so probably the only way to fix it is to ditch it and use true R REPL instead.\n", 
          "If you set `opts_chunk$set(warning = FALSE)`, this will be passed to `evaluate(..., keep_warning = FALSE)`, and as a result, it will leave warnings untouched during evaluation, hence not shown in the markdown output.\n\nIn fact it was me that set the `warn` option in `knit()`, and I just removed this setting, so it should work as you expect now.\n\nI have no idea about how to use a true R REPL programatically. I'll certainly be happy to hear more about it. And what are other \"lot of things\" in evaluate that annoyed you?\n"
        ], 
        "number": "320", 
        "title": "warn option is clobbered between cells"
      }, 
      {
        "comments": [], 
        "number": "289", 
        "title": "Collaborative editing features"
      }, 
      {
        "comments": [
          "Should be part of #144\n", 
          "Well, this is not an admin feature, but a user feature (just like \"Export a gist\") - so I don't think admin UI is the right place. However, this could be part of a bigger picture UI which handlers notebook dependency graph etc.\n"
        ], 
        "number": "244", 
        "title": "create UI for creating stash deployments"
      }, 
      {
        "comments": [
          "As discussed, the syntax is highlighted but the colors just don't stand out very much.  Looks like some colors are defined as css embedded in ace/theme-chrome.js.  We could add some css or change the file if necessary.\n\nThe colors were probably designed for a white background, but even on white they don't stand out very much: \n\n![screen shot 2014-01-08 at 4 16 27 am](https://f.cloud.github.com/assets/1366709/1867019/aca8655c-7845-11e3-9f04-e95efa5ff5f5.png)\n", 
          "I suspect that this is a personal preference issue. For example, I like subtle highlighting, but I have seen other people's settings that look like a flock of parrots is attacking you, so maybe the only solution to this is to add support for per-user CSS customization.\n", 
          "Maybe a dropdown menu allowing users to select their highlighting theme? I believe the theme is currently being set [in this line](https://github.com/att/rcloud/blob/0299a964cd97af326af2cc7ec3a801e6205389b8/htdocs/js/notebook/cell/create_html_view.js#L119). One could pick some of the popular ace themes and then create a simple dropdown in the navbar that will allow a user to switch themes? \n\nI would be happy to submit a pull request if this feature seems worth pursuing.\n", 
          "Thanks @ramnathv!\n\nI'm not sure what the most popular themes are, and we certainly can't include all 280K of them.  I guess it seems pretty low-priority to me, but if people keep thinking that there isn't syntax highlighting maybe we'll do something about it.\n\nFrom this theme explorer/editor it looks like we're using the least pronounced theme right now:\nhttp://ace.c9.io/tool/mode_creator.html\n", 
          "I really would rather avoid providing a menu simply for the highlighting theme. This is something that would change very rarely, and a menu takes a huge amount of space. This could go in an options menu somewhere, but it really really should not take any visual space on the default presentation.\n", 
          "I agree. One option is to allow the user to specify the theme in `rcloud.conf`. While I agree that syntax highlighting is purely cosmetic, some of us are quite wedded to our preferences. For example, I like the solarized light theme. I hacked directly at the rcloud javascript to modify this for my local edition, but it would be useful to allow specifying using a configuration.\n\nJust my two cents :) \n\nRCloud is really awesome. You guys should do a blog post about it sometime. I plan to do one soon, to expose the rest of the rstats community to its awesomeness!!\n", 
          "I run a solarized iTerm myself, so I sympathize, but it really clashes with the rest of the RCloud style. \n\n`rcloud.conf` is per-deployment, not per-user, so I don't think it really solves the problem. I think the place for this is in per-user global settings. We don't really have a GUI for it at this point, but we should eventually :)\n", 
          "@ramnathv If it's not much trouble, please post a screenshot of your instance. I am just wondering how the interface looks like. \n"
        ], 
        "number": "233", 
        "title": "Configurable Syntax highlighting for R"
      }, 
      {
        "comments": [
          "Now that we have language switching, I think we just need to add a third language - would it just be language `text`, extension `.txt`?\n", 
          "Sure, sounds good. You could also have `.tex` - that would be really cool (no, I'm not being sarcastic here - just getting carried away with the possibilities... :))\n", 
          "I was asked about this one again today; just making a couple of comments.\n\nIf we use .txt or .text, then we lose the original language, and also probably nice language-dependent features like automatic ACE highlighting and autocompletion.  Left-field suggestion.... how about overloading the extension and using something like .txtR, .txtpy, .txtmd, etc, so that the original language is maintained?\n\nAny .txt\\* extension cell would not be executed at run time.  We would also need to very clearly indicate cells that are \"commented out\" in the UI, possibly a different color at edit time and some special message at run time like \"cells of type comment are not executed\".\n", 
          "More thoughts... instead of having the user enable/disable this via the UI in the language pulldown, maybe there should be something like a \"toggle comment\" or \"toggle ignore cell\" button that turns this ignore cell feature on/off.  The icon for that button could be a pound sign.\n", 
          "Yes, I came to the same conclusion as well. Although reusing the language select for this is convenient from a programming perspective, and avoids yet another button, really it's independent from the user's perspective.\n\nNow the question is where to store the metadata. It's unfortunate that gists don't have an area for extra keys/values. I guess we'll have to keep the commentedness in RCS, which means it will get lost when the notebook is exported.\n", 
          "Is overloading the extension, like renaming part1.R to part1.txtR to turn on \"ignore\", then renaming back to turn off \"ignore\", a PITA for storing the metadata?  Seems like that would be maintained on export, but given that I do not know the RCloud internals, I have no idea how much pain that would be.\n"
        ], 
        "number": "229", 
        "title": "commenting out cells, or choosing their language"
      }, 
      {
        "comments": [
          "It is always saved, to the browser. It isn't part of the notebook until it's executed. Suggestions welcome but are you losing anything?\n", 
          "This seems to cause endless confusion, I'm having a lot of trouble explaining it to the QA folks as well.  @s-u, did this explanation help at all?\n", 
          "Thanks, the explanation is clear to me but it doesn't address the issue, because that change is lost if I close the browser and/or open it on another machine which is IMHO counter-intuitive in RCloud.\n", 
          "If you close the browser and reopen the same browser, you should still encounter the same command prompt when you reopen it. If you don't that's a bug under the current defined behavior.\n\nIf you want to open the same notebook on another machine and find the same unexecuted command prompt on that machine, then we will have to change the behavior to use not browser local storage but perhaps rcs or even the notebook.  It's not hard to do that, but we should define what we're doing here.\n\nOne of the bugs reported by QA seems to expect the command history to be stored in the notebook.  Let's just decide what we're doing here and be done with it.\n", 
          "I'd argue for notebook or RCS. If notebook is fast enough good, otherwise RCS.\n", 
          "This is updated every keystroke.  It would not only be too slow but also would create a lot of extra noise in the notebook.  I am open to putting it into RCS.\n", 
          "This doesn't need to be every keystroke -- part of autosave and/or on quit?\n", 
          "Hmm, use browser local storage as now to update the history, and then back it out to rcs on save (and quit saves now).. \n\nThat could work.\n", 
          "Great, sounds like a plan :)\n"
        ], 
        "number": "224", 
        "title": "save prompt/history in RCS"
      }, 
      {
        "comments": [], 
        "number": "215", 
        "title": "notebook tree commands sometimes don't disappear after leaving "
      }, 
      {
        "comments": [], 
        "number": "210", 
        "title": "user deletion"
      }, 
      {
        "comments": [
          "This is now available in `Rserve`. I think the next step is to modify JS client to allow it.\n", 
          "I think we agreed to put this off beyond 0.9?\n", 
          "It's not crucial, so I certainly don't mind.\n", 
          "Whatever happened with this?  Is it just replacing a stack with a hash on the JS side, or something?\n", 
          "something like that, but more like a stack of hashes if we want to do nicer tracebacks.\n", 
          "Putting off yet again\n", 
          "The reason why this probably hasn't come up yet is that you can still enqueue requests on the JS side - which works for most uses, you just cannot re-enter. The only thing that deadlocks is if you call an R callback in JS code invoked by R before the continuation (=you make the return value form JS to R conditional on something run in R).\n"
        ], 
        "number": "209", 
        "title": "Allow re-entrance to R"
      }, 
      {
        "comments": [
          "Are you taking about view? We can never close the socket in edit mode, because you can always add a new command, so it's never done running. And even in view mode, it is only safe to close if the notebook didn't register any callbacks (JS modules) - otherwise it may issue further calls and you cannot close the socket.\n", 
          "Yes, I'm talking about viewing a notebook and yes, in general there will be no automatic solution. But we need to have a way that a call to view.html which builds a static output will not hold on to a websocket until the webpage closes. That will simply not scale.\n\nI'm proposing we have a \"ok, I'm done\" ocap that gets interpreted appropriately in view mode.\n", 
          "Ok, that sounds good. Technically you can simply close the websocket - that invokes clean shutdown of the session.\n"
        ], 
        "number": "202", 
        "title": "Optionally close session after notebook is done running"
      }, 
      {
        "comments": [
          "Do you mean gist state?\n", 
          "Yes, and so the notebook model of a running session too (part1.R, eg, becomes out of sync when the other deployment updates the gist)\n", 
          "ideally github could implement the sort of compare-and-swap we talked about the other day, \"edit gist but only if the current commit is still _hash_, otherwise it's an error\"\n"
        ], 
        "number": "201", 
        "title": "Two separate deployments can clobber one another's state"
      }, 
      {
        "comments": [
          "@s-u wrote in #163:\n\n> Forking: we could handle it just like history - you get the last commit but you can unfold the various forks. \n\nBut this is a tree, not linear, and I hold that some internal node is probably the best. The root notebook was just a first try, then someone else made it work, then a bunch of other people worked with it but couldn't improve it. Search by text or tag should return that **best** version, and _somehow_ the ancestors and descendants should, yeah, unfold if desired... But how?\n\n> BTW: I didn't check but can you fork a notebook twice? (E.g. I forked A's notebook, made some small changes to make it work for me and then B continues to work on it and I want to fork the latest version)\n\nAbsolutely, you can. Or fork back someone else's. It's going to get messy quick.\n", 
          "#115 is just about seeing where a fork came from, like github does. But it could probably benefit from a solution to this.\n\nIf we ever figure out #127 merging this is going to get even trickier. I'm not saying we need [DynaDAG](http://dynagraph.org) but... we need DynaDAG.\n", 
          "stars may help with finding the best fork\n"
        ], 
        "number": "170", 
        "title": "Ways to visualize and grapple with multiple forks"
      }, 
      {
        "comments": [
          "Another idea for the second part might be notebook tagging, so that a notebook can belong to multiple categories. \n\nI'd be concerned with a strict hierarchy of folders, who owns a folder, who is able to 'curate' in or out notebooks, etc., all that messy permissions stuff. So unless we want to go there I think that a loose and open tagging system might be easier to implement, even while being a bit more general.\n\nAnother thing to think about, either way, is what impact forking has. When multiple users have their own versions of a notebook, and they are added to one of these shared folders, which one gets displayed? Or should there be a way to mark one fork as the \"best\" or \"active\" fork so that it would be the one showing up in such shared folders. #115 concerns other fork display issues.\n", 
          "Tagging = good idea!\n\nForking: we could handle it just like history - you get the last commit but you can unfold the various forks. BTW: I didn't check but can you fork a notebook twice? (E.g. I forked A's notebook, made some small changes to make it work for me and then B continues to work on it and I want to fork the latest version)\n", 
          "Now that we search is about to land, do we need tagging? Imagine replacing that with twitter-style hashtags.\n\nI'm actually thinking that a cool feature would be \"smart folders\" a la Apple Mail or iTunes, where you create a \"view\" of notebook list (like we have 'my interests', etc.), and this view would be whatever happened to match a particular search.\n"
        ], 
        "number": "163", 
        "title": "Notebook list (\"organizer\") overhaul ideas"
      }, 
      {
        "comments": [
          "Like to do some form of this for 1.2\n", 
          "Think this is a dupe of #637 following a live notebook, which spells it out more.\n", 
          "I think the difference between this and #637 following a live notebook is that this also follows the results on someone else's session, which shares some functionality with #777 session management.\n"
        ], 
        "number": "146", 
        "title": "\"Watch session\""
      }, 
      {
        "comments": [], 
        "number": "144", 
        "title": "Admin UI"
      }, 
      {
        "comments": [
          "optimistically putting this into 1.2\n", 
          "I am not finding the later issues for discussions of pulling the latest from another user's notebook, replacing the current contents, which should be much easier from a ui perspective.\n", 
          "Web merge GUIs exist now, e.g. https://microsoft.github.io/monaco-editor/index.html\n"
        ], 
        "number": "127", 
        "title": "notebook/gist merging"
      }, 
      {
        "comments": [
          "I have an idea of how the \"user-side\" would look like (that is, the user process running the R code and the associated javascript). How do you propose that the actual notification takes place? We have no \"admin interface\".\n\nIn other words: we need an admin interface. This would also allow configuration of RCloud on the web, etc.\n"
        ], 
        "number": "92", 
        "title": "Notifications"
      }, 
      {
        "comments": [
          "Discussing with @gordonwoodhull, we note that the main issue is we need to try and avoid a roundtrip to Github.\n\nOne way is to keep track of the notebook/version being currently edited (on RCS, for example), and issue an error if they don't match, since this would indicate two parallel sessions.\n\nIdeally, we'd do that without requiring a single session per user.\n", 
          "This is connected with live updates #146 and merge and so on, want to make some reasonable stab at it for 1.2\n"
        ], 
        "number": "80", 
        "title": "Two tabs opening the same notebook leads to weirdness"
      }
    ], 
    "repo": "rcloud"
  }, 
  {
    "open_issues": [], 
    "repo": "lux"
  }, 
  {
    "open_issues": [
      {
        "comments": [
          "Yes, that seems like a bug - it should be simply an array of length 0 in JS so `[]`.\n"
        ], 
        "number": "4", 
        "title": "empty vector has no length?"
      }, 
      {
        "comments": [
          "Take into account that I now reply email from an .edu account, and so my brain is now 98.73% useless for technical activities :)\n\nBut if I recall correctly, what I meant by \"allowing js-ocaps to specify what level of detail they want\" was that instead of using `wrap_all_ocaps` for everything, we'd go for a more piecemeal approach, where `wrap_ocap` (is that the name for the individual function?) is the generic function that wraps _everything_, but whenever a particular ocap requires a more careful conversion procedure, we design and write that one instead.\n\nbecause in a way, wrap_ocap takes a function and returns another function. But you could write a \"wrap_ocap_but_not_lang\" function, which you'd use to wrap the ocaps that need special treatment.\n\nDoes that make any kind of sense?\n", 
          "Almost. :wink: \n\n`wrap_all_ocaps` is the function that recursively replaces all ocaps with functions; `wrap_ocap` replaces a single ocap.\n\n`wrap_all_ocaps` is called directly from `onmessage` before forwarding the message to its client (RCloud), and `onmessage` doesn't even seem to know about the individual js-ocaps. So right now we could perhaps customize at the RCloud level, but I don't think we could have individual js-ocaps decide what level of processing they want.\n\nUnless perhaps they told RCloud what they want, and then rcloud.js chose the appropriate wrapper. Hmm. I guess it begs the question of how RCloud extensions would specify what they want in the code that gets eval'd by `install_js`.\n\nBetter stop staring at this and get back to \"real\" work...\n"
        ], 
        "number": "3", 
        "title": "don't jsonify lang nodes"
      }, 
      {
        "comments": [], 
        "number": "1", 
        "title": "`this` for javascript modules?"
      }
    ], 
    "repo": "rserve-js"
  }, 
  {
    "open_issues": [
      {
        "comments": [
          "> library(iplots)\r\nError: package or namespace load failed for \u2018iplots\u2019:\r\n .onLoad failed in loadNamespace() for 'iplots', details:\r\n  call: .jnew(\"org/rosuda/iplots/Framework\")\r\n  error: java.lang.NoClassDefFoundError: Could not initialize class org.rosuda.ibase.Common\r\n> \r\n"
        ], 
        "number": "1", 
        "title": "Issue loading iplots"
      }
    ], 
    "repo": "iplots"
  }, 
  {
    "open_issues": [], 
    "repo": "gsdjvu"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "116", 
        "title": "Fix controllers in multi-DCs have to start simultaneously"
      }, 
      {
        "comments": [], 
        "number": "115", 
        "title": "Support multiple DHCP servers"
      }, 
      {
        "comments": [], 
        "number": "114", 
        "title": "Asynchronous RPC queue"
      }, 
      {
        "comments": [], 
        "number": "113", 
        "title": "Multi-tenancy (Bug of GotoTable)"
      }, 
      {
        "comments": [], 
        "number": "112", 
        "title": "Gateway high availability (Plan B)"
      }, 
      {
        "comments": [], 
        "number": "111", 
        "title": "Read-only controllers"
      }, 
      {
        "comments": [], 
        "number": "110", 
        "title": "Fix Controller HA"
      }, 
      {
        "comments": [], 
        "number": "109", 
        "title": "Multi-threaded controller"
      }
    ], 
    "repo": "ryu"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "5", 
        "title": "discipline function \".unset\" only called once for array subscriptions"
      }, 
      {
        "comments": [], 
        "number": "3", 
        "title": "Tab completion chokes on ~/some"
      }, 
      {
        "comments": [], 
        "number": "2", 
        "title": "index.html"
      }
    ], 
    "repo": "ksh"
  }, 
  {
    "open_issues": [], 
    "repo": "core-cla"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "39", 
        "title": "Line break not ignored"
      }, 
      {
        "comments": [], 
        "number": "36", 
        "title": "No matching root policy found "
      }, 
      {
        "comments": [
          "Hi, thanks I will take a look at this. How are you testing this in order to generate the error?", 
          "```\r\nproperties props = new Properties();\r\nprops.setProperty(XACMLProperties.PROP_ROOTPOLICIES, \"policy\");\r\nprops.setProperty(\"policy.file\", \"src/main/resources/XACML/policy.xml\");\r\nPDPEngine engine = PDPEngineFactory.newInstance().newEngine(props);\r\n\r\nRequest request = //simple XAML request\r\nResponse response = engine.decide(request);\r\n```\r\nIf I remove the comment from policy file the request will be responed without error.", 
          "Hi, any news on this? I am facing exactly the same problem.", 
          "I've seen this issue as well. I have submitted the following pull request https://github.com/att/XACML/pull/38", 
          "@benkuly @g-spot should be fixed now"
        ], 
        "number": "35", 
        "title": "Comments in begin of policy-file throws Exception"
      }, 
      {
        "comments": [], 
        "number": "34", 
        "title": "Editing policies at the UI level"
      }, 
      {
        "comments": [], 
        "number": "33", 
        "title": "REST and JSON profile latest spec. implementations"
      }, 
      {
        "comments": [
          "You'll notice that everything but pap and pdp is commented out in XACML/pom.xml.\n\nSent from my iPhone\n\n> On Apr 12, 2017, at 3:18 PM, Samuel Benas <notifications@github.com> wrote:\n> \n> https://mvnrepository.com/artifact/com.att.research.xacml/att-xacml/1.0.0 <-- Returns a 404\n> \n> Should this be taken out of the pom.xml file and be built from source?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", 
          "Yes - we only released the XACML and XACML-PDP to Maven. I'm in the process of finishing the other projects and getting them into Maven. Apologies - will try to finish this up soon.", 
          "Thank you both for the quick response.", 
          "Has there been any update on when the other projects will be released in Maven?\r\n\r\nIs there a way to set up an ATT XAML server without that dependency?"
        ], 
        "number": "28", 
        "title": "xacml-rest-1.0.0.jar not on maven repository"
      }, 
      {
        "comments": [
          "Look at ygrignon-sfdc/XACML for fixed pom.xml files addressing this issue among others.\n\nSent from my iPhone\n\n> On Apr 12, 2017, at 2:59 PM, Aymon Fournier <notifications@github.com> wrote:\n> \n> Running this using RunJettyRun, WEB-INF shows no files. Looking at web.xml I see a bunch of files, that I do not see in the project. Are these generated, or missing?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", 
          "Yes we need to finish building the pom.xml for the REST and PAP admin interfaces. Will try to do this asap.", 
          "I swapped out the pom with https://github.com/ygrignon-sfdc/XACML/blob/master/XACML-PAP-ADMIN/pom.xml but I am still seeing NOT FOUND, even though directories are matched up as ones in pom file. Still following instructions in wiki to deploy with RunJetty, am I missing something else?", 
          "We have been using the Maven plugin to run Jetty, instead of the Eclipse Plugin. I just tried the latest Eclipse 9.0.0.M3 and it has bugs. The v8.1.8.v20121106 also seems to exhibit different problems with the persistence provider. But I'm not seeing the problem you are describing. \r\n\r\nI am going to commit the changes so that you could run from command line using Maven. Hopefully that would work for you: 'mvn jetty:run-war'\r\n\r\nThen see if I can figure out how to get it to work under Eclipse Jetty Plugin.", 
          "This was the install instructions I was using previously: https://github.com/att/XACML/wiki/XACML-PAP-ADMIN---Admin-Console-and-Policy-Editing-application\r\n\r\ncan you give updated instructions? Also clarify which pom is correct for the new instructions?"
        ], 
        "number": "27", 
        "title": "Where are index.html?"
      }, 
      {
        "comments": [
          "```\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<PolicySet xmlns=\"urn:oasis:names:tc:xacml:3.0:core:schema:wd-17\" PolicySetId=\"urn:com:xacml:policy:id:84554b18-58bc-46ca-83d8-072a67f304f7\" Version=\"1\" PolicyCombiningAlgId=\"urn:oasis:names:tc:xacml:1.0:policy-combining-algorithm:first-applicable\">\n    <Description>This policy defines access level to a particular resource.</Description>\n    <Target>\n        <AnyOf>\n            <AllOf>\n                <Match MatchId=\"urn:oasis:names:tc:xacml:3.0:function:string-equal-ignore-case\">\n                    <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">read</AttributeValue>\n                    <AttributeDesignator Category=\"urn:oasis:names:tc:xacml:3.0:attribute-category:action\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:action:action-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n                </Match>\n            </AllOf>\n        </AnyOf>\n    </Target>\n    <Policy PolicyId=\"urn:com:xacml:policy:id:0173b3a7-e365-4b3a-946a-e671648829ec\" Version=\"1\" RuleCombiningAlgId=\"urn:oasis:names:tc:xacml:3.0:rule-combining-algorithm:permit-overrides\">\n        <Description>policy to allow a specified user to perform all actions on all resources. </Description>\n        <Target/>\n        <Rule RuleId=\"urn:com:xacml:rule:id:9a897537-1115-4205-994b-02e88505916a\" Effect=\"Permit\">\n            <Description>Allow DummyA org users.</Description>\n            <Target/>\n            <Condition>\n                <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-at-least-one-member-of\">\n                    <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-bag\">\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">user_1</AttributeValue>\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">user_2</AttributeValue>\n                    </Apply>\n                    <AttributeDesignator Category=\"urn:oasis:names:tc:xacml:1.0:subject-category:access-subject\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:subject:subject-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n                </Apply>\n            </Condition>\n        </Rule>\n        <Rule RuleId=\"urn:com:xacml:rule:id:b54ea1be-f33e-4341-abff-26329ed70a04\" Effect=\"Permit\">\n            <Target/>\n            <Condition>\n                <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-at-least-one-member-of\">\n                    <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-bag\">\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">B_user_3</AttributeValue>\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">B_user_4</AttributeValue>\n                    </Apply>\n                    <AttributeDesignator Category=\"urn:oasis:names:tc:xacml:1.0:subject-category:access-subject\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:subject:subject-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n                </Apply>\n            </Condition>\n        </Rule>\n        <Rule RuleId=\"urn:com:xacml:rule:id:c8128d1c-8b44-4a3e-b600-a5dc232e4c38\" Effect=\"Permit\">\n            <Description>Allow I org users.</Description>\n            <Target/>\n            <Condition>\n                <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-at-least-one-member-of\">\n                    <Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-bag\">\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">I_user_1</AttributeValue>\n                        <AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">I_user_2</AttributeValue>\n                    </Apply>\n                    <AttributeDesignator Category=\"urn:oasis:names:tc:xacml:1.0:subject-category:access-subject\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:subject:subject-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n                </Apply>\n            </Condition>\n        </Rule>\n        <Rule RuleId=\"urn:com:xacml:rule:id:1055e91a-ab1b-4fcd-a247-b9ade3ba3112\" Effect=\"Deny\">\n            <Description>If none of the above rules match then deny.</Description>\n            <Target/>\n        </Rule>\n    </Policy>\n</PolicySet>\n```\n", 
          "Yes - when you have multiple root .xml policies, there's NO combining algorithm that the PDP can use to return a final decision to. One work around using the true XACML route is to create a single .xml with a combining algorithm that would then reference the other .xml policies. We also have another work around in the properties file where you can change the behavior of the PDP to use a designated combining algorithm. I'll have to check to see if that was open sourced already or if that's one of my todo items.\n\nWill get back to you tomorrow, today I am at a seminar.\n\nThanks!\n", 
          "Thank you for the reply, Ok got it. But when i tried to define the above file as a root policy and referenced policy as the following file:\n\n```\n<PolicySet xmlns=\"urn:oasis:names:tc:xacml:3.0:core:schema:wd-17\" PolicySetId=\"urn:com:xacml:policy:id:84554b18-58bc-46ca-83d8-072a67f304f7\" Version=\"1\" PolicyCombiningAlgId=\"urn:oasis:names:tc:xacml:3.0:policy-combining-algorithm:deny-overrides\">\n<Description>\nThis policy defines access level to a particular resource. \n</Description>\n<Target/>\n<Policy PolicyId=\"urn:com:xacml:policy:id:0173b3a7-e365-4b3a-946a-e671648829ec\" Version=\"1\" RuleCombiningAlgId=\"urn:oasis:names:tc:xacml:1.0:rule-combining-algorithm:first-applicable\">\n<Description>\npolicy to allow a specified user to perform all actions on all resources.\n</Description>\n<Target/>\n<Rule RuleId=\"urn:com:xacml:rule:id:9a897537-1115-4205-994b-02e88505916a\" Effect=\"Permit\">\n<Description>Allow users.</Description>\n<Target>\n<AnyOf>\n<AllOf>\n<Match MatchId=\"urn:oasis:names:tc:xacml:3.0:function:string-equal-ignore-case\">\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">all</AttributeValue>\n<AttributeDesignator Category=\"urn:oasis:names:tc:xacml:3.0:attribute-category:action\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:action:action-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n</Match>\n</AllOf>\n<AllOf>\n<Match MatchId=\"urn:oasis:names:tc:xacml:3.0:function:string-equal-ignore-case\">\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">all</AttributeValue>\n<AttributeDesignator Category=\"urn:oasis:names:tc:xacml:3.0:attribute-category:resource\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:resource:resource-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n</Match>\n</AllOf>\n</AnyOf>\n</Target>\n<Condition>\n<Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-at-least-one-member-of\">\n<Apply FunctionId=\"urn:oasis:names:tc:xacml:1.0:function:string-bag\">\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">h_user_1</AttributeValue>\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">h_user_2</AttributeValue>\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">i_user_1</AttributeValue>\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">i_user_2</AttributeValue>\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">o_user_1</AttributeValue>\n<AttributeValue DataType=\"http://www.w3.org/2001/XMLSchema#string\">o_user_2</AttributeValue>\n</Apply>\n<AttributeDesignator Category=\"urn:oasis:names:tc:xacml:1.0:subject-category:access-subject\" AttributeId=\"urn:oasis:names:tc:xacml:1.0:subject:subject-id\" DataType=\"http://www.w3.org/2001/XMLSchema#string\" MustBePresent=\"false\"/>\n</Apply>\n</Condition>\n</Rule>\n<Rule RuleId=\"urn:com:xacml:rule:id:1055e91a-ab1b-4fcd-a247-b9ade3ba3112\" Effect=\"Deny\">\n<Description>If none of the above rules match then deny.</Description>\n<Target/>\n</Rule>\n</Policy>\n</PolicySet>\n```\n\nHowever, I am getting NotApplicable during validation of permission decided by rules in this file. Looks, like root file (xml) not able to include policies from referenced file. Any thoughts ?\n", 
          "Ok, finally it seems to be working, but i have noticed a couple of points, definition of an algorithm in the root policy xml should be in such a way that would permit other referenced policies xml to be evaluated ( i had put earlier first-applicable that was always resulting in picking up a broader deny rule, even though it was a permit). \n\nAlso, It is surprising that Xacml does not have an algorithm to combine different policy(set) defined in different files? This brings another question to me that now Admin has more responsibilities while defining new policy in an appropriate way to avoid conflict or there could be a better way ?\n\nIn this UI, is there a way to connect two policy files ? i had to add manually policyset reference id.\n", 
          "The UI may need work with regards to connecting two policy files.\n\nI agree - in fact we built our own algorithm internally and then defined it via the properties file for the PDP to use.\n\nGlad you got it working, it can be tricky trying to get the algorithms to work the way you want them to. Sometimes I think a good old if-then-else and case algorithms would be nice.\n", 
          "Do you have that algorithm open source ? looks like policy conflict resolution and multiple policies to a request both features need to be addressed before anything.\n"
        ], 
        "number": "26", 
        "title": "Mutliple Applicable Root Policies"
      }, 
      {
        "comments": [], 
        "number": "25", 
        "title": "XACML-pap-admin running issue"
      }, 
      {
        "comments": [
          "Yes, please go ahead and and do the pull request. I need to investigate the FunctionDefinitionAccessPermittedTest, it isn't implemented but certainly should fail.\n", 
          "ok, i will do that, Just to let you know, I am interested in contributing to this project and we do see lots of improvement that can be added to the code. Do you have any design document ? are you now actively committing to this project or not?\n", 
          "The best I can do is point you to the wiki as far as design document. Sorry wish I had more. We are actively committing to this project now. I am currently trying to mavenize it going forward, working in the \"develop\" branch. Trying to merge with master hopefully this week or early next week. And do an official first release. After that we are open to suggestions for improvement.\n", 
          "Good to hear \"you are actively committing\", I do have couple of issues, e.g. running PAP-admin ui using jetty in Intellij, I had to add jetty plugin and only 9.0 or below version. I would suggest make it simple (Like you already have parent-child pom model) but also add jetty plugin for web based application to facilitate running and avoid dependencies from IDE (like Eclipse), You have META-INF dispersed in Webcontent which might not be the right place to load JPA configuration.\n"
        ], 
        "number": "24", 
        "title": "XACML-TEST"
      }, 
      {
        "comments": [], 
        "number": "18", 
        "title": "Create New Function"
      }, 
      {
        "comments": [], 
        "number": "16", 
        "title": "Drag-N-Drop Policy at the TOP/BOTTOM"
      }, 
      {
        "comments": [], 
        "number": "15", 
        "title": "PAP API - Design Considerations"
      }
    ], 
    "repo": "XACML"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "374", 
        "title": "Build the `pty` command."
      }, 
      {
        "comments": [], 
        "number": "369", 
        "title": "Build the `pty` program"
      }, 
      {
        "comments": [], 
        "number": "367", 
        "title": "Memory leak when command is redirected in while loop"
      }, 
      {
        "comments": [], 
        "number": "366", 
        "title": "Does any distro ship the `suid_exec` program?"
      }, 
      {
        "comments": [], 
        "number": "362", 
        "title": "Change temp folder pattern to indicate which test script it is created for"
      }, 
      {
        "comments": [
          "The fact that some temp directories are left behind after the tests are run indicates the test scripts are not terminating in a way for the trap code to be executed or the trap code fails.\r\n\r\nIn at least one case, the test involves file manipulations in a temporary sub-directory which have to fail because the sub-directory has no execute bit set; the final `rm -fr $tmp` will not be able to remove all the folders under $tmp, if the user is not `root`.\r\n\r\nI am more concerned with other scenarios.\r\nFor those cases, the more descriptive naming of the temporary folders are a benefit.\r\n"
        ], 
        "number": "360", 
        "title": "Tests create temporary folders which are difficult to associate with test scripts"
      }, 
      {
        "comments": [
          "Is it even possible to safely use threads in a shell builtin ? My understanding is that it's a bad idea to mix forks with threads and it should be disallowed.", 
          "@siteshwar\r\n> Is it even possible to safely use threads in a shell builtin ? \r\n> My understanding is that it's a bad idea to mix forks \r\n> with threads and it should be disallowed.\r\n\r\nI have many KSH built-ins that are multithreaded. Further, and much more daring, I have several threads (some started dynamically) that actually run along side KSH even when no built-ins are running. These can best be described as daemon-server threads that capture various events outside of particular built-in use. The built-ins also use general purpose libraries (shared-object or otherwise) that have background threads of their own (mostly started dynamically). So at any one time during a KSH session, there may be potentially several or many threads all running within the KSH address space.\r\n\r\nOf course, through all of this KSH does not know about the other threads.  Any interaction with the KSH API interfaces is serialized since KSH and its programming interface were not meant to be multithread safe. About forks (which of course KSH does all of the time): there is no problem at all with regular threads inside of a KSH built-in (assuming POSIX |fork1(2)| semantics, which should be arranged for if not the default already). But with background daemon threads, or with library background threads, there is the fork-safety problem. In general, all background threads need to be made \"fork-safe\" so that the child does not get messed up by half-baked variables in the address space that are no longer coherent due to an asynchronous fork by KSH itself. Also, it is always a *very* good idea to make sure that all background threads are eventually \"joined\" somehow.  This is generally done by arranging for the join to happen when the module that the background thread code is located in gets unloaded (|dlclose(3dl)|).  How this is done when the background threads are located in dynamically loaded and unloaded code modules is not obvious and is beyond the scope of this discussion. The UNIX thread-gods did not foresee this possibility and they did not plan for it specifically, but it is still achievable with some custom well-placed coding.\r\n\r\nAnyway, the short of it is that multi-threaded built-ins are not only possible, but background threads, being background to the rest of KSH itself, is also possible with due care.  Some caveats: the AST VMALLOC code had to be compiled out.  Although it was supposed to have a \"thread safe\" mode, that did not turn out to be thread-safe enough for any amount of multi-threading at all -- as far as I experienced. Without VMALLOC, the default allocation facility reverts to that of the host OS system itself (last I looked), which is generally (as far as I know) always multi-thread safe. Also, if you want multi-thread SFIO (like from within a built-in), make sure that your SFIO is complied as multi-thread safe also. For myself, I do not use SFIO for my multi-threaded I/O. Rather, I use my own interface library for that and most everything else. But remember that the KSH built-in programming interface *requires* the use of SFIO for STDIN, STDOUT, and STDERR regardless of anything else one might do with I/O from within a built-in.\r\n\r\nI have written over 110 KSH built-ins.  Several of them are explicitly multi-threaded.  But even my built-ins that are not explicitly multi-threaded, call library calls or instantiate library objects that may themselves be multi-threaded. So at any one time there can be zero or about a hand full (or more) background threads running along side and with KSH (without KSH explicitly knowing that they are even there). With properly written code, none of this is out of the ordinary.\r\n\r\nIn my view, all code today might secretly be multi-threaded for the simple reason that when libraries (either statically linked or more commonly dynamically linked) are called from any code (like from KSH built-in code) one or more background threads could be spawned.  It is just the way of the modern era now-a-days. People should just get used to this idea.\r\n\r\nMain caveat for multi-thread use w/ KSH (as far as I know): compile *out* the VMALLOC stuff and use the host OS process heap management instead.\r\n"
        ], 
        "number": "357", 
        "title": "`ksh` doesn't use threads so what should the stance be vis-a-vis threads in plugins?"
      }, 
      {
        "comments": [
          "+1. We should also enhance current test suite and write unit tests for other components of libast that we will continue to use."
        ], 
        "number": "350", 
        "title": "Enable libast unit tests"
      }, 
      {
        "comments": [
          "Has anyone subscribed to this repo tested these to see if they are working?\r\n\r\nI think it would be useful to be able to run services in `ksh`.", 
          "I have selected to \"Watch\" this repo.\r\n\r\nThe notifications I receive are for commits and issue activities, such as a new issue opened, an issue closing or comments added to issues.\r\n\r\nWorks for me.\r\n", 
          "> Works for me.\r\n\r\nHuh? The `mkservice` and `epoll` commands are hidden inside `#if 0...#endif` blocks. They effectively don't exist:\r\n\r\n```\r\n$ mkservice\r\nksh: mkservice: not found [No such file or directory]\r\n```\r\n\r\n> Has anyone subscribed to this repo tested these to see if they are working?\r\n\r\nSeems unlikely other than a member of the AT&T team that worked on this project. The embedded documentation is below. The ID string implies this was implemented in 2001 but there is no mention of it in any of the RELEASE files.\r\n\r\n```\r\n[-?\\n@(#)$Id: mkservice (AT&T Research) 2001-06-13 $\\n]\" USAGE_LICENSE\r\n[+NAME? mkservice - create a shell server ]\r\n[+DESCRIPTION?\\bmkservice\\b creates a tcp or udp server that is\r\nimplemented by shell functions.]\r\n[+?The \\aservice_path\\a must be of the form \\b/dev/tcp/localhost/\\b\\aportno\\a\r\nor \\b/dev/udp/localhost/\\b\\aportno\\a depending on whether the\r\n\\btcp\\b or \\budp\\b protocol is used.  \\aportno\\a is the port\r\nnumber that the service will use.]\r\n[+?The shell variable \\avarname\\a is associated with the service.  This\r\nvariable can have subvariables that keeps the state of all\r\nactive connections.  The functions \\avarname\\a\\b.accept\\b,\r\n\\avarname\\a\\b.action\\b and \\avarname\\a\\b.close\\b implement the\r\nservice as follows:]{\r\n[+accept?This function is invoked when a client tries to connect\r\nto the service.  It is called with an argument which\r\nis the file descriptor number associated with the\r\naccepted connection.  If the function returns a non-zero\r\nvalue, this connection will be closed.]\r\n[+action?This function is invoked when there is data waiting\r\nto be read from one of the active connections.  It is\r\ncalled with the file descriptor number that has data\r\nto be read.  If the function returns a non-zero\r\nvalue, this connection will be closed.]\r\n[+close?This function is invoked when the connection is closed.]\r\n}\r\n[+?If \\avarname\\a is unset, then all active connection, and the service\r\nitself will be closed.]\r\n```\r\n\r\nI've written one trivial network service in bash because I didn't want to add a dependency on another language. It was really hard to implement and make it robust. I would definitely not do it a again. I would use C, Go, Python, or anything other than a shell script. Whether the experimental `mkservice` ksh command makes using ksh for such things a good idea is debatable."
        ], 
        "number": "348", 
        "title": "What to do about builtins `mkservice` and `eloop`?"
      }, 
      {
        "comments": [
          "BTW, There are a bunch of commands in *src/cmd/builtins* which are ksh builtins. They are external commands and builtins with apparently one exception: `pty`. From a ksh built using the legacy build system from the beta branch:\r\n\r\n```\r\n$ type head\r\nhead is a shell builtin version of /usr/bin/head\r\n$ type pty\r\ndarwin.i386-64/src/cmd/ksh93/ksh: whence: pty: not found\r\n$ builtin pty\r\nbuiltin: pty: not found\r\n$ type rev\r\nrev is a shell builtin version of /usr/bin/rev\r\n$ type tee\r\ntee is a shell builtin version of /usr/bin/tee\r\n$ type grep\r\ngrep is a tracked alias for /usr/local/bin/grep\r\n```\r\n\r\nI am seriously confused by the state of the project before @siteshwar and I started to aggressively prune it down to just what is needed to build and execute `ksh`."
        ], 
        "number": "347", 
        "title": "Should we continue to support building `grep` as both a builtin and standalone command?"
      }, 
      {
        "comments": [], 
        "number": "345", 
        "title": "Another questionable #define symbol that should probably be removed"
      }, 
      {
        "comments": [
          "One of the reasons `ksh` is still used today is because there are large number of scripts written in it. Deprecating things like backticks will only end up creating chaos.", 
          "I think the answer is obvious: the ``` `...` ``` syntax can never ever be removed.  What would be worth to consider is making ksh interpret ``` `...` ``` and ```$(...)``` in the same way.  But even that is going to break some existing scripts I am afraid.  Similarly with the ```f() {...}``` syntax and ```function f() {...}``` syntax, which are each interpreted differently by ksh.  As far as compatibility matters, it would be IMO best to just analyze the current design and document it properly.", 
          "> Deprecating things like backticks will only end up creating chaos.\r\n\r\nThat implies that ksh must remain compatible with the [POSIX 1003 standard](http://pubs.opengroup.org/onlinepubs/007908799/xcu/chap2.html) even in a major release. That standard for shells dates back to at least 1992. Which means that standard is at least twenty-five years old. Like many standards its main purpose was to codify long established behavior. Rather than define new and better behavior.\r\n\r\nI am okay with formalizing that stance for this project but doing so means that ksh will never be competitive with general purpose languages like Python. Let alone other, newer, shells like [Fish](https://fishshell.com/) and [Elvish](https://elvish.io). It is not obvious how to reconcile statements from other individuals in other Github issues regarding making ksh competitive with language like Python in light of the restriction to remain POSIX 1003.2 compatible.\r\n\r\nI was hoping to gently drop support for POSIX 1003 in a few key areas. Such as how variable expansion and word splitting interact. At least when the variable has been explicitly declared to be an array or map. But that will be impossible if we can never deviate from POSIX 1003.2 compliance in any way. In which case what is the purpose of this project? Is it solely to make it easier to fix bugs to a version of ksh that most distros adopted five years ago?", 
          "POSIX compatibility is a major feature of ksh. If we deviate from it, there is a big risk that users are going to reject our changes. Even in case of shells like fish, there are discussions around supporting POSIX syntax. It will be a mistake to break compatibility with POSIX standard.", 
          "My `Even the backtick command substitution form should probably be removed` assertion was written tongue-in-cheek. I don't think we can realistically remove support for that feature without making a major release with an explicit declaration support for  backtick command substitution will be removed. My point is that too many discussions of this nature implicitly assume existing behavior can never be invalidated. Which means the project will die a slow  death due to an inability to evolve.\r\n  ", 
          "> My point is that too many discussions of this nature implicitly assume existing behavior can never be invalidated. \r\n\r\nI think we should take such discussions individually. I would like to hear more feedback from users when we attempt to make any change. This GitHub project still lacks visibility,  but I hope it will improve over time. \r\n\r\n> Which means the project will die a slow death due to an ability to evolve.\r\n\r\nWe can not survive long term without surviving short term. Any major breakage with existing ksh versions will guarantee a sudden death.", 
          "I believe it is possible to make `ksh` comparable to `python` _without_ breaking `POSIX`.  FWIW, I have written up quite a few proposals for syntax enhancements to do this but have not shared them yet.  There are about a dozen and I'm not sure whether to create one large issue or separate issues for each one.  What about one issue as an overview and a separate issue for each item so they can be discussed?\r\n\r\nNow, I'm not saying I have all the answers, or even the coding ability to do it, and there could be unforeseen flaws in my proposals, but I'm passionate about it because if it can be pulled off correctly, `ksh` would stand head and shoulders, no make that waist and up above the other shells, bringing shell programming up to modern standards while maintaining `POSIX` compatibility.", 
          "@dannyweldon I would suggest to create separate issues for each enhancement (unless enhancements are really close to each other).", 
          "@dannyweldon, Yes, please open a separate issue for each enhancement you have in mind. Issues that cover more than a single, distinct, topic are problematic. If for no other reason than it becomes hard to know when the issue has been resolved. If you have ideas on how to make `ksh` as safe to use as non-POSIX shells like [Elvish](https://github.com/elves/elvish) we definitely want to hear them.\r\n\r\nI'm skeptical `ksh` can be turned into a language comparable to something like `python` while retaining POSIX compatibility but I'd love to be proven wrong. Note that if the idea is to add an option to disable certain undesirable POSIX behaviors that's fine but obviously means a huge amount of additional complexity because you're introducing behavior \"personalities\". Python mostly solves this by limiting the scope of a `import` or `from ... import` statement to the current module. Including, notably, `from __future__ import X` statements. What would the equivalent look like for ksh?\r\n  ", 
          "Thanks @krader1961 and @siteshwar, I'll start cleaning up what I have got so far.  Look, I may have flaws in my designs but lets start the discussion anyway and see what we can come up with.\r\n\r\nI doubt if we could do anything as advanced as that `python` example, but the closest I can think of would be to add an option, but implement something like `zsh`'s `setopt localoptions` to make it possible to scope options to functions or inside new types.  My ideas don't involve adding options though.", 
          "On Wednesday, January 10, 2018 5:49:51 AM CET Kurtis Rader wrote:\n> I'm skeptical `ksh` can be turned into a language comparable to something\n> like `python` while retaining POSIX compatibility but I'd love to be proven\n> wrong.\n\nIf your intention is to develop a modern programming language, why are you \nstarting with (k)sh in the first place?\n\nThe language is neither efficient, nor intuitive, compared to other modern \nprogramming languages.  The key advantage of shell is portability.  If your \ngoal is to develop a shell-like language that is not compatible with POSIX \nshell (or bash), it is not going to be useful for anything but programming \nexercises.\n", 
          "We're in violent agreement, @kdudka. My reply was meant for the individuals (including he who shall not be named: j.e.l.l.m.d.) who have repeatedly argued that ksh is a great general purpose language. Which is why, they argue, it makes perfect sense (/eye-roll) to expose all of the libm functions. They need to show us how ksh can evolve such that it really can be used as a general purpose language that is competitive with something like Python or Ruby. I don't think it can be done. At least not without something like a `--no-posix` flag that radically changes how it behaves. And if we have to resort to such a tactic what would be the point? Why not just use one of the myriad mature languages that is likely already better suited to solving the problem?", 
          "FWIW, The point of this issue is to spark discussion about features marked obsolete long ago we might be able to jettison. The backtick form of command substitution is probably not in that set of features since it is codified by POSIX 1003.2. The reason I mentioned it is to move the [\"Overton window\"](https://en.wikipedia.org/wiki/Overton_window) about ideas that are acceptable to tolerate. Especially with respect to  removing features that were either\r\n\r\na) deprecated decades ago, or\r\n\r\nb) were added in the past decade but are incomplete and/or broken (e.g., `SHOPT_FIXEDARRY`) or not compatible with the goals of the project (e.g., faithful `bash` emulation via `SHOPT_BASH`).\r\n\r\nWith respect to backtick command substitution all I can say is that no one I know has used it in more than two decades. Whether we should still support it for the sake of being able to act as a faithful `/bin/sh` implementation from the 1980's, and thus execute very old scripts which might use that syntax, is an open question. The answer may very well be \"yes, you idiot\". But I think it is worth discussing given that we're trying to resurrect ksh from its dormancy and make it relevant again.", 
          "Removing support for backticks to do command substitution might be unacceptable but what about support for the `FCEDIT` env var? That was mentioned in *src/cmd/ksh93/OBSOLETE* and is thus so old that anyone still using it should not be too surprised if we no longer recognize that env var.\r\n\r\nThe point of this issue is not whether any particular feature should be removed. It is whether support for any legacy, deprecated, feature can be removed.", 
          "I think that our understanding of the marketplace for ksh fundamentally differs.  You want keep ksh relevant by removing questionable (unused, broken, obsolete, deprecated, legacy, whatever) features, thus make it better maintainable, extensible, etc.  I want to keep ksh relevant by preserving its compatibility with already existing ksh scripts, which I think is what the current user base asks for in the first place.\r\n\r\nEven if you improve ksh such that it compiles in 20 seconds, runs 10 times faster, and supports python-like module loading, nobody is going to use it unless it stays sufficiently compatible with ksh93.  Most of the existing users would be lost by loosing the compatibility and new users of such a shell would be difficult to find.\r\n\r\nI do not understand your comment about removing support for features instead of removing features.  There is no (guaranteed) support for ksh by upstream.  It is mainly Red Hat who has been providing support to existing users of ksh.  And it is obvious that the view of what is supported and what not currently differs between Red Hat and ksh upstream.", 
          "On 01/09/2018 02:56, Kurtis Rader wrote:\n> See the /src/cmd/ksh93/OBSOLETE/ file for a list of features flagged as deprecated with the ksh93 release. We should give serious \n> thought to removing them in the next major release. Even the backtick command substitution form should probably be removed so that \n> there is just one way to do command substitutions. Some people are going to deem this too radical for consideration. I disagree. How \n> long does a feature have to be deprecated before it can be removed? I think twenty-four years is long enough \ud83d\ude04\n> \n\n;-)\n\nI think that there is little value in removing features.\n\nBut.\n\nIt would be {useful,interesting} to add one or two features that will warn or throw a fatal error\nduring compilation for either:\n\n1. deprecated syntax\n2. non-posix syntax\n\nCheers,\nHenk Langeveld\n", 
          "@kdudka: Yes, it does appear we have fundamentally different views for the future of ksh. You seem to want to retain 100% compatibility with the version of `ksh` included in distros such as Fedora and RHEL. With the possible exception of fixing bugs. I say \"possible exception\" because I have seen instances where fixing a bug is itself considered unacceptable because it deviates from existing behavior that users have come to expect. Hence my use of the phrase \"bug for bug compatible\" in another issue from when I worked for Sequent Computer Systems. But that means we can't even change the build system because doing so may introduce differences in behavior. Let alone doing something like removing ksh's dependency on the AST VMALLOC subsystem.\r\n\r\nMy view is that if ksh has any hope of remaining relevant we have to break with the past. Which means updating the build system. Which means dropping dependencies on things like VMALLOC and SFIO which have not, and will never be, adopted by our industry. Which means restyling the code to a consistent style (whatever that style is) so that people who want to contribute improvements can more easily grok the code. It means removing the half-baked features that are undocumented and untested (e.g., `SHOPT_FIXEDARRAY`). It means removing features of dubious value that are undocumented (e.g., `SHOPT_AUDIT`). It especially means removing ill-advised features that should never have been implemented in the first place (e.g., `SHOPT_BASH`).\r\n\r\nI'm willing to bet that 99% of those modernization steps will not be noticed by anyone using `ksh`.\r\n\r\nRemoving support for backtick command substitution isn't something we should do until we've made at least one major release since AT&T open sourced this code. That proposal was deliberately provocative to force people to think about what changes are acceptable in the near term. Also, if you look at other shells like [Fish](https://github.com/fish-shell/fish-shell/) which explicitly are not POSIX 1003.2 compatible you will see that they regularly get questions about supporting `$(...)` syntax. But I've never seen them get a question about supporting the older backtick form. So while we probably should not, at least in the immediate future, remove support for backtick syntax I do not consider doing so unreasonable as a future change.\r\n\r\nVendors like Red Hat can obviously continue to maintain their own forks based on branch `2016-01-10-beta` and try to fix bugs in those forks. I wonder how easy that has been to do given all the issues that have caused me to champion changing the build system, restyling the code, removing support for pre-ANSI C compilers, etc. in order to update the code base to something that is easier to understand and work with.", 
          "> Even if you improve ksh such that it compiles in 20 seconds, runs 10 times faster... nobody is going to use it unless it stays sufficiently compatible with ksh93.\r\n\r\nI agree with that statement. The question is what is \"sufficiently compatible with ksh93\". If we remove the `tgammal` math function is that insufficiently compatible with the last public ksh93 release? What about the behavior predicated on the `SHOPT_AUDIT` symbol? My first question is obviously a straw man question since only a handful of individuals will argue for continuing to support that math function despite being unable to provide evidence anyone has used them in a production ksh script. Removing the behavior predicated on the `SHOPT_AUDIT` is more difficult. But I think I can make the case the current implementation is does not achieve its goals and is not sufficiently documented.", 
          "Could the mathematical functions be extracted into a \"plugin\" - i.e. shared library.\r\nIt would only be loaded if an environment variable were set, e.g. `KSH_MATH_ENABLED`.\r\nAlso, as soon as one of the math functions supported are invoked.", 
          "On Friday, January 12, 2018 7:45:11 AM CET Kurtis Rader wrote:\n> I'm willing to bet that 99% of those modernization steps will not be noticed\n> by anyone using `ksh`.\n\nI wish you were right.  Unfortunately, we have currently no data to support \nthis statement.  The only reliable feedback we have is that a customer opens\na support case about something that broke after update.  At that time, it is \nusually already too late to do anything reasonable about it.  Red Hat simply \ncannot afford this try/fail approach.\n\nIf I could recommend anything, please release a new version of ksh consumable \nby Linux distros rather sooner than later.  This way you can get feedback on \nthe recent changes before it is too late to revisit some of them.\n\nOtherwise the development feels to me just too disconnected from end users\nto be successful.\n", 
          "Regarding the math functions, they are an integral part of `ksh93` now, (that ship has already left) so can't just be removed or deprecated on a whim.  Why should they be removed anyway, and how is that improving `ksh93` and making it more relevant?\r\n\r\nAnd even if things are buggy still, that doesn't mean they should be removed?  Isn't your job as a maintainer to fix the bugs, not just to remove the code because you think no-one is using or would use it?  Including `SHOPT_FIXEDARRY`.  And why is the burden of proof whether people are using math functions on us anyway?  There was a lot of interest in the `ast-developers` list for math functions, which is why they are there.\r\n\r\n\r\nTo quote Michal Hlavinka, a previous `ksh93` maintainer from Red Hat from the `ast-developers` mailing list (not indexed on the web):\r\n\r\n> We ship what version our userbase needs and they mostly need their scripts to be working. Some have scripts hundreds of thousands lines long and don't want to update those scripts (ksh sometimes changes behaviour with next release) because it would be huge effort and it would introduce bugs. I'm not sure about bug infested either. We track more complains about bugs in latest release than the patched version we have. (Talking about real complains, not theoretical list of what bug can anyone see by checking the changelog.) The bugs that our userbase reports are usually present in latest release too and we usually write/backport the fix for next rhel minor release. So, lets agree to disagree.\r\n> ...\r\n> Back to the topic. ksh in rhel 7 won't be updated any time soon. First, there is no stable release to update to. Second, it changes behaviour of `...` vs. $(...) and when it's supposed to be completed. We can't throw that at our users in released version. It would break their scripts and make them angry. So this will get in in next major update (rhel 8). If you want this to be backported, you have to contact the official support and it will be evaluated by product management.\r\n\r\nSo even 40-year-old shell syntax has to stay, which is why `ksh` has always just added new syntax to get around old limitations.  Eg: `[[ ]]`, `$( )`, `function` keyword\r\n\r\nTo @kdudka:\r\n> If your intention is to develop a modern programming language, why are you starting with (k)sh in the first place? \r\n\r\nFor the love of shell scripting (`ksh93`)!  And enhancing `ksh93` with modern syntax would be awesome!\r\n\r\nI have been very busy so have not had time to review my proposals and would rather be doing that than replying to this thread.", 
          "@catull wrote:\r\n> Could the mathematical functions be extracted into a \"plugin\" - i.e. shared library.\r\n> It would only be loaded if an environment variable were set, e.g. KSH_MATH_ENABLED.\r\n> Also, as soon as one of the math functions supported are invoked.\r\n\r\nFirst, a dynamically loaded math library is ONLY needed if one wants to (for whatever\r\nreason) reduce the size of the default KSH binary on a system -- but does the inclusion \r\nof math functions really make the KSH binary so much bigger?\r\n\r\nIf it is indeed desired to reduce the size of a minimum KSH binary, I had a similar thought \r\nas @catull but slightly different.  The user could set something like:\r\nKSH_LIBMATH=libkshmath.so (or whatever the user might have)\r\nin the environment, and then when the first math function is invoked, the shared library\r\nwould be loaded (|dlopen(3dl)|).  Also, there should be both a default name and path to the\r\nlibrary as well as searching the LD_LIBRARY_PATH or DYLD_LIBRARY_PATH (or whatever),\r\nso that math functions still work even in the absence of any environment variable. That is,\r\nthe math functions would always be enabled.  If the caller never calls any of them, then\r\nno library would be loaded. If, for example KSH was installed on a system in:\r\n/usr/local/bin/ksh\r\nthen the default associated KSH math library could be:\r\n/usr/local/lib/libkshmath.so.1\r\net cetera, you all get the idea.\r\n\r\n\r\n\r\n\r\n", 
          "I agree with @kdudka. We should get our changes in hands of community as soon as possible. This is the main reason I spent time trying to get [Copr builds](https://copr.fedorainfracloud.org/coprs/g/ksh/latest/) working. I have managed to get builds working for RHEL (CentOS) along with Fedora. Hopefully we will be able to get more users to test these packages. If we end up removing any feature which is required by majority of users, we will have to revert back.", 
          "If binary size reduction is a requirement, there must be an issue for that; there is none yet.\r\n\r\nWhat @krader1961  is doing does contribute to reducing the size of the **source code** in various ways.\r\n\r\nE.g. by shaking off dead wood, source code lines guarded by `#ifdef`s that are not evaluating to true.\r\n\r\nOr by getting rid of code that was required for ancient platforms or compilers (pre-ANSI C etc).\r\n\r\nThese may not be big wins towards size reduction of the binary.  It is not a goal, just a side-effect.\r\n\r\nI have checked the sizes of some shells installed.\r\n\r\n```log\r\n-r-xr-xr-x 1 root     626'272 Apr 29  2017 /bin/bash\r\n-rwxr-xr-x 1 root     375'632 Mar 23  2017 /bin/csh\r\n-r-xr-xr-x 1 root   1'377'872 Mar 23  2017 /bin/ksh\r\n-r-xr-xr-x 1 root     630'464 Apr 29  2017 /bin/sh\r\n-rwxr-xr-x 1 root     375'632 Mar 23  2017 /bin/tcsh\r\n-rwxr-xr-x 1 root     592'656 Mar 23  2017 /bin/zsh\r\n\r\n-r-xr-xr-x 1 root  14'676'616 Jul  3  2017 /usr/local/bin/elvish\r\n-rwxr-xr-x 1 root     988'720 Jul  3  2016 /usr/local/bin/fish\r\n-rwxr-xr-x 2 root     728'092 Oct 28 12:15 /usr/local/bin/zsh\r\n\r\n-rwxr-xr-x 1 root   1'148'560 Jan 12 17:26 /usr/local/bin/ksh\r\n-rwxr-xr-x 1 root   1'498'884 Jan 12 17:25 /usr/local/lib/libast.dylib\r\n-rwxr-xr-x 1 root      14'080 Jan 12 17:26 /usr/local/lib/libcmd.dylib\r\n-rwxr-xr-x 1 root      51'548 Jan 12 17:26 /usr/local/lib/libcoshell.dylib\r\n\r\n-rwxr-xr-x 1 root   1'217'496 Feb 23  2017 /opt/bash/bin/bash\r\n```\r\n\r\nThis is on macOS 10.12.6\r\n\r\nThe shells in `/bin` above come pre-installed.\r\nThe ones in `/usr/local/bin` and `/opt/..` I have built and installed myself.\r\n\r\n`/bin/bash` is version \"3.2.57(1)-release\".\r\n`/opt/bash/bin/bash` is version \"4.4.0(1)-release\".\r\n\r\nThe two binaries `/bin/ksh` and `/usr/local/bin/ksh` have the ration of 6 : 5, which is good.\r\n\r\nThe `zsh` comes off as pretty small; however, some of the functionality is tucked away in 20-ish shared libraries the size between 8k and 260k each.", 
          "> Regarding the math functions.... Why should they be removed anyway, and how is that improving ksh93 and making it more relevant?\r\n\r\n@dannyweldon, We're ratholing a bit on the question of the math functions. The issue isn't math functions per se. There is absolutely nothing wrong with exposing 80% of the libm functions. What I find egregious was exposing the other 20% of those functions for no reason other than that they are provided by most libm/libc implementations and exposing them was trivial. I'm talking about functions that cannot reasonably, or probably even correctly, be used in a language like ksh. Functions like `tgammal`, `j0` and `errf`. I am not talking about things like the trigonometric functions or `ceil`. I've asked multiple times, both publicly and privately (in response to emails I received) for a single example of a production script that uses those functions. Crickets. I would fire anyone who wrote a ksh script that used those math functions. Ksh is not even remotely the right tool for a job that requires those functions.\r\n\r\nFinally, note that the original code had a separate `iffe` feature detection test for every single libm function (which is why it was a major contributor to the slow build speed). So theoretically you could find yourself trying to run your script on a `ksh` implementation that did not provide the `tan()` function. Or any other math function. Ksh provides no fallback implementation if the system libm/libc libraries don't provide one of those functions. It will simply tell you \"ksh: tan(1) : unknown function\".\r\n\r\n> If I could recommend anything, please release a new version of ksh consumable by Linux distros rather sooner than later.  This way you can get feedback on the recent changes before it is too late to revisit some of them.\r\n\r\nAgreed, @kdudka. That's why we're working to stabilize the new build system and ensure ksh can be built and run on a representative set of distros. The fact we can't currently get a working ksh on OpenBSD 6.2 concerns me.\r\n\r\nIt is also clear from this discussion that a rebranding is going to be needed. Which was obliquely mentioned in #335. We'll need to make it easy for distros, including mechanisms like Homebrew for macOS, to provide both the legacy ksh93 side by side with this resurrected incarnation.\r\n\r\n> So even 40-year-old shell syntax has to stay, \r\n\r\nHere I'm going to disagree, @dannyweldon. There are reasons why languages like Python do things like drop support for `print` as a language keyword and replace it with `print()` as a function when they went from python2 to python3. Yes, it was painful and many users choose to stay on python2. Nonetheless, such changes are necessary.\r\n\r\nIn any case, as I've said before, my suggestion we drop support for backtick command substitution wasn't really serious. While I hope no one has written a ksh script in the past decade using backtick command substitution I agree we can't remove support for it anytime soon. The question was to get people thinking about which incredibly old, deprecated, features we can drop when making the next major release. Better examples are things like `set -k` or the `FCEDIT` env var (both from *src/cmd/ksh93/OBSOLETE*).\r\n\r\n> If we end up removing any feature which is required by majority of users, we will have to revert back.\r\n\r\nI agree, @siteshwar. Although I might modify that statement by changing \"majority\" to \"significant number\" of users. I know \"significant number\" is an ill-defined phrase but I use it quite deliberately because there is a cost:benefit ratio to consider. We might retain a feature that is used by 0.1% of the ksh user base if that feature has a small source code footprint and is unlikely to cause problems over the long term. But we might jettison a feature used by 1.0% of the ksh user base if its source code footprint is large, it doesn't mesh well with the rest of ksh, is not compatible with the goals of the project (e.g., 100% compatibility with Bash), and/or is likely to be expensive to maintain.", 
          "I can't help but mention an enhancement I'd like to see implemented to offset the perceived negatives of removing features deprecated decades ago. At some point I'll open an issue but the short version is ksh should allow marking the end of a block via a `end` keyword. Rather than require `fi` to end a `if` block, `esac` to end a `case` block, `done` for a `while` block, etcetera. The current syntax is not friendly. Imagine if C/C++ required something other than a close-brace, `}`, depending on the original flow of control statement.", 
          "My prior comment noted that if ksh was built on a system that could not detect a math function like `tan()` it will emit this error if you try to use it:\r\n\r\n> It will simply tell you \"ksh: tan(1) : unknown function\".\r\n\r\nWhich means no one can bitch about removing support for any math functions since ksh does not promise they will be available. So please explain to me why we cannot remove those functions  in light of the legacy project behavior. I agree that doing so might might break a script which uses those math functions. But by definition the legacy ksh could break that script.\r\n\r\nAgain, to be clear, I think ksh should continue to provide, unconditionally, support for basic math functions including trigonometric functions like `tan()`. If a platform's libm/libc does not support those functions then either ksh should not build on that platform or it should provide a fallback implementation.", 
          "> I would fire anyone who wrote a ksh script that used those math functions. Ksh is not even remotely the right tool for a job that requires those functions.\r\n\r\nSorry, but when you keep making assertions like this, I think it just shows how out of touch you are with `ksh`.  And I do not have the time to respond to every argument/assertion you make that I disagree with or I would not get anything done.\r\n\r\nI disagree that `fi`, `esac` and `done` are unfriendly as they indicate what type of block they are closing,  and I would be against what you are proposing.  An `end` keyword may have other unforeseen uses down the track, so wasting it on something like this would preclude that, and anyway, it just amounts to syntactic sugar.\r\n\r\n> Which means no one can bitch about removing support for any math functions since ksh does not promise they will be available. So please explain to me why we cannot remove those functions in light of the legacy project behavior. I agree that doing so might might break a script which uses those math functions. But by definition the legacy ksh could break that script.\r\n\r\nSo, `ksh` is not going to implement the platform's math function library for them.  That's up to the OS maintainer.  If those functions are missing and someone wants to use them, they should simply log a support case with their vendor.", 
          "On 01/13/2018 15:00, Danny Weldon wrote:\n>     Which means no one can bitch about removing support for any math functions since ksh does not promise they will be available. So\n>     please explain to me why we cannot remove those functions in light of the legacy project behavior. I agree that doing so might\n>     might break a script which uses those math functions. But by definition the legacy ksh could break that script.\n> \n> So, |ksh| is not going to implement the platform's math function library for them. That's up to the OS maintainer. If those \n> functions are missing and someone wants to use them, they should simply log a support case with their vendor.\n\n+1\n\nThe math functions should be all-or-nothing.\n\nHowever, I do understand Kurtis' argument about useless libm functions, and we could define\na standard set of libm functions that constitute a successful ksh math build?\nOn the other hand, that would mean we would still need to check for their presence\nup front, which would slow down the build again...\n\nOn the third hand, we could postpone the checks with a post-build check of the math functions\nfrom ksh itself.\n\nHenk\n", 
          "I don't think we need to provide `tgammal` or `tgammaf` versions of the math functions because they only take one type: `double`.\r\n\r\nWhat if we added a phrase to the man page saying something like:\r\n\r\n    subject to being available in the local C library implementation\r\n\r\nor just:\r\n\r\n    if available"
        ], 
        "number": "344", 
        "title": "Remove features deprecated when ksh93 was released"
      }, 
      {
        "comments": [
          "Also, notice the somewhat unusual formatting of the version information:\r\n\r\n```\r\n$ src/cmd/ksh93/ksh --version\r\n  version         sh (AT&T Research) 93v- 2014-12-24\r\n$ echo $KSH_VERSION\r\nVersion BIJ 93v- 2014-12-24\r\n```\r\n\r\nThis makes using that information to programmatically determine which version is being used, and thus which features are available, more difficult than it needs to be. Which is another reason I favor a simple semantic version string.", 
          "But if you echo them in an arithmetic context, you get just the plain number:\r\n\r\n    $ echo $(( KSH_VERSION ))\r\n    20141224\r\n    $ echo $(( .sh.version ))\r\n    20141224\r\n\r\nIn one way, this makes it easier to check for a particular feature by checking whether this number is `>=` a particular date stamp.  There is no reference available though for when features were added, so I had been making notes of a few from the old email list when I came across them and from the RELEASE file.  Perhaps I could start a wiki page for it.\r\n\r\nIt might be better to keep that as is, so that existing scripts don't break and the fact that `93 < 2014`, and create a new variable.  eg. `.sh.semver`, but then should that become an array like `$BASH_VERSINFO`?  Or, maybe use `$KSH_VERSINFO`?  (But I don't particularly like the name.)\r\n\r\nI don't agree with starting a semver from `93` either.  That number should have been changed years ago.  There was a mention on the ast-developers lists that the internal company politics to get it changed was too hard, so they found it easier to just leave it.\r\n\r\nI think for major versions:\r\n\r\nksh88 was version 1\r\nksh93 was version 2\r\nnext major release version 3 ?\r\n\r\nHowever, you could argue that there probably has been lots of releases of `ksh93` that added major new features, but they were always backward compatible, so you could class them as minor releases.  So technically, you could just start the versioning at `2.100.0` (`100` being some arbitrarily high number), or perhaps just `3.0.0`, to separate it out and because you have made some major changes to the build system, which would affect people building their own builtins.", 
          "ksh88 is related to 1988.\r\nksh93 itself is linked to 1993.\r\n\r\nIs it too far-fetched to say ksh 2018 is in progress ?\r\nPerhaps ksh 2020 is more catchy.\r\n\r\nThere is also a need to distinguish long and short version info.\r\n\r\n> $ src/cmd/ksh93/ksh --version\r\n>  version         sh (AT&T Research) 93v- 2014-12-24\r\n\r\nHere I would expect something along the lines of\r\n\r\n```sh\r\n$ src/cmd/ksh93/ksh --version\r\n93v-\r\n\r\n$ src/cmd/ksh93/ksh --full-version\r\nksh (AT&T Research) 93v- 2014-12-24\r\n```\r\n\r\nArgument names can also be:   `--version-short` vs `--version-long`, leaving `--version` as is.\r\n", 
          "I would hope we'd reserve changing 93 to another YY only after the next\nmajor revision of the language semantics ... not just a new spin.\n\nThat said, I certainly have no objection to a git hash and/or semantic\nstring as mentioned above. Certainly for compatibility with existing\nscripts which check for 93* I wouldn't want to strip that out (again, until\nthere's a major semantic shift ;>).\n\nKeith Bierman\nkhbkhb@gmail.com\n303 997 2749\n\nOn Mon, Jan 8, 2018 at 1:51 PM, catull <notifications@github.com> wrote:\n\n> ksh88 is related to 1988.\n> ksh93 itself is linked to 1993.\n>\n> Is it too far-fetched to say ksh 2018 is in progress ?\n> Perhaps ksh 2020 is more catchy.\n>\n> There is also a need to distinguish long and short version info.\n>\n> $ src/cmd/ksh93/ksh --version\n> version sh (AT&T Research) 93v- 2014-12-24\n>\n> Here I would expect something along the lines of\n>\n> $ src/cmd/ksh93/ksh --version\n> 93v-\n>\n> $ src/cmd/ksh93/ksh --full-version\n> ksh (AT&T Research) 93v- 2014-12-24\n>\n> Argument names can also be: --version-short vs --version-long, leaving\n> --version as is.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/att/ast/issues/335#issuecomment-356092498>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/ALeolzPV8I59HIgKir4yUqlHTsziJ11Jks5tIn_TgaJpZM4RVhMn>\n> .\n>\n", 
          "@KeithBierman, I agree with you, more or less. I say \"more or less\" because a lot of time has elapsed since the last stable release. And, among other things, this project is now using a new build system. Which itself is a major change. Even if we haven't made any substantive changes to the behavior of `ksh` the aforementioned changes warrant a change to the major version of the project. If only to signal that there is new management of the project.\r\n\r\n@dannyweldon, Your comment is interesting in as much as I had not explored how the ksh version was exposed within a ksh script. But my point remains that `ksh --version` is basically unusable.", 
          "On 01/07/2018 12:36, Danny Weldon wrote:\r\n> I don't agree with starting a semver from |93| either. That number should have been changed years ago. There was a mention on the \r\n> ast-developers lists that the internal company politics to get it changed was too hard, so they found it easier to just leave it.\r\n\r\nThat discussion, IIRCC, was more about the legal name of the \"product\" \"ksh93\".\r\n\r\nThe original ksh was released as \"ksh88\".  The next update was released as a separate entity, and this was \"ksh93\".\r\nThe original ksh93 was offered as part of the AT&T Toolchest, a precursor to AST, which also contained nawk and nmake.\r\nFor a dollar sum with five figures you could download everything over a modem connection.\r\n\r\nSeveral milestones later, first ksh93 was released as freeware (binaries only) and later this century as open source.\r\nThroughout all of this time, the name of the product in legal speak remained \"ksh93\", even after over 20 major revisions.\r\n\r\nAll this time, the name \"ksh93\" was maintained, and the \"93\" is not a version number, nor has it anything to do with 1993.\r\n\r\nIt's a brand.  We should grandfather it somewhere into the version string.\r\n\r\nWe could do all kinds of things, like turning .sh.version into an assoc array,\r\nwith .sh.version.release, .sh.version.major,  .minor, etc...\r\n\r\n\r\n5 minutes fiddling later ...\r\n\r\nInterestingly, I find I can just do stuff like:\r\n\r\n     .sh.version.release=\"2012-08-01\"\r\n     .sh.version.compact=\"93u+\"\r\n\r\nand:\r\n\r\n     print -v .sh.version.{release,compact}\r\n     2012-08-01\r\n     93u+\r\n\r\nHey, I could write a ksh library module that would extract these strings from the legacy version strings...\r\n\r\nAny takers?\r\n\r\n\r\nCheers,\r\nHenk\r\n", 
          "> Throughout all of this time, the name of the product in legal speak remained \"ksh93\", even after over 20 major revisions.\r\n\r\nYes, that matches my recollection as an employee of Sequent Computer Systems for two decades. And it's one reason why I think we should revert to just \"`ksh`\" everywhere other than where we want to make it explicit this work is based on what has long been known as `ksh93`. And that means dropping the \"93\" from the version number, but possibly keeping it as a parenthetical in the long form version string.\r\n\r\nAlso, I still feel our first stable release should be viewed as a major release. Even if we don't add a major new feature. The reason is that we are pruning (i.e., removing) some experimental features like `SHOPT_FIXEDARRAY` and features of dubious value and correctness like `SHOPT_AUDIT`. That alone warrants changing the major component of the version number from \"93\" to something else.", 
          "Also, the fact you can mutate what should be read-only attributes is itself a problem in my opinion:\r\n\r\n```\r\nInterestingly, I find I can just do stuff like:\r\n\r\n     .sh.version.release=\"2012-08-01\"\r\n     .sh.version.compact=\"93u+\"\r\n```\r\n\r\nThose values should be considered immutable and the implementation should not allow changing them. My opinion is obviously going to be controversial. Consider `bash`:\r\n\r\n```\r\nbash-4.4$ echo $BASH_VERSION\r\n4.4.12(1)-release\r\nbash-4.4$ BASH_VERSION=wtf\r\nbash-4.4$ echo $BASH_VERSION\r\nwtf\r\n```\r\n\r\nI think allowing mutating such a fundamental attribute is wrong and can potentially lead to correctness, if not security, problems. Under what circumstances would you consider it acceptable to alter the output of `bash --version` without running a different version of bash?", 
          "> Those values should be considered immutable and the implementation should not allow changing them.\r\n\r\nAgreed.  I checked ksh and it has similar issues.\r\n\r\n> Hey, I could write a ksh library module that would extract these strings from the legacy version strings\r\n\r\nThanks, Henk.  They probably should be implemented in the ksh binary itself though.  Unless that is what you meant?", 
          "@krader1961 I think we vehemently *agree*.\r\nNote that these substrings do not exist currently...\r\nI would *not* want to change an existing version string during operation.\r\n\r\nThis was meant more as an example of how we could extend the existing\r\nversion string and turn it into a struct of sorts.\r\n\r\nAnd we can do better, and make them readonly:\r\n\r\n    function _ksh_set_version {\r\n      typeset -a A\r\n      A=(${.sh.version})\r\n      readonly .sh.version.prefix=${A[0]}\r\n      readonly .sh.version.legacy=${A[1]}\r\n      readonly .sh.version.compact=${A[2]}\r\n      readonly .sh.version.release=${A[3]}\r\n    }\r\n\r\nThink of this extension as akin to the various `uname` options to extract particular release info, vs. `uname -a` that prints the entire string.\r\n\r\nCreating these subfields does not change the original version string at all.\r\n\r\nBy adding the `readonly` we can make sure this only happens once.\r\nHeck, I'm tempted to add this to `.sh.version` itself...\r\n\r\nUnfortunately, there is no global init file for non-interactive shells, but a shell programmer can include this little piece in a standard library* for ksh.\r\n"
        ], 
        "number": "335", 
        "title": "What versioning scheme should we use?"
      }, 
      {
        "comments": [
          "And further along that lane, _WINIX is now a synonym for \\_\\_CYGWIN\\_\\_.\r\nCf. [ast_common.h](https://github.com/att/ast/blob/master/src/lib/libast/include/ast_common.h#L48-L50)\r\n\r\nIt might as well be replaced with \\_\\_CYGWIN\\_\\_.\r\n\r\nBeforehand, _WINIX was defined as (UWIN || \\_\\_CYGWIN\\_\\_ || \\_\\_EMX\\_\\_).\r\n"
        ], 
        "number": "329", 
        "title": "It should be possible to remove the code that depends on symbol `_WIN32`"
      }, 
      {
        "comments": [
          "We have been using coverity within Red Hat to scan ksh package builds. I agree that we should use it to scan upstream code too.", 
          "How frequent do you want to run it ?\r\nIs it a manual task, automated ?\r\n\r\nIf automated, is it run monthly, weekly ?\r\n\r\nIf it scans on each merge/commit, it would create an entire report that is likely not read.\r\nI mean, only every 15th or so would be read.\r\n\r\nI support the scanning, it is miles better than relying on clang / gcc to issue warnings.\r\n", 
          "@catull, Those are good questions. Coverity scans should not need to be manually initiated. Running  those scans on every commit is obviously silly since many commits will not materially affect the output of the analysis. This is the type of feature that should be performed periodically such as weekly or biweekly."
        ], 
        "number": "327", 
        "title": "Setup Coverity Scan for this project"
      }, 
      {
        "comments": [], 
        "number": "311", 
        "title": "OpenSUSE & sysinfo"
      }, 
      {
        "comments": [
          "It looks like some ```iffe``` test failed to execute. You can see it by executing these commands manually :\r\n\r\n```\r\ngit clean -dfx\r\nbin/setup_cmds.sh\r\nbin/libast_prereq.sh\r\n```"
        ], 
        "number": "285", 
        "title": "Ksh doesn't build on macOS 10.8 (Mountain Lion)"
      }, 
      {
        "comments": [
          "Some tests, by their very nature, require a specific locale. It's not clear from your problem description if you think the problem is that the test framework doesn't override any LC_&ast;/LANG env vars the user might have set. Or if the problem is that those tests fail if the locale isn't `C`.", 
          "I am quoting your own words, in https://github.com/att/ast/issues/255#issuecomment-353765919 you state:\r\n> Thanks for bringing this to our attention, @catull. This is an example of something that might have been okay more than a decade ago but is no longer valid.\r\n\r\n> I'm going to reopen this because unit tests should be immune to the user's values for locale env vars. I have LANG=en_US.UTF-8 in my environment but do not have a LC_ALL var. Simply setting LC_ALL in my environment should not affect unit test behavior. Unit tests are, by definition, supposed to be immune to the preferences of the user running them.\r\n\r\nIn issue #255 it was about a strange case of working in macOS but not in Fedora.\r\nHere it is about the test which only works with LC_ALL='C' or unset.\r\n\r\nHow can this be fixed ?\r\n\r\nI can see a couple of ways.\r\n\r\nA) The test case could be split into 3 different ones: `glob`, `glob-C` and `glob-en_US.UTF-8`.\r\n     In each one of them, LC_ALL is set accordingly - except for in `glob` it is specifically unset.\r\nB) The set is run with LC_ALL='C' because that is the pattern I see most \"compatible\"\r\n\r\nIn both scenarios, the original value of LC_ALL is saved away and restored after the test exits.\r\n\r\nBy \"most compatible\" I mean, pretty much everywhere in the code base LC_ALL is used explicitly as `env LC_ALL='C' some_command ....`\r\n\r\nBack in the '80s there was no UTF-8 in use on Unix systems.\r\nUTF-8 became the default encoding format for Solaris and Linux only at the beginning of the century, perhaps a few years before the turn of the century.\r\n\r\nPerhaps there are other ways to better deal with the situation.\r\nThe easiest way would be option B) with pre-saving and restoring the env variable LC_ALL.\r\n", 
          "[Lines 24-31 of src/cmd/ksh93/tests/shtests](https://github.com/att/ast/blob/master/src/cmd/ksh93/tests/shtests#L24-L31) state:\r\n```\r\n    The default environment settings are:]\r\n    {\r\n        [+unset LANG]\r\n        [+unset LC_ALL]\r\n        [+LC_NUMERIC=C?\\b.\\b radix point assumed by all test scripts.]\r\n        [+VMALLOC_OPTIONS=abort?\\bvmalloc\\b(1) arena checking enabled\r\n            with \\babort(2)\\b on error.]\r\n    }\r\n```\r\n\r\nI think the case is clear now.\r\n", 
          "> In both scenarios, the original value of LC_ALL is saved away and restored after the test exits.\r\n\r\nThat should not be necessary. Environment vars are inherited. If the test framework changes an env var such as `LC_ALL` that will not affect the environment of the person running the test.\r\n\r\nNote that running without a specific locale being set by the test framework means it will use whatever locale is in effect when the tests start running. That is, it will use the value of `LANG` and the other `LC_`&ast; vars. That is not good. While we might want to provide a way to explicitly test using an unusual locale the default should always be a hermetic test environment that is not influenced by user preferences such as the current value of `LANG` or `LC_ALL`.\r\n\r\nNote that if the test environment unsets `LANG` and `LC_ALL` that should be equivalent to `LC_ALL=C` assuming no other `LC_`&ast; vars are set. Which is not a safe assumption. We should ensure that all locale vars are either not set or set to known values as as `C` and `en_US.UTF-8`. Long term this should be extended to other locales that don't share the assumptions implicit in those American centric locales."
        ], 
        "number": "268", 
        "title": "test glob and friends succeed only with LC_ALL='C' or unset"
      }, 
      {
        "comments": [
          "The minimal set of shell script to reproduce this behaviour is\r\n\r\n```ksh\r\nfunction err_exit {\r\n  print -u2 -r $1: \"${@:2}\"\r\n}\r\nalias err_exit='err_exit $LINENO'\r\ntypeset -T X_t=(\r\n  typeset x=foo y=bar\r\n  typeset s=${_.x}\r\n  create() {\r\n    _.y=bam\r\n  }\r\n)\r\nX_t x\r\n[[ ${x.x} == foo ]] || err_exit 'x.x should be foo'\r\n[[ ${x.y} == bam ]] || err_exit 'x.y should be bam'\r\n[[ ${x.s} == ${x.x} ]] || err_exit 'x.s should be x.x'\r\ntypeset -T Y_t=( X_t r )\r\nY_t z  ## <------ the SIGSEV happens when this statement is executed\r\n[[ ${z.r.x} == foo ]] || err_exit 'z.r.x should be foo'\r\n[[ ${z.r.y} == bam ]] || err_exit 'z.r.y should be bam'\r\n```\r\n", 
          "One of the things we need to do is change the test driver to treat every unit test script that exits with a non zero status as having failed.", 
          "Created PR #269 to cause it to FAIL.", 
          "> One of the things we need to do is change the test driver to treat every unit test script that exits with a non zero status as having failed.\r\n\r\nI am afraid the test driver \"trusts\" the unit test scripts to correctly behave.\r\nThe only way to assist the test driver is to apply the same pattern at the beginning of the unit test scripts:\r\n\r\n```ksh\r\ntrap 'rm -fr $tmp' EXIT\r\ntrap 'rm -fr $tmp; exit 1' 0 1 2 3 5 7 8 9 10 15\r\n```\r\n\r\nOf course, if no temporary folder is created in the first place, this pattern reduces to:\r\n\r\n```ksh\r\ntrap '' EXIT\r\ntrap 'exit 1' 0 1 2 3 5 7 8 9 10 15\r\n```\r\n\r\nIf the two lines are transposed, the script succeeds.\r\nConsequently, if only the line with `EXIT` is used, the script succeeds as well!!"
        ], 
        "number": "267", 
        "title": "Tests types, types(shcomp) and types(C.UTF-8) on macOS - investigation"
      }, 
      {
        "comments": [
          "IMHO using `strncpy()` should not be used anymore as buffer overflow issues are more severe than all the other things talked over in your referenced lwn.net article. In fact, `strlcpy()` should definitely be preferred (in addition to guarding it with `if()`) to improve general security in ksh.\r\n  ", 
          "Sorry, @jens-maus, but `strlcpy()` just has a different failure mode. Albeit one whose consequences are less likely to result in a security hole but no less wrong. You can't just use it without dealing with the result being truncated. Any more than you can use `strncpy()` without ensuring the destination buffer was long enough for the terminating null. It's just a different way to shoot yourself in the foot and isn't as widely available. Which means maintaining our own implementation. No thank you.\r\n\r\nAlso, implementations of `strncpy()` are likely to be highly optimized for the machine architecture. That will never be true for the AST `strlcpy()` implementation."
        ], 
        "number": "266", 
        "title": "Replace uses of `strlcpy()` with `strncpy()`"
      }, 
      {
        "comments": [
          "@catull We are running all the tests under fedora 27 on Travis and these tests are passing, so it may be an issue with how your system is configured. To debug the tests, you should put ```set -x``` on top of glob test script and run it as ```meson test glob -v```.", 
          "Part of the reason there are discrepancies is due to the different CFLAGS used in meson.build and .travis.yml.\r\n\r\nMy Fedora 27 box has the following installation:\r\n\r\n```sh\r\ndnf install ed gcc langpacks-zh_CN meson sudo binutils cpp glibc-devel glibc-headers isl kernel-headers libgomp libmpc ninja-build vim-filesystem glibc-langpack-zh\r\n```\r\nI copied this from a successful Travis CI build.\r\n\r\nI have filed an issue with a patch to even out the discrepancies as far as the compilation is concerned, between meson and Travis, see issue #258 and PR #259.\r\n", 
          "`meson test glob -v` gives me still:\r\n\r\n```log\r\nninja: Entering directory `/home/carlo/workspace/shell/korn/ast.git/build'\r\nninja: no work to do.\r\n\tglob.sh[156] glob -- expected '<d> <dd> <de> <Beware>', got '<Beware> <d> <dd> <de>'\r\n\tglob.sh[276] glob -- expected '<abc> <abe> <bdir> <ca> <de> <man> <Beware>', got '<abc> <abe> <bdir> <Beware> <ca> <de> <man>'\r\n1/1 glob                                    FAIL     0.47 s\r\n\r\nOK:         0\r\nFAIL:       1\r\nSKIP:       0\r\nTIMEOUT:    0\r\n```", 
          "Found the problem:\r\n\r\nI have a few extra env variables: LC_ALL=en_US.UTF-8.\r\n\r\nIf I unset it, or set it to 'C', the test does not fail anymore!\r\n\r\nClosing this, as resolved.", 
          "Thanks for bringing this to our attention, @catull. This is an example of something that might have been okay more than a decade ago but is no longer valid.\r\n\r\nI'm going to reopen this because unit tests should be immune to the user's values for locale env vars. I have `LANG=en_US.UTF-8` in my environment but do not have a `LC_ALL` var. Simply setting `LC_ALL` in my environment should not affect unit test behavior. Unit tests are, by definition, supposed to be immune to the preferences of the user running them.", 
          "I also have `LANG=en_US.UTF-8`.\r\n\r\nAs far as I can tell, there are commands performed with `LC_ALL=C` in the `Mamfile`s.\r\nShould the tests not also run with `LC_ALL='C'` ?\r\n\r\nIndeed, they would still succeed.\r\n\r\nOtherwise, the tests must check if that variable is set, store it away and carry on with a defined one.\r\nAt the end, the original value is restored, if any.\r\n\r\nThe question is, which one.\r\nIn the past, that value was`'C`, these days it would be `en_US.UTF-8`.\r\n"
        ], 
        "number": "255", 
        "title": "Tests glob* fails under Fedora 27, but not on macOS 10.12.6"
      }, 
      {
        "comments": [
          "Not surprisingly you can also find people reporting problems building ksh with this feature enabled: https://access.redhat.com/solutions/234843\r\n\r\nSee also https://administratosphere.wordpress.com/2011/05/20/logging-every-shell-command/ ", 
          "Based on feedback in some other issues it appears that at least a couple of distros have been building ksh with this feature enabled. The question is whether they knew they were doing so (i.e., enabled it deliberately) and is there anyone actually using this feature? I suspect the answers are \"no\" and \"no\". If you have reason to believe otherwise please speak up and comment on this issue.", 
          "@krader1961.  Auditing of shell usage is a required feature in most high security facilities such as DoD, NSA, NRO, etc.  You are not getting feedback from the appropriate people because you are not engaging the appropriate people..  If anything, auditing in ksh93 should be enhanced.", 
          "@fpmurphy, Okay, how do we get feedback from the appropriate people? I consider myself to be more security conscious than most IT people. I've read Bruce Schneier's books and subscribe to his blog. I agree that security, including auditing of actions performed, is important. But the existing ksh code guarded by `SHOPT_AUDIT` appears to be undocumented. Furthermore, the implementation seems to be inadequate for solving the problem it purports to address. Can you provide evidence my assessment is incorrect? I don't see an equivalent feature in `zsh` or `bash`. You seem to be claiming that you know that security conscious entities are explicitly using `ksh` due to the feature guarded by the `SHOPT_AUDIT`. Care to provide a citation for that assertion?", 
          "I just learned that Red Hat had a customer using RHEL explicitly request this be enabled in the RH builds. Which means we have to retain it. So I'll just do the same thing I've done for some of the other features controlled by a `SHOPT_\\*` symbol and just drop the `SHOPT_AUDIT` symbol so the feature is enabled in every `ksh` build.", 
          "We have to retain this feature as PCI audits require it.", 
          "Not sure how secure this is though if any user can view the audit log and see the commands of other users who may have accidentally or carelessly embedded a password into the command line.", 
          "@krader1961 I see that bash supports both libaudit and syslog.  Just grep the source code for these strings.\r\n\r\n@dannyweldon Why would anyone configure the audit log to be readable by arbitrary users?  If ksh allows it, then the administrator can indeed create an insecure setup.  But it does not mean that the ksh auditing feature itself is insecure.", 
          "@krader1961.  Your experience of shell development seems to be extremely limited.  If you were the least bit security conscious and SDLC-aware, you would not be trampling like a bull in a china shop all over the existing ksh93 source code, chopping or modifying feature after feature because you do not feel anybody is using that particular feature.   Organizations that use ksh93 (and other shells) use these shells in ways that you are obviously totally unaware of.  Organizations expect stability whereby new versions of a shell do not break existing scripts, not the radical changes you are making.    Nobody is going to ever touch ksh93.new if it breaks their existing  scripts!   Leave the SHOPT_AUDIT and all the other feature defines alone.", 
          "@fpmurphy, Your feedback is not constructive. If you want ksh93 with 100% compatibility with the last stable release by AT&T you're welcome to use that version, bugs and all. The point of all this activity is to try and modernize the code base so that it is easier for the open source community to contribute to its maintenance. And that entails removing things that are no longer relevant.\r\n\r\nSo far we've only removed one feature, SHOPT_FIXEDARRAY, because it was untested and based on an inspection of the code not ready for prime time. If it turns out that anyone is using that feature it won't be much work to reinstate that code. The only other item removed is support for the long obsolete AT&T UWIN environment. 99% of the other changes involve simplifying the code by always enabling a feature, such as SHOPT_MULTIBYTE, so that users don't have to worry about whether or not a particular distro chose to build with the feature enabled. Also, removing support for things we no longer need to support like pre-ANSI C compilers.\r\n\r\nAnd for your information I am more than \"the least bit security conscious\". While computer security is not my specialty I have read several books on the topic, have been reading Bruce Schneier's \"CRYPTO-GRAM\" emails almost as long he has been writing them, and have worked for companies like IBM and Google which take security extremely seriously.\r\n\r\nThe reason I opened this issue was to determine whether the complexity needed to be retained. Especially since it is trivial to bypass and therefore provides very little additional security by itself unless a lot of other steps have been taken to limit or audit the ability of an end user to execute commands or syscalls via means other than `ksh`.", 
          "@fpmurphy, You also apparently were so eager to rant that you didn't read my previous comment where I said we should \"drop the SHOPT_AUDIT symbol so the feature is enabled in every ksh build.\" That is, at the time you made your unhelpful comment, I had already agreed, approximately a full day earlier, this feature needed to be retained. There is a reason we're opening issues like this with a \"RFC\" label. We want to simplify the project by removing code that isn't needed. We don't want to break existing uses. Thus we're soliciting feedback before removing any code. Having said that it is clear the next release will have to be a major release because even if we made no changes that explicitly break backward compatibility a major release is warranted due to\r\n\r\na) the amount of time that has elapsed since every distro made their most recent ksh release, coupled with\r\n\r\nb) other changes such as the build system going from Nmake to Meson, enabling most features unconditionally, and removing dependencies on things like VMALLOC (high on my TODO list).", 
          "@kdudka, You wrote\r\n\r\n>  I see that bash supports both libaudit and syslog. Just grep the source code for these strings.\r\n\r\nYes, but where is that documented outside of the source code? I have no objection to retaining, and improving, this feature. What I object to is retaining a feature that is undocumented and is of dubious value. Having said that I have no objection to retaining this, seemingly flawed, feature since the amount of source code is small and easy to understand (and potentially unit test).", 
          "FFS! Look at that the *src/cmd/ksh93/edit/history.c* module. It requires that the user running `ksh` be able to open the `SHOPT_AUDITFILE` for reading. It then requires the user be able to open the actual audit file for writing if it is a local file. This only qualifies as a security feature if the `SHOPT_AUDITFILE` specifies a network path such as */dev/tcp/host/port* per @fpmurphy's [blog post](https://blog.fpmurphy.com/2008/12/ksh93-auditing-and-accounting.html). Which is not the same thing as explicitly supporting logging via syslog.\r\n\r\nI was going to enable this \"feature\" unconditionally but am now inclined to just nuke that code. Security is hard. Half assed solutions like this one benefits no one other than bad actors (e.g., hackers)."
        ], 
        "number": "240", 
        "title": "Remove support for SHOPT_AUDIT and SHOPT_AUDITFILE?"
      }, 
      {
        "comments": [
          "If someone spent time on implementing the option and getting it upstream in 2014 (when upstream was nearly inactive), it must have been for a very good reason.  Please do not remove it unless you know the reasoning behind.\r\n\r\nIn general, compatibility options are useful.  Especially Zsh does very good job in maintaining compatibility with other shells.  I know the compatibility is not 100% and it will likely never be.  Still having these options available makes porting legacy scripts at least possible without rewriting them from scratch.", 
          "```SHOPT_BASH``` option was present in ```ksh93u+```. You can see it in the code [here](https://github.com/att/ast/blob/2012-08-01-master/src/cmd/ksh93/sh/main.c#L215).", 
          "I always unset SHOPT_BASH before compiling ksh, and I vote for the complete removal of this code. (BTW, I also unset SHOPT_EDPREDICT, that does scale and turns out to be annoyingly slow on huge history files).", 
          "> SHOPT_BASH option was present in ksh93u+.\r\n\r\nOkay, but it doesn't seem to be operational. Copy that ksh binary to a file named `bash` and run it. You should be able to execute the `shopt` command. But none of the ksh93u implementations I have access to behave that way. Also, `set -o` should list a `bash off` option. If you build ksh from the master branch those things work. \r\n\r\n> In general, compatibility options are useful.\r\n\r\nExcept that isn't what this feature does. Assuming by \"compatibility options\" you mean features, perhaps disabled by default, that make it easier to port a bash script to ksh. I have no objection to such features assuming they otherwise mesh well with the existing ksh features. What this option appears to attempt to do is make ksh behave like bash when the ksh binary is invoked as `bash`. That is, be a faithful implementation of bash behavior. And that is just plain nuts. If I want bash behavior I'll use the bash command. This feature is like saying you prefer Python to Perl but because you have a bunch of Perl scripts you don't want to have to rewrite there should be a Perl emulation mode added to Python.\r\n\r\nI don't doubt the person who implemented this feature felt fully justified in doing so. But even good software engineers make bad decisions. In this case I'd bet the person who implemented this did not solicit feedback on the idea before they wrote the code.", 
          "Also, if you search the ast-developers list archive, https://marc.info/?l=ast-developers&w=2&r=1&s=shopt_bash&q=b, there is exactly one message by David Morano in 2015 that mentions this option. And that message is a FYI that building ksh fails if the feature is enabled.", 
          "Some of the code under ```SHOPT_BASH``` is operational even without enabling bash emulation mode. For e.g. test for [```local``` keyword]( https://github.com/att/ast/blob/master/src/cmd/ksh93/bltins/typeset.c#L385). ```SHOPT_BASH``` macro has been enabled by default for long time, so it will likely cause regressions when we remove code related to it.\r\n\r\nI agree that adding bash emulation mode in ksh was a bad decision, however given the current state of code, we will have to be exteremely careful while removing any code related to it.\r\n\r\nEDIT: ```SHOPT_BASH``` was enabled by default only since the last ```beta``` release, so my comment about it being \"enabled by default for long time\" was incorrect.", 
          "> Some of the code under SHOPT_BASH is operational even without enabling bash emulation mode.\r\n\r\nThat makes me a sad puppy. Adding a `local` keyword as an alternative to using `typeset` inside a function is a reasonable thing to do. But that should not have been tied to the bash emulation mode.\r\n\r\nI'll see if the bash emulation mode can safely be disabled and leave just the other aspects such as the `local` keyword. If not I'll open an issue to remind us to remove the bash emulation mode.", 
          "I think there needs to be more attention given to what @kdudka as a representative of Redhat says.  If you change ksh too much, you run the very real risk of it never being accepted back into the mainstream distros, mainly because they have paying customers to support, and they will definitely come first.  Meaning that they may be forced to stick with the old code and keep backporting fixes.  This would not be good for ksh acceptance.\r\n\r\nI was delighted when I discovered the bash emulation options for ksh and thought it was a stroke of genius.  If the ubiquitous bash can't catch up to ksh technically with it's type system, then make ksh try to emulate bash while bringing along the korn shell's benefits.  Sure, it would be better to make `local` a standard builtin and the bash emulation a compilation option.  Probably all new experimental features should be made to be a compile time option, or at least maybe that's how it was done before, whereas maybe it's better now to have them in separate branches now that the source is in git; I'm not sure.\r\n\r\nDon't think that ksh could not again rise to the top of the shell ecosystem.  There have been some surprising changes to the Linux world recently, with nothing being sacred any more:\r\n\r\n- systemd replacing sysv init\r\n- xfs the default filesystem on redhat instead of ext4\r\n- debian using dash for init scripts (this would have been a good case to use ksh instead)\r\n- the rise in the use of clang/LLVM instead of gcc\r\n- alternative implementations of php and ruby (similarly ksh could be a serious alternative implementation of bash if someone spent more time on it)\r\n\r\nAnyway, just removing unfinished experimental features adds nothing except an appearance of productivity and takes away valuable work that someone has spent time contributing.  That doesn't mean that all contributions should be accepted or ksh could end up like zsh, but this is code that was accepted by the author @dgkorn, if that means anything.  This also applies to #234.\r\n\r\n", 
          "@dannyweldon,\r\n\r\nIf my peers at RedHat, SuSE, or any other distro deem certain changes too radical, by which I mean they depart too far from existing ksh93u+ behavior, I am happy to drop those proposed changes. I do not think dropping bash emulation is in that category. Dropping support for the `local` keyword on the other hand is definitely in that category. That removing the `SHOPT_BASH` symbol and the code predicated on it might remove code we want to retain while simultaneously removes code we want to jettison simply reflects how messy the current code base is and why caution needs to be exercised in making such changes.\r\n\r\nAs I said earlier the bash emulation is equivalent to asking that the Python language have a means of emulating the Perl language.\r\n\r\nYour reference to issue #234 is interesting. That feature implementation is clearly incomplete. Despite many years passing since the original changes were merged. And the feature is not in any of the ksh93 implementations any one is using AFAICT unless they are building from this project's source.\r\n\r\nThere is a lot of bit rot in this project. I've already found several instances where the code fails to compile if various `#define` symbols involving \"experimental\" features are changed. And even if the code does compile with those build time symbol change I'll bet $100 that there are platforms we care about where it fails to run correctly when those symbols are changed.\r\n\r\nIf the community feels the bash emulation should be retained and improved I will stop contributing. Bash is an active project. It makes zero sense to commit the ksh team to tracking that moving target. It will be hard enough to fix all the extant issues with ksh specific features. Consider the [Fish](https://github.com/fish-shell/fish-shell/) and [Elvish](https://github.com/elves/elvish/) shell projects. Both have made it an explicit anti-goal to maintain POSIX 1003 compatibility. Obviously ksh can't do that given its origins. But I see no reason this project should commit to running bash or zsh scripts with full fidelity.", 
          "```SHOPT_BASH``` option is not enabled on RHEL or Fedora. It is not enabled on openSUSE either. It was turned on by default in the last ```beta``` release.\r\n\r\nRelated log from ```RELEASE``` file :\r\n\r\n```\r\n14-06-02 +When compiled with the SHOPT_BASH and run with the name bash,\r\n      the shell now uses dynamic scoping for name() and function name.\r\n      In addition the builtins declare and local are supported.\r\n      The SHOPT_BASH option is on by default in the Makefile.\r\n      More work remains with the bash compatibility option.\r\n```\r\n\r\nThe code around ```SHOPT_BASH``` was work under progress when it was enabled by default. This code is likely to be untested and will be a source of many issues if we start using it. Bash is a complex beast and it will require significant amount of work to support bash compatibility. Current codebase has large number of issues and supporting bash compatibility makes it worse. None of the active contributors is willing to spend effort to continue to support such option.\r\n\r\nI can see if we continue to support bash compatibility, there will be a use case for it, but the cost of maintainability outweighs it's benefits. It would be best to deprecate this option in next stable release.", 
          "While I see your points about the futility of chasing BASH, \"As I said\nearlier the bash emulation is equivalent to asking that the Python language\nhave a means of emulating the Perl language.\" is a bit strong, it is much\nmore similar to C vs. C++. There certainly have been C++ compilers which\nhad modes which accepted \"C\" rather than C++.\n\nThat said, for whatever it's worth, I concur that having a BASH mode for\nKSH (other than some bits the community might wish to make part of the\nnormal processing ... possibly *local* because it's arguably a good thing)\nis probably unhelpful.\n\nKeith Bierman\nkhbkhb@gmail.com\n303 997 2749\n\nOn Tue, Dec 19, 2017 at 11:29 PM, Kurtis Rader <notifications@github.com>\nwrote:\n\n> @dannyweldon <https://github.com/dannyweldon>,\n>\n> If my peers at RedHat, SuSE, or any other distro deem certain changes too\n> radical, by which I mean they depart too far from existing ksh93u+\n> behavior, I am happy to drop those proposed changes. I do not think\n> dropping bash emulation is in that category. Dropping support for the\n> local keyword on the other hand is definitely in that category. That\n> removing the SHOPT_BASH symbol and the code predicated on it might remove\n> code we want to retain while simultaneously removes code we want to\n> jettison simply reflects how messy the current code base is and why caution\n> needs to be exercised in making such changes.\n>\n> As I said earlier the bash emulation is equivalent to asking that the\n> Python language have a means of emulating the Perl language.\n>\n> Your reference to issue #234 <https://github.com/att/ast/issues/234> is\n> interesting. That feature implementation is clearly incomplete. Despite\n> many years passing since the original changes were merged. And the feature\n> is not in any of the ksh93 implementations any one is using AFAICT unless\n> they are building from this project's source.\n>\n> There is a lot of bit rot in this project. I've already found several\n> instances where the code fails to compile if various #define symbols\n> involving \"experimental\" features are changed. And even if the code does\n> change I'll bet a $100 that there are platforms we care about where it\n> fails to run correctly when those symbols are changed.\n>\n> If the community feels the bash emulation should be retained and improved\n> I will stop contributing. Bash is an active project. It makes zero sense to\n> commit the ksh team to tracking that moving target. It will be hard enough\n> to fix all the extant issues with ksh specific features. Consider the Fish](\n> https://github.com/fish-shell/fish-shell/) and Elvish\n> <https://github.com/elves/elvish/> shell projects. Both have made it an\n> explicit anti-goal to maintain POSIX 1003 compatibility. Obviously ksh\n> can't do that given its origins. But I see no reason this project should\n> commit to running bash or zsh scripts with full fidelity.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/att/ast/issues/238#issuecomment-352977025>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/ALeol4xGwZUF0AbJnjnjN3qAxJ2GILA9ks5tCKlcgaJpZM4RE6pz>\n> .\n>\n", 
          "@siteshwar Thank you for doing the research on this!  Given the facts, I agree that removing the feature (or at least disabling it by default) is a reasonable thing to do before the next release of ksh.", 
          "Thanks for commenting, @KeithBierman. This project definitely needs more involvement from people in the open source community like yourself. But I disagree with your assessment that this is \"more similar to C vs. C++.\" There is no question that both ksh, bash, and zsh derive from the original Bourne shell (the \"C\" language in your analogy). But there is no equivalent to the C++ language standard that binds them. This is very much like asking that Python have a mode that allows it to run Perl programs.\r\n\r\n\"Bug for bug compatible\" is one of the phrases I heard many years ago when I worked for Sequent Computer Systems. That was because even though a particular behavior is objectively wrong, whether or not measured against a published standard versus a specific implementation, the reality is that you sometimes need to exhibit the same \"bug\". As an open source project I don't see any reason we should try to be \"bug for bug\" compatible with `bash`.\r\n\r\nIssue #220 notes that the `local` keyword doesn't work if using the `my_func() {...}` syntax but does work when using the `function my_funct {...}` syntax is 99.99% likely to be related to this half-baked change.", 
          "Okay, I would have liked to have had it kept, but I will concede that it is probably best to remove it.  The code will still be there in the history if someone really wants to resurrect it to complete it.  But this begs the question on how new features are going to be accepted, especially as like `SHOPT_FIXEDARRAY`, they often involve multiple touch points over multiple files.  I am assuming that the preference would be for working PRs that merge cleanly without the conditional compilation?\r\n\r\nAnd Kurt, I think bash and ksh are different shell dialects, whereas perl and python are completely different languages, but lets not quibble.  :-)\r\n\r\n", 
          "Well, it's more like ksh is C++, bash is Objective-C and zsh is C#. They all share antecedents and thus have a lot in common but they are distinct languages. Imperfect analogies aside the core issue here is that we should not commit to a bug-for-bug compatible bash or zsh emulation mode. As I said earlier I have no objection to borrowing good ideas from other shells (or languages like Python) as long as the primary motivation is to improve ksh as opposed to making it able to run scripts written for those other shells.\r\n\r\nI have no objection to conditional compilation while a complex feature is being implemented. Although I think every effort should be made to implement a feature in self-contained commits that don't break existing behavior so that conditional compilation is not needed. And those `#if` statements should be removed at the earliest opportunity. We don't want different ksh dialects. If a feature is enabled on platform X it should be enabled on platform Y.\r\n\r\nObviously there may be exceptions to the above guideline. One that comes to mind is being able to build ksh as an alternative to busybox.", 
          "> Anyway, just removing unfinished experimental features adds nothing except an appearance of productivity...\r\n\r\nIt makes it easier to focus on non-experimental features. If a feature is still experimental 5+ years since the last stable release it should be jettisoned.\r\n\r\nHow many of the current test failures, or general test flakiness, is because of experimental features? I have no idea and I'll bet no one else does. But removing code we aren't committed to maintaining definitely makes it easier to understand and improve the remaining code and tests. Pruning dead wood is as important to software as it is to horticulture.", 
          "I like to say: ksh is ksh, bash is bash, ...\r\nAll those are children of Born Shell. We have also Posix specs. Dash is full posix and only posix, if I have understood correctly. Debian like to use only posix compatible properties in critical scripts. Not bad idea. I used long time only \"bourne shell\" syntax in ksh/bash ... It was safe when I done porting to many different *nix and customers. Never know which version of sh was possible to use.\r\nKsh have to include bourne shell + posix + ksh88 + ksh93 \"2012\" version.  Example all regexp and json extensions have been nice. Don't remove those :). That's the problem: all those who has used some extensions, don't know that those extensions are something new, even experimental and maybe not anymore in next version ... \r\n\r\nIf I sometimes like to use bash some special feature, then I use bash, not bash by ksh. I like more ideas that if some of those (ksh, bash, zsh,...) add some good idea (real usable extension) which is needed, not easy to done using current syntax, then it should be new builtin extension.  \r\n=> those which are included in ksh should be there, those which only works using bash, should be removed. It's too heavy, expensive, ... to try to be everything. No need.\r\n\r\nThank you and continue your excellent updating process even I don't like every moves, too old and lazy to learn new .... I really hope that younger find root of sh's. => building env use today/tomorrow envs.", 
          "Thank you for commenting @kshji and I hope you continue to comment. You reinforced my observation that if someone needs a bash feature they explicitly invoke that program to run their script. Why would someone expecting bash behavior for an obscure bash feature expect ksh to implement the same behavior?", 
          "For your enjoyment from the *src/cmd/ksh93/bltins/typeset.c* module:\r\n\r\n```c\r\n#if SHOPT_BSH\r\n                if (flag & NV_EXPORT) nv_offattr(np, NV_IMPORT);\r\n#endif /* SHOPT_BSH */\r\n```\r\n\r\nNotice the typo: `SHOPT_BSH` rather than `SHOPT_BASH`."
        ], 
        "number": "238", 
        "title": "Should we remove `SHOPT_BASH` and the code predicated on it?"
      }, 
      {
        "comments": [
          "I assume you're aware there are a large number of test failures on various platforms. Including the ones I have been using to verify changes such as macOS 10.13, FreeBSD 11.1, and Ubuntu 16.10. I have simply been verifying that a particular change does not increase the number of failures on those platforms. Without regard to whether the change simply replaced one failure with a different failure. My goal is to reformat the code and address compiler and lint tool warnings before spending more time on the failures seen on a specific platform. I did not want to expend energy investigating test failures before that cleanup was completed.", 
          "Yes, I am aware about the test failures. I want to get rid of all the ```iffe``` tests before diving into bugs.", 
          "> Yes, I am aware about the test failures. I want to get rid of all the iffe tests before diving into bugs.\r\n\r\nMy comment was rhetorical but I'm happy to see we are on the same page. Being focused on eliminating a lot of legacy baggage that is no longer relevant is a good thing IMHO. Primarily in the hope that doing so will make it easier to fix bugs and add new features. What I don't understand is the perspective of some commenters (e.g., \"jelmd\") that modernizing the code is unacceptable.", 
          "@krader1961 \r\n\r\n> What I don't understand is the perspective of some commenters (e.g., \"jelmd\") that \r\n> modernizing the code is unacceptable. \r\n\r\nI am only guessing here, but there may be people who have written built-ins which use \r\nsome (or more) functionality from either LIBSHELL or LIBAST (or even some other AST libs)\r\nwhich might get either broken or missing due to the clean-up efforts.\r\n\r\nIn a dream world, I think everyone would welcome cleaner and more maintainable code,\r\nbut perhaps people fear that some old (and maybe occur) function might get compromised.\r\n\r\nJust a guess here (I could be wrong).\r\n\r\n\r\n"
        ], 
        "number": "227", 
        "title": "bracket test fails due to update to Trusty images in Travis"
      }, 
      {
        "comments": [
          "Interestingly, it works correctly if the function is defined using the `function` keyword.", 
          "By the way, one more thing I'm seeing (ksh-20120801-31 version in Fedora 25):\r\n\r\n```ksh\r\n$ cat ./test.ksh \r\n#!/bin/ksh\r\n\r\nfunction func {\r\n  local stat=($(< /proc/self/stat))\r\n  echo $stat\r\n}\r\n\r\nfunc\r\n\r\nexit 0\r\n```\r\nResults in:\r\n`./test.ksh: syntax error at line 4: `(' unexpected`\r\n\r\nHowever, changing the script like this:\r\n```ksh\r\n#!/bin/ksh\r\n\r\nfunction func {\r\n  stat=($(< /proc/self/stat))\r\n  echo $stat\r\n  unset stat\r\n}\r\n\r\nfunc\r\n\r\nexit 0\r\n```\r\n\r\nWill work OK - for example:\r\n```\r\n$ ./test.ksh\r\n6785\r\n```\r\n\r\nThe syntax error occurs only when code causing it is inside a function, and the variable is set to be `local` for that function.", 
          "Hmm, I'm also seeing no output when running just:\r\n\r\n    echo $(</proc/self/stat)", 
          "Note that this issue seems to be predicated on the `SHOPT_BASH` symbol. Which is being discussed in issue #238 for removal. The state of the ksh source code at this time which  implements the `local` keyword is obviously incomplete and/or broken with  respect to this feature.  ", 
          "IIRC The AST group subscribed strongly to the idea of one interface, one name, one behaviour. When introducing new behaviour they would go out of their way to create a new interface with a new name.\r\n\r\nFrom what I remember when `typeset` was introduced, the `function` keyword was created precisely for supporting local variables.  The AST group did not want to \"contaminate\" old  `sh` style functions with different behaviour, so a new type of function was created.\r\n", 
          "@hlangeveld This is consistent with my understanding as well. `func()`-style functions behave as `sh`, `function func`-style functions support things like `local`."
        ], 
        "number": "220", 
        "title": "local keyword is not recognized in a function"
      }, 
      {
        "comments": [
          "@krader1961 I think I picked up the API versions from the ```nmake``` build, but it's possible I might have missed something there. IIRC I was having build failures at some point while using the latest versions of API functions.\r\n\r\n@dgkorn Can you give us a hint ?"
        ], 
        "number": "218", 
        "title": "What AST API version should we be using?"
      }, 
      {
        "comments": [
          "Yep, I noticed it too and most of these ```#if```'s should be removed.", 
          "To clarify my opening comment.... I don't see anyone ever compiling it without `-DSHOPT_MULTIBYTE` for example. Or `-DSHOPT_BASH` and `-DSHOPT_KIA`. The only one that vaguely looks like it might make sense to remain optional is `-DSHOPT_COSHELL`.\r\n\r\nI'll send an email to the ast-developers mailing list as well but if anyone lurking can explain why it should be possible to build ksh without these features that would be helpful. Alternatively, if you strongly believe these conditional features should always be included say so.", 
          "> To clarify my opening comment.... I don't see anyone ever compiling it without -DSHOPT_MULTIBYTE for\r\n>  example. Or -DSHOPT_BASH and -DSHOPT_KIA. The only one that vaguely looks like it might make \r\n> sense to remain optional is -DSHOPT_COSHEL\r\n\r\nI do not know about all of these flags in  detail (off-hand), but I have had to turn OFF more than\r\none of these in order to get the bugs out within the optional code (on some platforms).\r\nAmong the very first of these options often needing to be turned OFF is -DSHOPT_MULTIBYTE !\r\nJust my experience.  In fact, I wish that *more* of the whole of KSH was more optioned so that\r\nmore of the bugs can be optioned out.  For example, the \"sophisticated\" command line completion\r\nand command line multi-line display are very buggy (causing core dumps) on some platforms.\r\nI wish they could be optioned out!\r\n\r\nIn a few cases, I added compile-time options of my own in order to get rid of some code that was\r\ncausing bad bugs.  Just to be clear: \"bad\" bugs are often core dumps!\r\n", 
          "It would be best to have such bugs reported and fixed. Working around bugs by trimming down features is not the best option.", 
          "Thank you, @DavidMorano, for taking the time to comment. However, I agree with @siteshwar. If a feature is so broken that it causes people like you to want to build ksh without the feature then the feature has no business being included in a stable release. We should not be hiding broken features behind build time flags. With the possible exception of the bleeding edge development branch and even then the flag should not exist for more than a few months. Once a feature is ready to be included in a stable release it should no longer be guarded by a compile time `#define`.\r\n\r\nI definitely share your concerns, @DavidMorano, about the quality of a lot of the recently added code. That is, code added since version 93u+, released 2012-08-01, which seems to be the basis of the `ksh` binary included in every distro I use. But the answer is not to complicate the code with `#if SOME_SYMBOL` tests. The answer is to either fix those bugs or remove the feature.", 
          "@DavidMorano,\r\n\r\nYour comment suggests that you have actually looked at, and attempted to modify, the ksh source code. Is that correct? I ask because I am extremely unhappy about the current number of blocks of code conditioned on `#if SOME_SYMBOL... #endif` tests. It makes the code extremely hard to read, format, run through tools like `oclint`, and test. I've been programming in C, including OS kernel code (not just Linux), for three decades. I've never seen a project that makes such liberal use of conditional blocks of code outside of *.h* header files. So I'm perplexed by your comment where you seem to suggest there should be more instances of that anti-pattern.", 
          "> Your comment suggests that you have actually looked at, and attempted to modify, \r\n> the ksh source code. Is that correct?\r\n> ...\r\n\r\nI hear you and sympathize with where you are coming from.\r\n\r\nYes, that is correct. I confess. I apologize for causing some extra concern\r\nhere. I have at times gone through the KSH source (more than I ever wanted to)\r\nto compile-time disable code either by an existing feature switch or by inserted\r\ncompile-time switches of my own (sometimes possibly compiling in a little\r\nalternate code) in order to get around some problem. I confess that I usually do\r\nnot have the time to properly figure out exactly where the bugs lie. Instead my\r\n(admittedly) selfish goal was to get a working compiled KSH as fast as possible.\r\nI wish with all of my heart that someone paid me to clean up KSH (get all of the\r\nbugs out), but sadly that is not the case. To this day, I live every day with a\r\nKSH that crashes (core dumps) if I do something that irritates it in just the\r\nwrong way. But I live with this because I understand that both my resources and\r\nthose of the open-source community in general are quite limited. In fact, this\r\napplies to much of all the software I use everyday, open-source or commercial.\r\nThere are bugs in almost every piece of software I use now-a-days. Somehow --\r\nand I certainly wish this was *not* the case -- I (being especially cursed it\r\nseems) find bugs in much of the the software I use regularly. I think this is\r\njust the world we live in now.\r\n\r\nKSH is complicated enough -- at least for me -- such that attempting to properly\r\ntrack down some of its bugs would likely be quite time consuming. For example,\r\nthere is a very subtle I/O redirection related or associated bug that has been\r\nin there for about fifteen years now, but it is subtle enough to live with it\r\nrather than dedicating my life towards finding and correcting it. There are some\r\nsubtle esoteric SFIO bugs that I would like see cleaned up (again in there for\r\nover fifteen or more years) , but good luck with that. For me, the SFIO code is\r\nnot the easiest to always follow, and as I stated already, I do not have the\r\ntime to become the next SFIO guru for planet Earth. So I live with this stuff as\r\nit is. Again, sorry for being so selfish.\r\n\r\nMy suggestion was not to necessarily keep all of the compile-time switches in\r\nthe code base, but rather to retain an ability to disable features of the code\r\n(like multibyte, or command completion, or multi-line command display, or ...\r\nthe whole VMALLOC facility for that matter, and more) at run-time, when they\r\nturn up in a so-called \"stable\" release, but are either malfunctioning or\r\noutright broken to the point of core dumping on some platforms! There could be\r\nrun-time switches in the code that are set either by option key-words in one or\r\nmore environment variables or by additional options to the KSH 'set' command\r\n(for example). But something to switch out some of the supposedly fancy features\r\nthat do not automatically work properly on all platforms would still be\r\nwelcomed.\r\n\r\nFor myself, I have used KSH just about every day for the last 34 years (nearly\r\nfrom its very inception). I have written over 110 KSH builtin commands (many of\r\nthem being huge codes, using numerous dynamically loaded shared-object\r\nlibraries, and application loaded shared objects) not to mention functions and\r\nscripts. I have KSH built-ins that are multithreaded. I have background daemon\r\nthreads or server threads running along side KSH in its own background. So few\r\npeople want to see KSH stay around more than I do, but the most important thing\r\nfor widespread adoption is for an end user-developer-local-maintainer or\r\nwhatever, to get the code base and get it complied to a point where it is stable\r\nenough to use as quickly as possible. We should not expect everyone who\r\ndownloads the KSH source base to debug every bug they find before they are\r\nallowed to reasonably use it as a tool. Having something like some feature\r\nswitches (implemented in whatever way) might help with the local adoption\r\nprocess by possibly disabling code functions which a) are not strictly needed,\r\nand b) might be malfunctioning, or even c) might be a feature which the local\r\norganization finds either unwelcomed behavior or outright abhorrent.\r\n\r\nIs the KSH source base messy? YES. But just as important or even more so, there\r\nare numerous bugs, subtle and not so subtle, in the code base. But simply\r\nremoving the existing compile-time switches is not going to remove those bugs.\r\nShould the bugs be removed? Of course. How that should be best done I will leave\r\nto others. I wish I had the time to rewrite much of the KSH base from\r\nessentially the ground up (not the place here to elaborate on alternate code\r\narchitectures). But I do not see that happening any time soon.\r\n\r\nI was only pointing out that having features that can be disabled has proven\r\nuseful at times in getting rid of code that has malfunctioned on one or more\r\nplatforms.\r\n", 
          "FWIW, @DavidMorano, my intention is to remove dependencies on things like the AST vmalloc and SFIO subsystems once we've made the build process and unit tests more robust and less flakey. I have no interest in maintaining that code and, as you've noted, they are likely to be the source of bugs. Since the POSIX/Xopen standards provide the functionality needed by ksh and every platform we expect to run on provide support for those standards it doesn't make sense to maintain our own implementations of those APIs.", 
          "@krader1961 \r\n> my intention is to remove dependencies on things like the AST vmalloc and SFIO \r\n> ...\r\n\r\nI would welcome VMALOC being removed, \r\nand all of the other AST specific things that were originally designed to stub out\r\nfor missing POSIX/Xopen  interfaces. I found that I had to remove VMALLOC\r\nbecause even though VMALLOC had a compile-time option to make it \r\nthread-safe, for some reason it was not thread-enough-safe even in so-called\r\n\"thread-safe\" compile mode (had races and core dumps).  Also, for me, I would \r\nwelcome the removal of SFIO!  Yes, I said that correctly.  I actually find SFIO quite \r\ndeficient for my needs and I do not want to take the plunge to go into the code\r\nto learn enough about it to make it more suitable for my needs (mostly related to\r\nasynchronous operations).\r\n\r\nCurrently, KSH mandates the use of SFIO for its I/O interface with any\r\ncoded built-ins.  This has been a huge problem for me in the past, and\r\ncontinuing, because of either bugs or deficiencies within SFIO.\r\nSo I would welcome the removal of SFIO just so the standard I/O within \r\nbuilt-ins can be released from their present bondage.\r\n\r\nBuilt-ins that people may have which wish to continue using SFIO\r\ncould continue to do so, but the way those streams would get initialized would\r\nwork differently.  Currently SFIO streams for STDIN, STDOUT, and STDERR\r\nare inherited from KSH itself rather than  being initialized from the\r\ncorresponding FDs (STDIN, STDOUT, and STDERR).  Korn did this\r\nso that purely memory based streams could be passed into and out\r\nof built-ins without actually using any FDs. But with the removal of\r\nSFIO from KSH, built-ins which continued to use SFIO, would have to\r\nhave their standard streams (IN, OUT, and ERR) initialized from the\r\ncorresponding FDs (IN, OUT, and ERR) just like STDIO (and others)\r\ndo when running in the context of a newly spawned process.\r\n\r\nSo I do not see any real problem with the removal of SFIO, but I do\r\nsee up-sides to its removal (bugs gone and being released from its constrained\r\ninterface and semantics).\r\n\r\nIn short, I would welcome all of these sorts of changes.\r\nI only now wish that this stuff was removed at least 20 years ago,\r\nsince it would have saved me innumerable head and heart aches working \r\naround them as I had to do (too numerous to elaborate on in this space).\r\n\r\nThank you very much for your plan.  I assume that you have the time do all\r\nof this. so thanks for that also!\r\n", 
          "Note that disabling features can cause compilation failures. For example, compiling with `-DSHOPT_MULTIBYTE=0` results in this error:\r\n\r\n```\r\n../src/cmd/ksh93/sh/string.c:348:23: error: \u2018lc_unicodeliterals\u2019 undeclared (first use in\r\n  if(isaletter(c) && (!lc_unicodeliterals || c<=0x7f))\r\n                       ^\r\n```", 
          "While restyling the code I am amazed at how many `#if SOME_SYMBOL` directives (or equivalent) I am seeing. For example, `SHOPT_SYSRC`, `ATTRS` and `STR_MAXIMAL`. Just to pick three at random. I recognize that conditionally compiled code is necessary to support really old, as well as new, systems. But the manner in which this has been done is suboptimal and needlessly confusing. And it appears the majority of these tests are for things that should not be conditionally compiled and are unrelated to features available on a specific system. Which is the nicest way I can say what I really think. Ask me out for a beer for a more blunt appraisal of the state of the code."
        ], 
        "number": "210", 
        "title": "Should we remove a bunch of compile time `-D` flags?"
      }, 
      {
        "comments": [], 
        "number": "203", 
        "title": "Reading file through command substitution fails"
      }, 
      {
        "comments": [
          "Steps to reproduce:\r\nrlogin localhost\r\nType \u3042\u3044\u3046\u3048\u304a from keyboard\r\nActual results:\r\n^A^A\u3044\u3046\u3048\u304a is displayed.\r\nExpected results:\r\n\u3042\u3044\u3046\u3048\u304a should be displayed.\r\nIs this the same bug?\r\n\r\n$ uname -s -v\r\nSunOS 11.3\r\n$\r\n", 
          "@k-takahagi Do you have ```KEYBD``` trap set ? It should not reproduce when ```KEYBD``` trap is not set."
        ], 
        "number": "197", 
        "title": "Multibyte characters get corrupted when KEYBD trap is set"
      }, 
      {
        "comments": [
          "From (among others) the *https://www.gnu.org/software/libc/manual/html_node/Locale-Names.html* page:\r\n\r\n> Portability Note: With the notable exception of the standard locale names \u2018C\u2019 and \u2018POSIX\u2019, locale names are system-specific.\r\n\r\nI am not aware of any non-AST implementation that provides support for \"territory\" extensions to the C or POSIX codeset. Given that Unicode encodings provide support for code points like the Euro currency symbol there should not be a need for the `C_EU.UTF-8` locale name. The `C` (or `POSIX`) locale implicitly does not support things like the `EU` territory for number formatting. The need for such support is why the misguided ISO-8859-x standards exist and were ultimately replaced by the Unicode standard.\r\n\r\nAnyone wanting support for EU formatting of numbers can do so by setting the `LC_NUMBER` env var while leaving `LANG` set to `C`.\r\n\r\nThe bottom line is that ksh should use the same distro provided library code that almost every other program uses for localization. If only ksh93 recognizes `LANG=C_EU.UTF-8` what use is it? ", 
          "How are ```decimal_point``` and ```thousands_sep``` used in ksh?", 
          "It's used with builtins for e.g. \r\n\r\n```\r\n$ echo $LANG\r\nen_US.UTF-8\r\n$ printf \"%'d\\n\" 1000\r\n1,000\r\n$ export LANG=C_EU.UTF-8\r\n$ printf \"%'d\\n\" 1000   \r\n1.000\r\n```", 
          "Yes, but since it isn't a standard locale no other program will honor it. For example, if you do this on Ubuntu you get no thousands separator:\r\n\r\n```\r\n$ env LANG=C_EU.UTF-8 /usr/bin/printf \"%'d\\n\" 1000\r\n1000\r\n$ echo $LANG\r\nen_US.UTF-8\r\n$ /usr/bin/printf \"%'d\\n\" 1000\r\n1,000\r\n```\r\n\r\nThe `C_EU.UTF-8` locale is only meaningful inside ksh which is borderline useless and going to be the source of many bug reports due to the confusion it causes.", 
          "Basically, this \"feature\" is nonstandard, only usable within ksh (or other programs built against the AST libraries), and guaranteed to be a source of confusion and bug reports. It should be removed. Even better would be to remove the ksh93 dependency on the AST locale support code and use what is provided by the OS. Which is what we're slowly doing with other things like the string manipulation functions.", 
          "Agreed.  If the locale is understood only by ksh built-ins, it is not very useful.", 
          "I propose we remove the ksh dependency on the libast locale code ASAP unless someone provides a convincing argument for retaining the dependency. Like the SFIO subsystem and other parts of the AST code base it would have been great if it had been adopted by a the broader UNIX community. But that didn't happen. It would be better if ksh used the standard locale support provided by any (semi-)compatible POSIX environment. We should only be using fallback implementations to work around shortcomings of the target platform. Which for something like locale support should be done by mapping the POSIX functions to native functions rather than using an independent implementation.", 
          "I agree that using local (re)implementation of the system libraries is a bad approach.  The only thing I am afraid of is that switching the implementation of such a core functionality must have observable side effects and there is no reliable way to check in advance what is going to break in all the ksh scripts that people have been using for the last few decades.", 
          "> ...switching the implementation of such a core functionality must have observable side effects...\r\n\r\nYes, but at this point we're looking at the next published, stable, version being what amounts to a major release. Even if we don't implement any new features. Precisely because changes like this one have a very small, but non zero, chance of breaking existing uses.\r\n\r\nAs a practical matter I will be surprised if there is anyone using the `C_EU.UTF-8` locale since, as said above, only AST code recognizes it. Still, it's something we'll want to clearly document. In fact, I'm going to start a `CHANGELOG.md` file since we should be keeping track of changes that could be noticed by a user some place of than the git commit history.", 
          "Hmmm, I suggest to study the code and tests a little bit deeper and if they were still not understood, just use online docs like ML archives, etc. to find out, why this feature exists, the intention behind it - google makes this really easy ;-) .\r\n\r\nA serious developer would have find out in < 5 min, that C_EU.UTF-8 and C.UTF-8 are \"just\" test locales, introduced with the intention to write regression tests with deterministic results across all \r\nplatforms. But since the current target of development seems to be RH linux, only, who cares ...\r\n"
        ], 
        "number": "177", 
        "title": "Support for C_EU.UTF-8 locale in ksh93"
      }, 
      {
        "comments": [], 
        "number": "175", 
        "title": "Exit status when there is a segfault"
      }, 
      {
        "comments": [
          "It would a good idea for `PWD` to also contain a space but that may be more trouble than it's worth."
        ], 
        "number": "166", 
        "title": "Ensure the `PATH` env var contains a directory with a space in its name for every test"
      }, 
      {
        "comments": [
          "This makes me so sad as I love ksh. On the other hand, only ~250 bugs? Heck we should be able to fix that many bugs in a few days. :smile:\r\n\r\nOn a more serious note this is why I want to make it trivial and routine to run the code through tools like `clang-format`, `oclint`, `cppcheck`, and `scan-build`. There should be zero warnings from the compiler or any of those tools. Let alone obvious errors being identified.", 
          "My PR#368 enables clang static analysis (what `ninja scan-build` does) as part of running `oclint`. As well as running the code through `cppcheck`. Just the *src/cmd/ksh93* code produces a report that is over 7000 lines long."
        ], 
        "number": "161", 
        "title": "Investigate issues identified by the `bin/lint` command"
      }, 
      {
        "comments": [], 
        "number": "152", 
        "title": "signal test hangs sometimes"
      }, 
      {
        "comments": [], 
        "number": "150", 
        "title": "Signal test fails with a SIGSEGV on Ubuntu"
      }, 
      {
        "comments": [
          "Some food for thought....\r\n\r\nWhen the [fish-shell](https://github.com/fish-shell/fish-shell) project considers adding a new builtin they carefully consider whether the builtin name might conflict with a widely used external command.\r\n\r\nFish also realized that not every platform provides a `realpath` command. But rather than make it a builtin that always overrides an external `realpath` command they used the function autoload mechanism to dynamically check for a) a `grealpath` command (in case someone had installed the GNU version under that name), b) a `realpath` command, and only if those aren't found  c) fallback to the builtin. This minimizes the chance of surprising the user by ensuring they get the full featured implementation provided by their OS if one is available. If not fallback to the builtin so that fish scripts can assume they can at least do `realpath /a/symlinked/path`.\r\n\r\nMost of those commands aren't too hard to justify as being optionally available as a builtin in terms of portability and/or performance. But `sync` is a really odd command to have as a builtin. When was the last time anyone used that command? Regardless it can't be justified as a builtin on the grounds or portability or performance. So why is it included?", 
          "> Most of those commands aren't too hard to justify as being optionally\n> available as a builtin in terms of portability and/or performance. But sync\n> is a really odd command to have as a builtin. When was the last time anyone\n> used that command? Regardless it can't be justified as a builtin on the\n> grounds or portability or performance. So why is it included?\n\nOne possibility is if ksh is being used as a root shell in single user\nmode, having sync built in could be useful if no other commands are\navailable, to allow root to get the filesystem saved for consistency\nbefore powering off the machine.\n", 
          "@dannyweldon, If no other commands are available I have a hard time believing a sync builtin is needed. If the root filesystem (which should have a `sync` command) isn't available the system is so screwed up the inability to run that command is the least of the admin's worries. Sorry, but I don't buy that argument. Nice try, but I'm unconvinced we should be maintaining that code and bloating the ksh size, even if just by a few hundred bytes, for something that 99.9999% of ksh users will never need.", 
          "I am a professional Unix/Linux administrator and kept running into\nthis situation recently repeatedly when the glusterfs filesystem\ndriver was having issues causing all file I/O on a Linux system to\nfreeze.  Running any local commands would hang, however I could kill\nthem with Ctrl-C.  But I could still run \"commands\" that were built\ninto the shell, of which in bash was only \"echo\"; not very useful, but\ncan be a crude form of ls.  I have worked a long time ago previously\nwhen we did all root system administration on various Unix flavours\nusing the Korn shell.  It would have been nice to have had builtin\ncommands available so that I could actually do something useful, which\nis why I think the sync command has been added as a builtin, and I\nbelieve I am correct.  Whether anyone will really use it very often\nnowadays is another matter.\n", 
          "@dannyweldon, I am still unconvinced the `sync` builtin is worth maintaining as a core feature. There is a nearly infinite number of commands we could include as builtins using the criteria from your comment. But that does not justify the cost of making them builtins for everyone. I have no objection to making it easy for third-parties to extend ksh with such commands where they have specialized requirements such as you describe. Quite the contrary. Making it easy to adapt ksh to such needs is more likely to keep it relevant. I just don't see why the core ksh project should pay the cost of maintaining that code.\r\n\r\nAlso, if \"Running any local commands would hang\" it is likely that running `sync`, even as a builtin, will also \"hang\". How likely is it that even if it forces a sync of the filesystem(s) you care about before it blocks syncing the filesystem(s) that are causing problems you would even notice? You also wrote, perhaps imprecisely, that `the glusterfs filesystem driver  was having issues causing all file I/O on a Linux system to freeze`. If it was causing all I/O to stall what use is `sync` even as a builtin?\r\n\r\nThat you could not run external commands is usually an indication that one or more filesystems in $PATH is unresponsive. In my experience as a sysadmin, and UNIX support tech, not being able to run the `sync` command in that situation was never a concern. Even before journaled filesystems were the norm. So I remain unconvinced that the core ksh code should retain `sync` as a builtin. But should make it easy for people like you to build a version that includes it as a builtin if they deem the command useful enough to justify the overhead.", 
          "Followup to my previous comments...\r\n\r\nKeep in mind the kernel typically performs periodic syncs on the order of every 30 to 60 seconds. So even if the `sync` command isn't available all you have to do is stop doing anything and wait a minute before rebooting the system. The primary purpose of the `sync(2)` API is to hasten a graceful shutdown. If you're dealing with an abnormal situation, such as where some filesystem I/O is blocked, it is not unreasonable to just \"count to 10\" before forcing the system to halt (e.g., by pressing the \"big red button\").", 
          "I also like to keep them, because they also provide some add. feature, which might be usable in certain situations, make life easier (e.g. see `getconf --man` etc.).  ksh scripts may rely on them - most distro provided commands do not have all the options, which the ast cmds provide - so removing them may break a lot of ksh scripts. Last but not least I can understand @dannyweldon : around 2000 +-5  we used static ksh with all its builtins enabled as our busybox - advantage was, that commands worked as expected and even having a man page for these cmds w/o having access to all the groff/troff stuff. Not used anymore, because we PXE boot, ... now - however, with such builtins incl. dyn. cmd load  ksh has the potential to be used as a much better busybox as well ... So please do not close this door!", 
          "I have no objection to making it easy for ksh to be a viable alternative to [busybox](https://busybox.net/about.html). Busybox is the basis of the CLI for the [Asuswrt-Merlin firmware project](https://asuswrt.lostrealm.ca/) that I use on my WiFi router. Not to mention a lot of other hardware that uses Linux and Busybox. I'd be thrilled if ksh were used instead. But that does not justify encumbering the general purpose ksh code with features that 99.9999% of users won't use.\r\n\r\nWe should make it easy to build a statically linked `ksh` binary that includes a lot of builtin commands (e.g., `sync` and `cat`) that can't be justified as builtins in any other situation. And those builtins should be enabled by default. But I see no reason why those commands should be available as builtins of a ksh command used in typical situations. And even if made available in those typical situations they should not automatically supplant the external commands of the same name.", 
          "Note that I had to revert commit 734c1108 because the \"heredoc\" unit test expected behavior of the builtin `cat` command that is apparently not provided by the external command. But it's not obvious from the failure message that the difference in behavior has anything at all to do with the options supported by `cat`. This seems to be a good example for why including such builtins by default is a bad idea. A unit test that uses the `cat` command should not be affected by whether it is a builtin or an external command unless the test is explicitly testing the behavior of the builtin. Which the `heredoc` test is not doing AFAICT.", 
          "having builtins of system commands is one of the ways ksh93 made it possible to write system independent scripts that also ran much faster than with other shells. Glenn and Dave tried to keep these commands as close to posix as possible. when a builtin was discovered to violate the standard, they just fixed the builtin. builtins were always optional, but they are a documented feature of ksh93 so I think they have to stay.", 
          "I agree with @jelmd and @lkoutsofios: The builtin's provided by `ksh93` are a boon to portable scripting (portable between systems, not shells), and the embedded documentation (via `--man`) is consistently helpful. It would be a shame to lose either of these things.", 
          "With regards to the sync builtin, a very common problem scenario is when a server runs very low on memory such that it cannot fork processes any more.  That's when it becomes very important to have shell builtins, the most notable being the kill builtin, which is even in bash.  The reason being that without it, it would be impossible to kill any errant processes.\r\n\r\nSo the sync builtin has obviously been added for completeness in such situations where it can be used as a last ditch effort to minimise loss of data before power cycling.  While filesystem journaling will keep your filesystem from being corrupted, it will not prevent the data loss in files from buffers not being flushed.\r\n\r\nNow of course, you would have to have had a root ksh shell open before the problem became too serious, but it could also be used by a system ksh script that runs continuously and runs the sync builtin at some predetermined pattern, or perhaps after certain file operations and would be guaranteed not to fail in low memory situations.\r\n\r\nAlso, the builtins of standard utilities are documented here:\r\n\r\n(Note: debian/ubuntu users need to install the mm and ms macros using: apt install groff)\r\n\r\n    nroff -mm PROMO.mm | less -R\r\n\r\n          \u00b7 Improved  performance:  KSH\u201093  executes  many  scripts\r\n            faster  than  the System V Bourne shell. A major reason\r\n            for this is that many of  the  standard  utilities  are\r\n            built\u2010in.   To  reduce  the time to initiate a command,\r\n            KSH\u201093 allows commands to be added as built\u2010ins at  run\r\n            time  on  systems  that support dynamic loading such as\r\n            System V Release 4.\r\n", 
          "BTW, There are a bunch of commands in *src/cmd/builtins* which are both ksh builtins and external commands with apparently one exception: `pty`. From a ksh built using the legacy build system from the beta branch:\r\n\r\n```\r\n$ type head\r\nhead is a shell builtin version of /usr/bin/head\r\n$ type pty\r\ndarwin.i386-64/src/cmd/ksh93/ksh: whence: pty: not found\r\n$ builtin pty\r\nbuiltin: pty: not found\r\n$ type rev\r\nrev is a shell builtin version of /usr/bin/rev\r\n$ type tee\r\ntee is a shell builtin version of /usr/bin/tee\r\n$ type grep\r\ngrep is a tracked alias for /usr/local/bin/grep\r\n```\r\n\r\nI don't understand why `pty` isn't available as a builtin along with related commands like `grep` and `tee`. We definitely do not want to be providing external programs (e.g., `grep`) as part of this project which might shadow the distro provided version of the program. That the `pty` command is not implemented as a builtin means it has to be provided as an external command. Which I don't understand."
        ], 
        "number": "129", 
        "title": "Should ksh provide builtins for external commands like `cat` or `mkdir`?"
      }, 
      {
        "comments": [
          "This would be a show stopper for downstream consumers, especially for enterprise level distros as I already commented on https://github.com/att/ast/issues/82#issuecomment-345632314.  Please do not change the code beyond what is really necessary to fix existing bugs.", 
          "Plus, it feels like sacrilege.  :smile:  I find the code a thing of beauty, such as things like [this](https://github.com/att/ast/blob/3f54fd611f536639ec30dd53c48e5ec1897cc7d9/src/cmd/ksh93/bltins/cflow.c#L52-L54).\r\n\r\n", 
          "I would like to investigate if code can be made more consistent in a way that is easier to backport. Otherwise given the current state of ksh93, the number of patches that are backported to distros are rather less. It would be good to have an opinion from package maintainers from other distros/operating systems about it.", 
          "When I feel it absolutely necessary to reformat code, what I do is I put all the changes into a single commit where the diff of the \"objdump -d ...\" output of the before and after binaries are identical (sans the header line).  I explain this approach in the commit log as well.  This greatly simplifies people's testing since if the two \"objdump -d ...\" compare, no further testing is necessary for regardless of how complex and invasive the patch is.\r\n\r\nIf there are reformatting changes that do change the binary output in any way, make them in (hopefully) very small commits that can easily be inspected separately.", 
          "@kdudka, The problem is that the current state of the code makes it hard to read. Which leads to mistakes (bugs). Furthermore, we absolutely need to address the huge number of compiler warnings and the hundreds of warnings I expect `oclint` and `cppcheck` to warn about. Also, I was being hyperbolic when I said that \"it will be impossible to\" backport fixes after reformatting the code. It does, however, mean that most of the time you won't simply be able to do `git cherry-pick`. Someone will have to manually apply the fix. Much like I did with several of the Solaris patches.\r\n\r\n@melbit-dannyw, That example you linked to is definitely a \"thing of beauty\" if the criteria is to win the Obfuscated C contest :smile: It's definitely a poster child for why I want to reformat the code.\r\n\r\n@qbarnes, Comparing the output of `objdump` is an interesting idea. But I would not be surprised if  totally innocuous changes resulted in differences simply due to triggering different behavior from the optimization phase of the build process.", 
          "@krader1961, I've used the objdump (or an equivalent) approach hundreds of times over the past 30 years to clean up and/or reformat C code into something much more readable and consistent.  Very rarely are what seems innocuous changes show up as diffs, as long as the optimizer is on.  I've found that the optimizer is pretty good at returning the generated instruction sequences to what they were.\r\n\r\nIf there is an innocuous change (or a not so innocuous change) that changes the generated code, either change the approach for that piece of code so it's clean or don't make it part of the clean mega-commit.  Break those small pieces out into their own commits that can be tested separately.\r\n\r\nOften I can rewrite a chunk of code very close to the way I want it so it can be in the mega-commit.  That way the final tweaks to that code that break the instruction compatibility is as small as possible.", 
          "> ...as long as the optimizer is on...\r\n\r\nThat might be true for `-O2`. My concern is that other levels, such as `-Os`, can result in different assembly code even if the modified source if logically identically to the original source. It's been more than ten years since I've used the technique you proposed so perhaps my concern is no longer well founded but it was definitely an issue when I was doing things like kernel crash dump analysis in my previous job. When I run the code through `clang-format` (or otherwise try to normalize the style) I'll try the `objdump -d` approach to see if it reports unexpected differences. If it reports no differences that will be a pleasant surprise but I'm not going to bet a paycheck on it. :smile:", 
          "@krader1961 I think I wasn't clear.  When doing the objdump -d test, you have to have the exact same compiler, compiler version, and compiler flags for both binaries to prove a commit didn't result in an  instruction sequence change.  That's very easy to do if you build the code, save the binary, immediately rebuild the code with the patch, and then compare binaries.\r\n\r\nMy optimizer comment was that reformatting code and running with the optimizer off is more likely to result in inadvertent instruction code differences than doing the comparison with the optimizer on.", 
          "The neomutt project recently had this exact same [discussion](https://github.com/neomutt/neomutt/issues/224). It's rather long so you might want to just jump to this [comment](https://github.com/neomutt/neomutt/issues/224#issuecomment-277490030) and read what follows. The take away is that everyone commenting in that thread agrees that using `clang-format` to create a consistent style is a really good idea. And there is broad agreement on the style rules.\r\n\r\nThere are two aspects of the style they settled on where I think we should make a different decision. First is line length. They decided to stick with 80 chars. The fish-shell team debated this extensively and compromised on 100 chars. That is still short enough that even on a typical laptop screen you can comfortably display side by side diffs. Yet the extra 20 chars can dramatically reduce the number of statements that need to be wrapped. The second aspect is to use the \"Allman\" brace style. That is,\r\n\r\n```\r\nint my_func()\r\n{\r\n    if (cond_a)\r\n    {\r\n        do_something();\r\n    }\r\n    else\r\n    {\r\n        do_something_else();\r\n    }\r\n}\r\n```\r\n\r\nAlmost no one liked that style because it greatly decreases information density and makes poor use of the vertical display space. They chose it to make it easier to merge changes with the upstream mutt project since that is the brace style of that project.  I'd rather we use the \"Attach\" brace style used by the Google style guide:\r\n\r\n```\r\nint my_func() {\r\n    if (cond_a) {\r\n        do_something();\r\n    } else {\r\n        do_something_else();\r\n    }\r\n}\r\n```", 
          "Definitely agree with the Attach brace style over Allman, especially after an incident a few years ago.\r\n\r\nA problem with the \"Allman\" style was someone had written code like:\r\n```\r\nint myfunc()\r\n{\r\n        ...\r\n        foo1();\r\n        foo2();\r\n        if (myvar222 == myvar444 && *myptr111 == *myptr222 && myvar111 == myfunc333());\r\n        {\r\n                do_something();\r\n        }\r\n        ...\r\n```\r\n\r\nThat single character typo was even harder to see because it was in column 80, let alone having a C brain parser \"know\" that \";\"s go on the end of a line right after a \")\".\r\n\r\nWe had 16 people looking over the misbehaving code for days.  We knew it was a bug probably in the one function, but didn't know exactly where it was.  No one saw the typo for the longest time.  I finally compiled the module with \"-S\" and looked over the instructions in the bad function.  I saw the entire if statement had been optimized away and it was always executing do_something().  I stared at the one if statement for like 15 minutes until it finally leapt out at me.\r\n\r\nThe above example was only one of two if-statements with compound expressions written in Allman style in the entire file.\r\n\r\nBefore this bug, I used to me meh on people wanting to use Allman thinking it was just wasting a lot screen space for nothing.  Now I'm against it.\r\n", 
          "@qbarnes I presume a static analyzer would have caught this issue.\r\n", 
          "> That single character typo was even harder to see because it was in column 80\r\n\r\nTangent... I can relate. When I was really young I wrote a lot of code in FORTRAN and COBOL when 80 column punched cards were still in widespread use. It was not unusual to have a statement run into the \"sequence number\" field ([columns 73-80](https://en.wikipedia.org/wiki/Computer_programming_in_the_punched_card_era)) which would alter the meaning and was really hard to spot if it didn't result in a syntax error.", 
          "@siteshwar If you have a static analyzer suggestion, I'm willing to give it a try to see if it would catch it today.  I still have access to the original code when the problem came up around 7 years ago.  Note though that it's Linux kernel code and a various C static checking tools I used back then to use would barf on kernel code.  Hopefully. newer tools wouldn't have the same limitation.\r\n\r\n@krader1961 Yep, I still have some punch card decks in PL/C (variant of PL/1) from my Intro to CS class in college (and even still some 8\" floppies from another CS class).  I'm all too familiar with that pesky column > 72 problem with dropping those characters.  :-/", 
          "@qbarnes I can suggest you to try https://en.wikipedia.org/wiki/Coverity", 
          "On Wednesday, November 22, 2017 2:28:41 AM CET Quentin Barnes wrote:\n> @siteshwar If you have a static analyzer suggestion, I'm willing to give it\n> a try to see if it would catch it today.\n\nBare gcc-6.4.0 can warn you about it:\n\n% cat xxx.c\nextern void do_something(void);\n\nvoid myfunc(int a)\n{\n    if (a == 42);\n    {\n        do_something();\n    }\n}\n\n% gcc -Wall -c xxx.c \nxxx.c: In function 'myfunc':\nxxx.c:5:5: warning: this 'if' clause does not guard... [-Wmisleading-indentation]\n     if (a == 42);\n     ^~\nxxx.c:6:5: note: ...this statement, but the latter is misleadingly indented as if it is guarded by the 'if'\n     {\n     ^\n", 
          "On Monday, November 20, 2017 11:40:34 PM CET Kurtis Rader wrote:\n> @kdudka, The problem is that the current state of the code makes it hard to\n> read. Which leads to mistakes (bugs). Furthermore, we absolutely need to\n> address the huge number of compiler warnings and the hundreds of warnings I\n> expect `oclint` and `cppcheck` to warn about.\n\nI fully support this idea.  Just keep in mind that it is not so difficult to \nintroduce new bugs while trying to fix the existing ones.  It happens quite \nfrequently that someone fixes a memory leak that nobody knew about and, at\nthe same time, introduces a double free that causes occasional crashes, etc.\n\nI would discourage you from blindly fixing static analyzer's reports in\ncode that nobody knows how it works, which in ksh is quite a common case, \nunfortunately.\n", 
          "> I would discourage you from blindly fixing static analyzer's reports in code that nobody knows how it works, which in ksh is quite a common case, unfortunately.\r\n\r\nWe're in agreement. I've done this before and am intimately familiar with the dangers of fixing lint warnings. Which is why I hope we can all get behind improving the robustness and coverage of the unit tests.\r\n\r\nI always start by taking care of the trivial warnings which, short of introducing a typo not caught by the compiler, can't possibly break anything. These usually involve questionable style that makes it more likely someone will misunderstand what the code is doing. Only then turning attention to warnings about substantive issues like possible use of uninitialized variables, use after free, and the like.\r\n", 
          "So @siteshwar asked \"Can we keep tabs for indentation?\". We could but they tend to cause problems. One reason people ask for tabs is that it allows each person to individually determine the level of indentation by configuring whether tabs are modulo 2, 4, or 8 columns. The problem then becomes how do you enforce a consistent limit on line length?\r\n\r\nUsing tabs inevitably means mixing tabs and spaces so that alignment of continuation lines produces the desired result. For example (obviously contrived),\r\n\r\n```\r\nint my_func(int x, char *my_really_really_really_really_really_long_var_name,\r\n            float y) {\r\n```\r\n\r\nIf that second line begins with one tab followed by spaces then the alignment will be wrong unless everyone else uses the same tab width that you do. It also inevitably leads to situations where there is a single (or small number) of leading spaces followed by a tab. Which again won't render correctly for everyone.\r\n\r\nOnce you allow tabs people will insert them in the middle of a line rather than only at the start of a line. That's even more problematic and, again, requires everyone to agree on the width of a tab.\r\n\r\nThere are exceptions (e.g., Linux kernel code) but most projects I've touched in the past decade disallow tab characters. The [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html#Spaces_vs._Tabs) disallows them. And while I'm not a fan of two space indents even that isn't as bad as using tab characters.\r\n\r\nIn the distant past I used tabs for indentation of my code. For the reasons above as well as others I long ago switched to spaces only. The tab key is helpful on a typewriter but note that even there it's just a shortcut (e.g., a macro) for quickly inserting a bunch of spaces. You can't actually insert a \"tab\" character on a typewriter.\r\n\r\nFriends don't let friends insert tab chars in their code :smile:\r\n", 
          "I somewhat agree to @kdudka's concerns that it would be harder to backport patches after changing coding style. But on the other hand it may be a good idea to just bite the bullet and improve it.", 
          "Also, note that the projects which do allow tab chars, such as the Linux kernel, are likely to mandate that tabs are modulo 8 as originally defined long, long, ago when things like the [Teletype Model 33](https://en.wikipedia.org/wiki/Teletype_Model_33) peripheral were common. That is what I used for my first High School programming course way back in 1975.", 
          "We absolutely need to \"just bite the bullet and improve it\" if we have any hope of keeping ksh relevant. Speaking for myself I won't bother to improve the code given its current condition which makes it far too hard to read and correctly understand what it does. \r\n\r\nSimply avoiding refactoring the code for a couple of years will make the cost of backporting fixes acceptable. Even if the code has been restyled. Obviously there are a thousand variables here. Simply removing support for pre-ANSI C compilers will make backporting fixes more difficult. Any change we make that is not the most minimal change possible to fix an issue makes it more difficult for distros to backport a fix. I am sympathetic since I worked for Sequent Computer Systems and then IBM where that consideration was important. But I am not so sympathetic that I'm willing to see `ksh` transition from being in a coma to death. I'd rather make the newly open sourced `ksh` so awesome that distros decide to adopt it and stop trying to fix bugs in code that is more than a decade old.", 
          "Hmmm, FWIW wrt. tabs vs. spaces: I always use tabs, only. Problem wrt. mixing tabs with spaces gone ...\r\ntab-width: 4 spaces, yepp.", 
          "https://insights.stackoverflow.com/survey/2017#work-tabs-or-spaces\n\nAccording to this, tabs are preferred.  Of course python, cobol and\nfortran programmers will prefer spaces, skewing the results even\nfurther.  :)\n\nI find the code fairly easy to read because if loosely follows the\nAllman style.  I would however prefer some spaces around operators and\nafter commas, and when the tab size is set to 8 spaces, the bigger\nindentation makes the blocks easier for the eye to discern, which is\nwhy I have always preferred it.\n\nWhen I pointed out this code, I thought it was quite novel as I had\nnever seen this done before, but it is certainly very easy to read:\n\n    while((n = optget(argv,options))) switch(n)\n    {\n\nIt is a concern that reformatting it all will make backporting patches\nfor Redhat and others more difficult.  Plus, won't the changes that\nhave been made so far be invisible as well?\n\nI don't think that reformatting the code is the key to the project's\nlife.  The only reason it was dormant is that everyone was just\nwaiting for something to happen till finally we realised that we just\nhad to jump in and start contributing.\n\nI am not that fond of reformatting the code but don't want to stand in\nthe way of further progress.\n\nFWIW, I personally find the Attach style harder to read, but I agree\nthat it is more compact.\n\nWhat about having at least an Allman-style indent around function\ndefinitions?  Just a thought.\n\n    int my_func()\n    {\n       if (cond_a) {\n           do_something();\n       } else {\n           do_something_else();\n       }\n    }\n", 
          "Note that the existing code assumes tab stops are every 8 columns. If you change it to 4 then all the places that attempt to vertically align var names and initializers by using tabs between tokens no longer achieve that alignment. As I said earlier you can't allow tabs unless you either mandate a specific width (like the Linux kernel code does) or you impose severe restrictions on where they can be used. If the former then why use them since it invalidates the most common reason for using tabs (i.e., letting individuals control how wide each indent level is). The latter restriction means that you can only use tabs to indent a new block and all tab chars must appear at the start of a line. Continuation lines must have the same number of leading tabs as the previous line -- you can't use tabs to achieve alignment. And it is a certainty that restriction will be violated.\r\n\r\n> What about having at least an Allman-style indent around function definitions?\r\n\r\nI think `clang-format` can be configured to support that mixed style. I'm mildly opposed because a function block differs from a \"while\", \"for\" or \"if\" block in only one way --- it can be called like subroutine. I don't think that single difference warrants putting the opening brace in a different place than any other block.", 
          "\u200bSorry, I should have pointed out that even though I prefer tabs, if the code is completely reformatted, then I would agree then that spaces probably should be the indentation, but not sure if should be 4 or 8.  Having said that, if the tabs were kept in the reformat, the diffs might be much smaller, making it easier to reconcile the changes.\r\n\r\nCurrently for me the code aligns nicely in vim, of course using the default tabstop=8.\r\n\r\nFYI, for a test, I enabled the EditorConfig plugin in Visual Studio Code and created this .editorconfig file, and the alignment looks the same as vim:\r\n\r\n    [*.{c,h}]\r\n    indent_style = tab\r\n    tab_width = 8", 
          "No need to apologize, @dannyweldon. My previous comment was primarily directed to the other commenter I've decided to stop engaging directly. Because they said it's not a problem if you set the tab width to 4.  Having said that I think you'll find that if you look at blocks of code like [this one](https://github.com/att/ast/blob/master/src/cmd/ksh93/sh/main.c#L123-L127) and change the tab stop value to 4 (by typing `:set tabstop 4`) things no longer line up. Which is just one example for why I am adamantly against allowing tab chars.", 
          "And for the record, we can clearly see some ```misleading-indentation``` warnings in the code. See the log from [latest build](https://travis-ci.org/att/ast/jobs/308221645) from ```beta``` branch.", 
          "Those few can be easily fixed by hand.", 
          "> Those few can be easily fixed by hand.\r\n\r\nSure, but you seem to be missing the point that the warnings from compilers and oclint point to broader problems with the code. Some of which are most easily addressed by tools like `clang-format`. Some of those warnings, like the misleading indentation, potentially indicate a real bug. This is a prime example why the developers of the Go language decided that there was decided to side step this issue by requiring that the output of `gofmt` is the authoritative way to format a Go module.", 
          "In light of all the problems we're finding that involve uninitialized variables there are going to be a lot of bug fixes in the immediate future. I will be surprised if more than a handful are backported to the older ksh93u code that most (all?) distros are using. So I'm feeling even less guilty today about the work I'm about to do to reformat the code and address lint warnings. What I think will, and should, happen is that distros will either\r\n\r\na) continue to maintain the older code base on their own, or\r\n\r\nb) adopt the new ksh93 code base and Meson based build once it has stabilized and all the unit tests are enabled and passing."
        ], 
        "number": "125", 
        "title": "Make the ksh source code conform to a consistent style"
      }, 
      {
        "comments": [
          "Also, PR #1 proposed merging the patch used on Solaris: https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/260-22964338.patch. But it wasn't obvious to me that patch does more than paper over a serious bug. If someone can take the time to do a careful analysis of that fix to determine if it is actually fixing, not papering over, the bug that would be appreciated."
        ], 
        "number": "116", 
        "title": "SIGHUP is sent to processes with recycled pids"
      }, 
      {
        "comments": [], 
        "number": "108", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "I would be mostly interested in supporting just Linux and BSD family of operating systems. I am fine with dropping support for rest.", 
          "I think we should try to support as many operating systems as possible that are still being actively maintained. Not just used but being maintained by which I mean that bugs are being fixed in a timely manner. There may be people still using Solaris for example but it is dead. From its wikipedia page:\r\n\r\n> On September 2, 2017, Simon Phipps reported that Oracle had laid off the Solaris core development staff, interpreting it as sign that Oracle no longer intends to support future development of the platform.\r\n\r\nClearly we shouldn't expend resources trying to make ksh93 work on dead OS's. Removing support for an OS that is supported by ksh93u is a more contentious question and probably needs to be handled on a case by case basis. I'm comfortable removing support for DYNIX/3 because it's dual universe support adds non-trivial complexity to ksh and no one is going to care that we no longer support it. The same is true for UWIN. Not to mention pre-ANSI C compilers.", 
          "FWIW, It turns out that the att/ucb universe mechanism was found in OS's other than DYNIX/3: https://en.wikipedia.org/wiki/Universe_(Unix). But as all of those operating systems are now dead we can still safely remove support for dual universe OS's. Also, to the extent there are any SVR4 based distros being used that still have a /usr/ucb directory the commands therein should not be special-cased by ksh93. The native SVR4 variants are perfectly acceptable.", 
          "Removing support for att versus ucb \"universe\"s is going to be really\r\ndifficult without breaking things. At least inadvertantly. Consider this\r\nblock of code from function `B_echo()` in *src/cmd/ksh93/bltins/print.c*:\r\n\r\n```\r\n       static char bsd_univ;\r\n\r\n       /* This mess is because /bin/echo on BSD is different */\r\n       if(!prdata.sh->universe)\r\n       {\r\n               register char *universe;\r\n               if(universe=astconf(\"UNIVERSE\",0,0))\r\n                       bsd_univ = (strcmp(universe,\"ucb\")==0);\r\n               prdata.sh->universe = 1;\r\n       }\r\n       if(!bsd_univ)\r\n               return(b_print(0,argv,(Shbltin_t*)&prdata));\r\n```\r\n\r\nWhy does the builtin `echo` behavior depend on the current \"universe\"?\r\nThe whole point of builtins is to avoid this type of OS specific behavior\r\nso that portable scripts are easier to write. There are even worse examples\r\nof this such as the `settime()` function in *src/lib/libcmd/date.c*. And\r\nwhat the hell does `!prdata.sh->universe` mean in the above block of\r\ncode? Too, that is not even close to the most hard to understand block\r\nof code involving dual-universe support.\r\n\r\nAlso, declaring `bsd_univ` to be static is just plain gross. That is\r\nrelying on static ints being initialized to zero. Furthermore, the\r\n\"static\"ness of the value isn't needed. It should be declared like this:\r\n\r\n```\r\n    char bsd_univ = 0;\r\n```\r\n\r\nBottom line is this cleanup can't be done until the unit tests pass without\r\nfailure on current Linux and BSD based distros.", 
          "These constants are candidates: _UWIN, __EMX__ (remember OS/2?) and __INTERIX.\r\nCreated PR #286 to address this.", 
          "In response to:\r\n\r\n> There may be people still using Solaris for example but it is dead. \r\n\r\nWhile Solaris proper may be dead, illumos (https://github.com/illumos/illumos-gate) and derivatives are still actively developed and used in new deployments.\r\n\r\nIncidentally, `/usr/ucb` is still a thing on those systems. Aside from `/usr/ucb/install`, I can't recall needing much from there, though."
        ], 
        "number": "81", 
        "title": "Remove support for \"att\" and \"ucb\" universes (i.e., OS personalities)"
      }, 
      {
        "comments": [], 
        "number": "75", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "74", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "This is definitely a bug. But the subject line is misleading. The problem is that unless you force the `(...)` list of commands to be executed in a subshell you get the wrong behavior. The `(...)` notation does not force the creation of a subshell. It only creates a \"separate environment\". Whatever that means as the term appears to be unused anywhere else in the documentation or source code. I too used to think it created a subshell but it doesn't. Try this: `echo $$; ( echo $$ ); ( echo $$ ) &` to see what I mean.\r\n\r\nSome things, most notably variable assignment, are handled as expected by parenthesized blocks:\r\n\r\n```\r\n$ x=1; echo $x $$; (x=2; echo $x $$); echo $x $$\r\n1 51108\r\n2 51108\r\n1 51108\r\n```", 
          "No, your understanding is incorrect. The `(...)` notation always creates a subshell, but ksh93 by default implements subshells without forking a new process.\r\n\r\nYour example `echo $$; ( echo $$ ); ( echo $$ ) &` simply prints the PID of the main shell three times. That's because `$$` doesn't change (on any shell) when a subshell is created (whether by forking or not) because by definition it represents the PID of the main shell.\r\n\r\nInstead, try this:\r\n\r\n    $ echo ${.sh.subshell}; (echo ${.sh.subshell}; (echo ${.sh.subshell}); echo ${.sh.subshell})\r\n    0\r\n    1\r\n    2\r\n    1\r\n\r\nThe subshell counter goes up as the subshell level increases.\r\n"
        ], 
        "number": "73", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "71", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "FYI, it is an effective workaround to use a shell function that tests if the variable is set, even if that function uses the same `${foo+s}` sort of parameter expansion."
        ], 
        "number": "70", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "The write access that prevent further triggers is in function nv_disc() of file nv_dist.c ... the function is called with mode parameter value of NV_POP which delete &lt;fp&gt; from top of the stack  ... caused by the line \"np->nvfun = lp->next;\" ... this overwrite the discipline registration with the next function in the chain ... this should only occur if \"unset X_ARR\" is invoked ... and of course not for \"X_ARR[0]\" or \"X_ARR[{0..2]}]\" so the condition shall be \"the presence of a subscript\" if unset is invoked ...", 
          "The discipline function is assigned to array index \"[0]\" ... which as side effect creates a element \"[0]\" ... looks like a ugly design flaw ...\r\n\r\n$ typeset -a Y_ARR\r\n$ typeset -p Y_ARR\r\ntypeset -a Y_ARR\r\n$ function Y_ARR.unset\r\n  {\r\n  :\r\n  }\r\n$ typeset -p Y_ARR\r\ntypeset -a Y_ARR=([0]=)\r\n$\r\n", 
          "The discipline functions are assigned to the \"value part\" of the \"name-value\" (NV) pairs  in general. But how shall that work with a \"empty array\" ... the discipline stack must be assigned to the \"name part\" or \"type/attribute part\" to active manage the \"value part\" ... will check if root cause is inside the container data type desgin.", 
          "After use of arrays something remains dirty ... also if no discipline function involved:\r\n\r\n$ typeset -a X_ARR=(aa bb cc)\r\n$ typeset -p X_ARR\r\ntypeset -a X_ARR=(aa bb cc)\r\n$ unset X_ARR[1]\r\n$ unset X_ARR[0]\r\n$ typeset -p X_ARR\r\ntypeset -a X_ARR=([2]=cc)\r\n$ unset X_ARR[2]\r\n$ typeset -p X_ARR\r\ntypeset -a X_ARR=([0]=)\r\n$\r\n"
        ], 
        "number": "69", 
        "title": "discipline function \".unset\" only called once for array subscriptions"
      }, 
      {
        "comments": [
          "side note, `>#pattern` as an alternative to `1<#pattern` is not documented (though referred to in the text of the man page)."
        ], 
        "number": "61", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "55", 
        "title": "ksh does not detect invalid array declarations"
      }, 
      {
        "comments": [
          "ksh (like its predecessor the Bourne shell) has been traditionally lax about matching quotes (backtick there being considered one of those quotes). While I agree that doesn't make for a very clean syntax and encourages dirty coding, that could be considered as a feature (and fixing it would probably cause backward portability issues). As ksh93 was a rewrite, I suspect the behaviour was intentional for backward portability with ksh88.\r\n\r\nSee also\r\n\r\n```\r\necho \"`uname\"\r\n```\r\n\r\nAnd it not complaining about missing heredoc terminators"
        ], 
        "number": "54", 
        "title": "ksh should proper error message if command inside back quote ends in a quote"
      }, 
      {
        "comments": [
          "@saper, AFAICT this is the only open issue that deals with anything other than the `ksh` command. As you might have noticed from other issues and mailing list messages several people, including myself, want to focus work on the `ksh` command. Other libraries and commands, such as `tksh`, would still be part of the project but would probably see very little, if any, active maintenance. Obviously if someone like yourself created a pull-request with a fix for this issue it would be merged. But simply opening an issue isn't likely to result in someone else creating a fix.\r\n\r\nI mention all of that because I'm wondering what your expectations (or hopes) are regarding this project. Are you, or anyone you know, likely to contribute changes to the non `ksh` command code?", 
          "Actually @krader1961 , I was looking at this before I was bitten by the same bin/package bug that you experienced and lost all my commits, which wasn't much.  I hadn't fixed it fully, but would have liked to have been able to push it to a branch for this so that others could see what I had done and continue the effort or comment.  Is there a way to do this without it being complete?  When I get time again, I'll try to figure out what I had done and push that somewhere, even if it's just to my fork.", 
          "Is the @melbit-dannyw account just an alternative to the @dannyweldon account? Because the former has no Github activity prior to the above comment AFAICT.\r\n\r\n> Is there a way to do this without it being complete?\r\n\r\nI don't understand your question, @melbit-dannyw. You can create a pull-request (PR) for any Git branch. If you have useful changes to this project, even if unrelated to the `ksh` command, you should create a pull-request to ask that the improvement be merged.", 
          "Sorry, that was me but I accidentally sent it from my work github account.\r\n\r\n> I don't understand your question, @melbit-dannyw. You can create a pull-request (PR) for any Git branch. If you have useful changes to this project, even if unrelated to the ksh command, you should create a pull-request to ask that the improvement be merged.\r\n\r\nOkay, thanks.", 
          "I hope that ksh remains embeddable. Since Common Desktop Environment has become a free software, they are interested in updating their old version of ksh93 that should work as the `dtksh` desktop shell.\r\n\r\nI was looking at tksh as a way to quickly script Xlib calls.", 
          "No worries, @saper, I can't imagine any reason ksh would be changed in a way that would make it impossible to embed it. But someone using it in that manner will probably have to create the fix for issues of this sort as I can't imagine anyone not using `tksh` being willing to go to the trouble of setting up that environment to figure out the proper fix.", 
          "While restyling *src/cmd/ksh93/sh/xec.c* I came across this line:\r\n\r\n```\r\n#define SH_TOPFUN 0x8000 // this is a temporary tksh hack\r\n```\r\n\r\nWhile I have no objection to being able to build ksh as a library that can be embedded in `tk`, `vim`, or other UIs as a scripting language I definitely see \"hacks\" like the one above as a red flag. That comment doesn't even bother to explain the meaning of the magic constant or why it is needed."
        ], 
        "number": "53", 
        "title": "nv_open(\"tcl_library\", 0, 0) will crash tksh on startup"
      }, 
      {
        "comments": [], 
        "number": "43", 
        "title": "Active locale/character set is not properly applied when parsing C-style strings"
      }, 
      {
        "comments": [
          "(Actually, as it turns out, file descriptors opened in command substitution aren't limited to the lifetime of the command substitution in ksh anyway:\r\n\r\n```\r\n$ echo hi > message               \r\n$ cat <&$(exec 4<message; echo 4)-\r\nhi\r\n$ ls -l /proc/$$/fd/4\r\nlr-x------. 1 tetsujin tetsujin 64 May 31 20:38 /proc/5704/fd/4 -> /home/tetsujin/message\r\n```\r\n\r\n...Unless the file descriptor is auto-assigned...\r\n```\r\n$ cat <&$(exec {fd}<zort; echo $fd)-\r\nksh: 12-: cannot open [Bad file descriptor]\r\n```\r\n\r\n...Or identified by number, and that file descriptor is already open in the main shell process:\r\n```\r\n$ cat <&$(exec 4<message; echo 4)-  \r\nhi\r\n$ cat <&$(exec 4<zort; echo 4)-\r\n$ ls -l /proc/$$/fd/4\r\nlr-x------. 1 tetsujin tetsujin 64 May 31 20:38 /proc/5704/fd/4 -> /home/tetsujin/message\r\n```\r\n\r\n...But the dash on the redirect still only affects the command being run, not the overall state of the shell...)", 
          "Another model that may work for this type of functionality would be to integrate file descriptor passing into the shell, and obtain the file descriptor for the redirection from a command that sends a file descriptor to its output using SCM_RIGHTS or similar functionality. For instance, if \"accept_connection\" is a command which, when run, accepts a connection on some interface and then passes the file descriptor for that connection over a socket on FD 1, a syntax such as this one:\r\n\r\n`$ cmd <>&(accept_connection --with-complicated-options)`\r\n\r\ncould be used to run accept_connection with its output connected via a socket pair to the shell, and then use recvmsg() on the other end of that socket pair to receive a file descriptor emitted by the command. The file descriptor is then used for the redirection of \"cmd\" and disposed of when \"cmd\" is finished.\r\n\r\nIf \"accept_connection\" returned a nonzero result, or did not yield a file descriptor over its output socket, then the redirection would fail.\r\n\r\nThis approach would allow for various mechanisms of opening a (single) file descriptor to be implemented as internal or external commands, and integrated with the redirection syntax, allowing for a programming style in which the lifetime of these file descriptors is managed by the shell and by the structure of the code."
        ], 
        "number": "41", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "At least on Solaris 11.3 SRU 24.4 it works as expected, i.e. embedded into a `for (( I=0; I < 20; I++ )); do  ... done` it produces expected results, i.e.:\r\n```\r\nAlpha: 1 2 3 4 5\r\nBeta:  1 1 1 1 1\r\nAlpha: 6 7 8 9 10\r\nBeta:  1 1 1 1 1\r\nAlpha: 11 12 13 14 15\r\nBeta:  1 1 1 1 1\r\nAlpha: 16 17 18 19 20\r\nBeta:  1 1 1 1 1\r\n...\r\n```\r\n\r\nHowever, on Ubuntu 16.04 I see similar misbehavior as you:\r\n```\r\nAlpha: 1 2 3 4 5\r\nBeta:  1 0 0 0 0\r\nAlpha: 1 2 3 4 5\r\nBeta:  0 0 1 1 0\r\nAlpha: 1 2 3 4 5\r\nBeta:  0 0 1 1 0\r\nAlpha: 1 2 3 4 5\r\nBeta:  0 0 1 1 0\r\n...\r\n```\r\n\r\nPerhaps it is worth to check the patches applied to the Solaris version: https://github.com/oracle/solaris-userland/tree/master/components/ksh93/", 
          "It seems like a no brainer that we should merge fixes from other forks (e.g., Solaris). The problem is that doing that proactively may require more work than can be justified given that the changes may not apply cleanly. Furthermore, each change needs to be reviewed even if it does apply cleanly since the change may introduce problems. I think the value is worth the cost. So if you're willing to do some leg work, @jelmd, to figure out which of the Solaris patches fixes this problem we would be happy to merge them.", 
          "It was just a hint, to possibly safe you some time. If you prefer troubleshooting it by your own and provide your own fix, just go ahead.", 
          "I took at look at all of the Solaris patches. Some are only relevant to integrating ksh93 into the process of building Solaris software. Others, like [010-path_utmp.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/010-path_utmp.patch) don't apply cleanly and it appears the fix has already been implemented in a different manner. Similarly this [patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/050-CR7065478.patch) does not apply cleanly and appears to fix a `wctomb()` bug that may have been fixed in a different manner looking at the current code.\r\n\r\nThen there's [015-solaris_alias.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/015-solaris_alias.patch) which introduces a *src/cmd/alias/alias.c* file. This patch appears to workaround a performance issue and a bug in command alias handling. The code is licensed by the CDDL. Even if we wanted to merge that patch could we given the license?\r\n\r\nThis one, [020-CR6919590.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/020-CR6919590.patch), looks like it can be applied but the affected block of code is now ~100 lines away from the location in the patch. And given the commit comment, \"19782029 userland should be able to build from SCM repositories\", it's hard to know exactly what bug is being fixed. And whether this block near the line number listed in the patch doesn't already address the issue:\r\n\r\n```\r\n                        if(sh_isoption(shp,SH_RESTRICTED) && !f && o==SH_RESTRICTED)\r\n                                errormsg(SH_DICT,ERROR_exit(1), e_restricted, opt_info.arg);\r\n                        break;\r\n```\r\n\r\nPatch [060-CR7065900.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/060-CR7065900.patch) is a one line change that removes `sleep` builtin table. Why? The commit comment provides no clue. We probably don't want this one.\r\n\r\nPatch [075-multi_lang_arith.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/075-multi_lang_arith.patch) is a one line change that looks valid and is not already in the AST code. It appears to fix a bug in `S2F_function()`'s handling of the thousands separator character (presumably only seen in locales that don't use the English rules). It should probably be merged but without a better understanding of what it fixes I'm hesitant to do so.\r\n\r\nA lot of the more recent patches state \"This fix is from the community, details in the following location.\" So presumably the fix is already in this code base.\r\n\r\nA few say \"This fix has been developed inhouse. Patch has been submitted upstream but has not been accepted yet.\" One such example is [250-22561374.patch](https://github.com/oracle/solaris-userland/blob/master/components/ksh93/patches/250-22561374.patch) which is tied to issue #7. It has not been applied and probably should be. None of the patches would obviously affect this issue but a couple in this category might.", 
          "@jelmd, Do you see the difference between your comment\r\n\r\n> It was just a hint, to possibly safe you some time. If you prefer troubleshooting it by your own and provide your own fix, just go ahead.\r\n\r\nand my previous comment? I actually went to the trouble of trying to figure out which Solaris patches we might want to import. You just implied I'm an idiot for not wanting to import all the Solaris patches and instead do it the hard way by figuring out the fix for the issue on my own.\r\n\r\nI'm not getting paid to work on keeping ksh relevant. Of the POSIX compatible shells it is simply my favorite such shell. If you want to help ensure ksh remains relevant you might consider actually contributing more than unhelpful comments.", 
          "@krader1961: OT wrt. the Issue, but since you are asking I owe an answer:\r\nI have a job and thus my time is limited. Even if you do not consider hints, where one may find a solution for a problem as a contribution, I do. And a lot of people are actually happy, when getting a hint, because this is all they need to get started. In contrast to this, wiping away any help, patches, ... (because of not understanding things, having not done its homework, having complete different ideas or for whatever reason) and than saying, that one is not willingly to contribute is simply not fair, to be diplomatic. So please be careful about what you are saying (I have a google translator ;-))! Just reading carefully and the will to understand, what ppl/non-native speaker have written may also help.\r\n\r\nI think right-now no-one is getting payed to work on ksh, but spends its spare time to it. And thus it is not surprising, that at least some of them start wondering, when one, who actually hasn't even took the time to read the documentation, starts to make essential changes to the software they care about. Last but not least I haven't seen any open source project (and not even internal ones), where developers encourages others to commit aka merge back unfinished features. Maybe I've missed something, but than I think one can at least expect, that it gets explained, why such unusual things are being allowed. If it is the way you learned it - ok, that's at least an explanation, but still do not expect, that other developers change their mind about it ...\r\n\r\nI hope, we can now concentrate on the issues instead polluting issues with discussion belonging somewhere else, e.g. ML.", 
          "I've built a ksh with every applicable patch from the aforementioned Solaris set of patches. They do not resolve this issue. However, I get this consistent output rather than random output or what is asserted to be the correct output:\r\n\r\n```\r\nAlpha: 1 2 3 4 5\r\nBeta:  0 0 0 0 0\r\nAlpha: 1 2 3 4 5\r\nBeta:  0 0 0 0 0\r\n```"
        ], 
        "number": "40", 
        "title": "typeset -S within functions"
      }, 
      {
        "comments": [], 
        "number": "39", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "38", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "It does work.  As he said that he might consider adding a self-generating man page anyway, it can't hurt to do one, just add a note about David's warning.\r\n\r\nFinbarr's blog has some examples of usage:\r\nhttp://blog.fpmurphy.com/2008/12/mysterious-ksh93-alarm-builtin.html\r\n\r\nDon, would you be willing to have a go and submit a pull request?  :)\r\n\r\nThe variable to update is sh_optalarm in src/cmd/ksh93/data/builtins.c", 
          "Thanks for the feedback Danny. I will try it out.\r\n\r\nNo problems for the pull request. They may be some lag time here as I have troubles compiling the code these days on my mac box. But will sure do so :-)\r\n"
        ], 
        "number": "35", 
        "title": "Missing `alarm` man page"
      }, 
      {
        "comments": [
          "The need for such `#undef` directives implies that the code needs to be refactored. But I would prefer to just remove the use of the `posix_spawn()` API. That API is so [fugly](https://www.urbandictionary.com/define.php?term=Fugly) that even a Microsoft software engineer would probably hate it.", 
          "BTW, the intended use case for `posix_spawn()` is spawning \"helper processes\", not starting new process groups. Notably it doesn't provide the equivalent of `setsid()` and `tcsetpgrp()`.  Which makes it a poor choice for shells like ksh. It's really meant to provide a cheap way for potentially large programs to run external commands without incurring the cost of duplicating its virtual memory structures (e.g., the process page tables).\r\n\r\nWhile it is more efficient than `fork()` when the virtual process size is large that will not normally be an issue for a ksh process. And we still have to support `fork()` because `posix_spawn()` isn't available on all systems we want to support or is broken (e.g., on Cygwin). Also, note that on Linux it's actually implemented as a function not a syscall. On Linux we should  be using `clone()`. And on other systems (e.g., BSD) we should probably be using `vfork()`.\r\n\r\nSee https://bugzilla.redhat.com/show_bug.cgi?id=1295563 for another example of how `posix_spawn()` causes problems.\r\n\r\nThere was a long discussion about using `posix_spawn()` in the Go language: https://github.com/golang/go/issues/5838. It looks like ultimately they chose to use the Linux `clone()` function."
        ], 
        "number": "34", 
        "title": "KSH hang in |spawnvex(3ast)|"
      }, 
      {
        "comments": [
          "@zakukai, your first sentence is incorrect. From the [ksh93 man page](https://linux.die.net/man/1/ksh93): \"The environment for any simple-command or function may be augmented by prefixing it with one or more variable assignments.\" An explicit **export** command is not necessary.\r\n\r\nThe rest of your comments aren't relevant to this issue.", 
          "I guess I misunderstood the issue you were describing. Sorry about that.", 
          "Hmm. The man page is incorrect in any case, whether this behaviour is desired or not:\r\n\r\n       The environment for any simple-command or function may be augmented  by\r\n       prefixing it with one or more variable assignments.  A variable assign-\r\n       ment argument is a word of the form identifier=value.  Thus:             \r\n                                                                                \r\n              TERM=450 cmd args                  and                            \r\n              (export TERM; TERM=450; cmd args)                                 \r\n\r\n       are equivalent (as far as the  above  execution  of  cmd  is  concerned\r\n       except for special built-in commands listed below - those that are pre-\r\n       ceded with a dagger).                                                    \r\n\r\nThey are, of course, not equivalent at all if `cmd` is a shell function: if you run a shell function within a subshell, any changes it makes apply to that subshell only, whereas a function run from the main shell can make permanent changes.\r\n\r\nIn POSIX terms, it's [undefined](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_09_01) whether (a) variable assignments preceding a function call persist after the function call and (b) whether they are exported or not. So, at least for POSIX functions, the current behaviour is standards-compliant (though undocumented)."
        ], 
        "number": "32", 
        "title": "VAR=value followed by nested function call fails to put VAR into environment"
      }, 
      {
        "comments": [
          "Agreed, and zsh behaves the same as bash as well.", 
          "Not sure if this is a bug or a legitimate implementation difference. Nothing in the ksh93 man page says that the pattern following `#` or `%` may be empty.\r\n\r\n[yash](http://yash.osdn.jp/) does not recognise an empty pattern there either.\r\n"
        ], 
        "number": "29", 
        "title": "parameter expansion pattern replacement does not match empty string at beginning/end "
      }, 
      {
        "comments": [
          "Agreed, this bug exists in 2012-08-01, but I just tried it in 2014-12-24 and it works."
        ], 
        "number": "28", 
        "title": "string match on ERE quantifiers fails"
      }, 
      {
        "comments": [], 
        "number": "27", 
        "title": "man sh.1 not include json print and printf, test pattern also not include full json testing"
      }, 
      {
        "comments": [], 
        "number": "25", 
        "title": "typeset -f output truncated for functions within functions"
      }, 
      {
        "comments": [
          "Pretty sure this is the same as #23 . This one's annoying.  I might try to bisect and find what broke it since this bug wasn't in the last stable. It could be one of the many late changes in the incomprehensible nvtree code."
        ], 
        "number": "24", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "23", 
        "title": "Regression appending to an indexed array overwrites arr[-1] if arr[0] is unset"
      }, 
      {
        "comments": [
          "I seem to be getting some rather odd behavior here.\r\nI wanted to turn this example into a test I could use on different shells. Bash posed a problem because \"shopt lastpipe\" was not set. So I rearranged the test to take input from a \"here string\":\r\n\r\n_file read-n_bytes_or_characters.sh_\r\n```\r\nfor ((i=1;i<=6;i++)); do\r\n\tIFS= read -rn \"$i\" a <<<'\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac'\r\n\tprintf \"$i %q\\n\" \"$a\"\r\ndone\r\n```\r\n\r\nIn this case, ksh seems to get it right:\r\n\r\n```\r\n$ ksh read-n_bytes_or_characters.sh\r\n1 $'\\u[20ac]'\r\n2 $'\\u[20ac]\\u[20ac]'\r\n3 $'\\u[20ac]\\u[20ac]\\u[20ac]'\r\n4 $'\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]'\r\n5 $'\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]'\r\n6 $'\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]\\u[20ac]'\r\n```\r\n\r\nBut if I switch it back to \"echo '\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac\u20ac' | read ...\" then it fails again.\r\nThe \"here string\" feature is implemented using an unlinked temporary file, while the pipeline is (of course) a socket pair in ksh. It seems to go wrong when the input is a socket, tty, or pipe, but it does OK when the input is a file.", 
          "2017-05-22 09:46:36 -0700, zakukai:\n[...]\n> It seems to go wrong when the input is a socket,\n> tty, or pipe, but it does OK when the input is a file.\n[...]\n\nThe fact that we get a different code path when the input goes\nfrom a regular file doesn't surprise me.\n\nWhen getting input from a seekable file (like a regular file and\nsome device files), it's easier. To read the requested amount of\ncharacters, ksh93 can read a large block, find out how many\nbytes those characters occupy and seek back after that.\n\nWhile for a non-seekable file like a pipe/socket/tty device, it\nneeds to read one byte at a time to make sure it doesn't read\npast the requested amount of characters.\n\nI suppose that's when it gets confused.\n\n-- \nStephane\n", 
          "I haven't quite nailed it down yet but it looks like it comes down to this line\r\n\r\n```\r\nast/src/cmd/ksh93/bltins/read.c : 649\r\nif((size -= x) > 0 && (up >= cur || z < 0) && ((flags & NN_FLAG) || z < 0 || m > c))\r\n    continue;   // Otherwise, end the read loop\r\n```\r\n\r\nBasically, when using -n (that's N_FLAG, as opposed to -N which is NN_FLAG), the code loops: On each iteration there are (x) characters remaining, so the implementation reads (x) bytes (since each character must take at least one byte). Then the newly-completed multi-byte characters are counted (starting from the pointer (up) and extending to the pointer (cur)) to determine how many characters will be left on the next iteration. Usually there will be some number of extra bytes read in that are carried over to the next iteration. But when the end of the last read coincides with a character boundary, it hits an edge case:\r\n(up == cur): the end of the last complete character read coincides with the last byte read from the stream\r\n(z > 0): The call to mbsize(up) on line 644 returned nonzero, because *up = 0 (an end-of-string marker set on (cur) to prevent reading beyond the buffered data) - and 0 is a single-byte character in UTF-8.\r\nSo the back half of the \"if\" condition ((flags & NN_FLAG) || z < 0 || m > c) fails on this edge case, because the NN flag isn't set and z>0 (I don't really understand (m > c) yet..)\r\n\r\nI'll try to work out the parts I'm not quite understanding yet and put a patch together."
        ], 
        "number": "22", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "The license is EPL 1.0\n\nYes, AT&T made a weird license choice (again). The EPL is particularly ambiguous about the reusability of \"modules\", and this is a project that consists largely of libraries.\n\nI would have liked to use AST's regex code but avoided this because I couldn't guarantee license compatibility everywhere I might have wanted it.\n", 
          "It is a little tricky because this repo contains many independent packages, which could each technically have their own license, should AT&T decide to do so I suppose, and the license is stated at the top of every source file, though I have only checked a few.\r\n\r\nPerhaps a LICENSE file could be created indicating this information rather than just stating EPL 1.0?  Though it makes more sense to me to have a single LICENSE file and have the source files point to that location rather than all of them declare what the license actually is, to make it easier to change.", 
          "The [Fish](https://github.com/fish-shell/fish-shell) project does not have a LICENSE file. The [Elvish](https://github.com/elves/elvish) project does. Those are the other shell projects I've contributed to. I am not a lawyer so I have no idea what the right thing to do here is. We can certainly, and probably should, create a *LICENSE* file that describes which portions of the code are under which licenses.\r\n\r\nThis may be difficult because parts of the code (e.g., *src/libbz/crctable.c*) are from other projects without an explicit license mentioned in the file but which do have a *LICENSE* file. While other pieces of code put the license in each source file. And, of course, there may be other variations I haven't noticed."
        ], 
        "number": "21", 
        "title": "Missing license"
      }, 
      {
        "comments": [
          "This issue is the poster child for why ksh93 should use the equivalent OS provided functionality rather than that of the AST libraries. There will never be enough people who care about AST locale and timezone functions to fix bugs like this in a timely manner. If we want ksh93 to remain relevant we must update it to rely more on the functionality provided by the OS. Possibly providing fallback implementations when necessary but with the understanding that those fallback functions will always be best effort and likely to have shortcomings. Basic features like support for timezones and locales should not be the responsibility of this project."
        ], 
        "number": "17", 
        "title": "date"
      }, 
      {
        "comments": [
          "As St\u00e9phane has pointed out on austin-group-l, the output of `times` (being actually the output of `time`) on ksh93 is not POSIX compliant either. It should follow [this format](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_27). So that's another reason to implement a proper special builtin."
        ], 
        "number": "16", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "15", 
        "title": "optimisation done by ksh93 file reading builtins break functionality and cause memory leak"
      }, 
      {
        "comments": [
          "I ran into this - it happens actually right after \\0176, at \\0177 (0x7F)\n", 
          "I believe Apple fixed this with: https://opensource.apple.com/source/ksh/ksh-25/patches/src__lib__libast__sfio__sfvprintf.c.diff.auto.html"
        ], 
        "number": "14", 
        "title": "Issue with printf %Lb \"\\0200\" in UTF-8 locales"
      }, 
      {
        "comments": [
          "On the release version (2012-08-01), expanding `\"$*\"` while IFS contains a UTF-8 character corrupts ksh93's shell-quoting mechanism, so that anything that produces output suitable for re-entry into the shell has the final quote missing -- even after IFS is restored.\r\n\r\nThis appears to be fixed on the current beta (2014-12-24), at least as compiled on Linux.\r\n\r\nOn the release version, the behaviour is as follows:\r\n\r\n    $ ksh -c 'i=IFS; IFS=\u00e9; set : :; echo \"$*\"; IFS=$i; trap \"echo end\" EXIT; trap'\r\n    :?:\r\n    trap -- 'echo end EXIT\r\n    end\r\n\r\nNote the missing quote after `trap -- 'echo end`. You get the same with the output of `export -p`, `alias`, etc.\r\n\r\nEven using a subshell doesn't avoid the corruption (yay non-forking subshells). However, setting and then unsetting `LC_ALL=C` seems to be an effective workaround:\r\n\r\n    $ ksh -c 'IFS=\u00e9; set : :; echo \"$*\"; trap \"echo end\" EXIT; LC_ALL=C; unset LC_ALL; trap'\r\n    :?:\r\n    trap -- 'echo end' EXIT\r\n    end\r\n"
        ], 
        "number": "13", 
        "title": "ksh93"
      }, 
      {
        "comments": [
          "Note that fixing it could break some use cases like https://unix.stackexchange.com/a/411006"
        ], 
        "number": "12", 
        "title": "ksh"
      }, 
      {
        "comments": [], 
        "number": "11", 
        "title": "ksh regression"
      }, 
      {
        "comments": [
          "I just tried this with 2012-08-01 on ubuntu and it worked fine, and the same with a local build of 2014-12-24 (beta).  What ksh version and platform are you using?  eg. $KSH_VERSION", 
          "Danny,\r\n\r\n```\r\n$ ksh -c 'echo \"${.sh.version}\"; type suspend'\r\nVersion ABIJM 93v- 2014-12-24\r\nsuspend is an alias for 'kill -s STOP $$'\r\n```\r\n\r\nLeaving a variable unquoted in list contexts has a very special meaning in Bourne-like shells other than `zsh`. It doesn't make sense to leave a variable unquoted unless you want splitting and/or globbing applied to it. See https://unix.stackexchange.com/questions/171346/security-implications-of-forgetting-to-quote-a-variable-in-bash-posix-shells for more details.\r\n\r\nAbove, because `$$` is not quoted, splitting (globbing can't apply as pids never contain wildcard characters) applies, so if `$IFS` contains digits, `$$` will be split.\r\n\r\nYes, that's an awful, very surprising design. It's there because David Korn didn't want to break backward compatibility with the Bourne shell. And I suppose the Bourne shell did that so parameter expansion was not too different from that of the Thompson shell (where `$1`... expansion (no variable in that shell yet) was more like some kind of preprocessor macro expansion)\r\n\r\n```\r\n$ ksh -c 'echo \"${.sh.version}\"; IFS=1234567890; suspend'\r\nVersion ABIJM 93v- 2014-12-24\r\nksh: kill: : Arguments must be %job, process ids, or job pool names\r\n```", 
          "Sorry, I realise now that one must set IFS to a number that occurs within $$ for this to take effect, so I have been able to replicate it.  I doubt if anyone would change their IFS variable in an interactive shell to anything that would cause this, but I think it can't hurt to update this alias for correctness."
        ], 
        "number": "10", 
        "title": "Wrong syntax for the \"suspend\" alias in ksh93"
      }, 
      {
        "comments": [], 
        "number": "9", 
        "title": "<>; redirection operator doesn't work for the last command of a `ksh -c inline-script`"
      }, 
      {
        "comments": [], 
        "number": "8", 
        "title": "ksh93"
      }, 
      {
        "comments": [], 
        "number": "6", 
        "title": "ksh93 dumps core in emacs mode while entering characters in different locale."
      }, 
      {
        "comments": [
          ":+1: on this. Would be nice to have tagged releases so we can get these installations working again under Homebrew. (Affects `vmalloc` and `vcodex`, which were previously downloaded from the web site.) Would probably be convenient for other users, too, because then they could download distribution tarballs and install from them, instead of having to clone the Git repo.\n", 
          "@ilovezfs and @apjanke: It's not clear what you're requesting. Is simply tagging commits that represent a new stable release sufficient for your needs? Should something like a `stable` tag always be attached to the current stable release or should we simply use a unique tag for each stable release and somehow communicate to Homebrew when a new stable release is available?\r\n\r\nA couple of the maintainers (e.g., @siteshwar and myself) would like to rearrange this project to focus on ksh and shunt the non-ksh bits into a separate branch. At some point that will likely entail switching the build system from Nmake to Meson (or possibly Cmake). How does that affect Homebrew?"
        ], 
        "number": "3", 
        "title": "Please create tag(s)"
      }
    ], 
    "repo": "ast"
  }, 
  {
    "open_issues": [], 
    "repo": "yoix"
  }, 
  {
    "open_issues": [], 
    "repo": "wsp"
  }, 
  {
    "open_issues": [], 
    "repo": "uwin"
  }, 
  {
    "open_issues": [], 
    "repo": "twitterscope"
  }, 
  {
    "open_issues": [], 
    "repo": "vertx-eventbus"
  }, 
  {
    "open_issues": [
      {
        "comments": [], 
        "number": "7", 
        "title": "why not always use traversals?"
      }
    ], 
    "repo": "dcplot.js"
  }, 
  {
    "open_issues": [], 
    "repo": "mojombo.github.com"
  }, 
  {
    "open_issues": [], 
    "repo": "Cdt"
  }, 
  {
    "open_issues": [], 
    "repo": "vcodex"
  }, 
  {
    "open_issues": [], 
    "repo": "solomon"
  }, 
  {
    "open_issues": [], 
    "repo": "ECharts"
  }
]